{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import arcgis\n",
    "from arcgis.features import GeoAccessor\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import locale\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "Output_polygon_features_ach_union = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\new_fgbd_temp.gdb\\ach_bln_Bali_ver_202409\"\n",
    "arcpy.management.AddField(\n",
    "                        in_table=Output_polygon_features_ach_union,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "                    \n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "        in_features=Output_polygon_features_ach_union,\n",
    "        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "        area_unit=\"HECTARES\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROSES 1 BULANAN\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# #Get current year and month\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "\n",
    "\n",
    "# Get the current month name\n",
    "current_month_name = now.strftime(\"%B\").upper()\n",
    "\n",
    "# Get the current year\n",
    "current_year = now.strftime(\"%Y\")\n",
    "\n",
    "# Get current date\n",
    "current_day = now.day\n",
    "\n",
    "# Get date time\n",
    "current_date_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "#Get file and folder structure\n",
    "\n",
    "main_folder = r'D:\\Project\\BMKG SiPinter Iklim\\Data\\PROSES_1-20240605T061252Z-001\\PROSES_1'\n",
    "folder_bulanan = r'BULANAN'\n",
    "folder_dasarian = r'DASARIAN'\n",
    "file_name_bulanan = f'BlendGSMAP_POS.{year}0{month}.xls'\n",
    "file_name_dasarian = f'BlendGSMAP_POS.{year}0{month}dec.xls'\n",
    "\n",
    "file_path_bulanan = os.path.join(main_folder, folder_bulanan)\n",
    "newPath_bulanan = file_path_bulanan.replace(os.sep, '/')\n",
    "\n",
    "\n",
    "# Get the file geodatabase\n",
    "\n",
    "fgdb_input = r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb'\n",
    "fgdb_output = r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_output.gdb'\n",
    "fgdb_temp = r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp.gdb'\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Parameter\n",
    "sheet_name = \"Sheet 1\"\n",
    "x_field=\"LON\",\n",
    "y_field=\"LAT\",\n",
    "z_field=None,\n",
    "coordinate_system='GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision'\n",
    "gridsize_pbesar = 0.01\n",
    "gridsize_pkecil = 0.005\n",
    "\n",
    "\n",
    "# Parameter for interpolation\n",
    "extent_pulau = {'NTT' : '118.927002959119 -11.0076153767482 125.193332857026 -7.77865793181803 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'NTB' : '115.820981003271 -9.10965601960959 119.346162224907 -8.08005395782385 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Bali' : '114.431628140926 -8.84925896962568 115.712436009614 -8.06162162313933 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]' ,\n",
    "                  'Malut' : '124.283099246633 -6.64183298230625 129.923590280667 2.64524507410096 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Maluku' : '125.722520307167 -8.34541150093997 134.908456811133 -2.72545123828399 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Kepri': '103.279684216553 -1.27537377987602 109.167114597261 4.79579910164728 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Babel' : '105.108508705812 -3.80160971581569 108.871826028249 -1.49339863673765 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Sumatera' : '94.9719518118267 -6.16796564429899 106.220687422587 6.0767684013407 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'NAD' : '94.9719518118267 1.97715200096411 98.2874408863879 6.0767684013407 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Sumut' : '97.0574708260179 -0.638797358811019 100.434456035817 4.30254668807925 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Sumbar' : '98.5965019151313 -3.57302000037265 101.892882963778 0.906722222852352 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Riau' : '100.049719928432 -1.12760203040932 103.813577353112 2.92115400035686 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Jambi' : '101.130556666657 -2.77005799038392 104.500728368919 -0.730430926046324 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\\\n",
    "                  'Sumsel' :  '102.063888894357 -4.92415918240027 106.220687422587 -1.62693146341627 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Bengkulu' :  '101.022391691423 -5.51443935888926 103.790488044688 -2.28865368971594 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Lampung' :  '103.590696917129 -6.16796564429899 106.1110309739 -3.72366604425247 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Jawa' : '105.099873731188 -8.78022255682549 116.270189000022 -5.0429653290866 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Banten' :  '105.099873731188 -7.01628117283781 106.779863216015 -5.80758839039186 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'DKI' :  '106.390424798266 -6.37262555572477 106.973390999895 -5.20241887802877 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Jabar' :  '106.37027230872 -7.820989562818 108.847083830654 -5.8065380586844 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Jateng' :  '108.555848823564 -8.21180553419799 111.691393655193 -5.72537100017149 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'DIY' :  '110.003529175031 -8.20562453964072 110.838827850625 -7.54116155925851 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Jatim' : '110.89528623737 -8.78022255682549 116.270189000022 -5.0429653290866 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Kalimantan' : '108.598444260794 -4.94274407807671 119.03708614421 4.40846169535104 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Kalbar' : '108.598444260794 -3.06791852422049 114.205522583201 2.0814594439982 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Kalsel' : '114.346635820587 -4.94274407807671 117.458157058801 -1.3125795360167 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Kalteng' : '110.732447353363 -3.54360722409405 115.849358829846 0.791009028144174 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Kaltim' : '113.83433533171 -2.40959270094237 119.03708614421 2.61939906121773 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Kaltara' : '114.565164000119 1.11404135402529 117.985933926809 4.40846169535104 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Sulawesi' : '117.038291271225 -7.75894120157517 127.163453354689 5.56594630797576 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Sulbar'  :   '117.058410824 -3.57057991393185 119.874828088046 -0.849096375597185 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Sulsel'  :   '117.038291271225 -7.75894120157517 122.222552631299 -1.88115016644696 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Sulteng'  :   '119.42652694786 -3.64056320942456 124.181408050141 1.37428146871486 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Sultra'  :   '120.864497544026 -6.21307839725017 124.6168589242 -2.77328875357307 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Sulut'  :   '123.104812308741 0.292131835415944 127.163453354689 5.56594630797576 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Gorontalo'  : '121.161229220053 0.30628139167294 123.55229455505 1.055647735055 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Pulau_Papua': '129.29993427105 -9.12554166671453 141.020041789097 1.08129531522667 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Papua'  : '134.299477112279 -3.95672767993841 141.004719444047 0.938007294101396 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Papbar'  : '131.577417201143 -4.33079498869773 135.334166666758 -0.713742988348201 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Papsel'  : '137.495965436756 -9.12554166671452 141.020041789097 -4.5413156685832 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Papteng'  :'134.585257884944 -5.14744646987862 138.301778493683 -2.27452565693346 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Papgun'  : '137.826991573702 -5.26482342925783 141.002474721831 -3.1069562128589 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  'Papbarda'  : '129.29993427105 -2.28386464963381 133.493930115283 1.08129531522667 GEOGCS[\"GCS_WGS_1984\".DATUM[\"D_WGS_1984\".SPHEROID[\"WGS_1984\".6378137.0.298.257223563]].PRIMEM[\"Greenwich\".0.0].UNIT[\"Degree\".0.0174532925199433]]',\n",
    "                  }\n",
    "\n",
    "\n",
    "pulau_feature = {'NTT' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_NTT',\n",
    "                  'NTB' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_NTB',\n",
    "                  'Bali' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Bali' ,\n",
    "                  'Malut' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Maluku_Utara',\n",
    "                  'Maluku' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Maluku',\n",
    "                  'Kepri': r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_KepRiau',\n",
    "                  'Babel' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Bangka_Belitung',\n",
    "                  'Sumatera' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Sumatera',\n",
    "                  'NAD' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\NAD',\n",
    "                  'Sumut' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Sumut',\n",
    "                  'Sumbar' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Sumbar',\n",
    "                  'Riau' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Riau',\n",
    "                  'Jambi' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Jambi',\n",
    "                  'Sumsel' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Sumsel',\n",
    "                  'Bengkulu' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Bengkulu',\n",
    "                  'Lampung' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Lampung',\n",
    "                  'Jawa' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Jawa',\n",
    "                  'Banten' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Banten',\n",
    "                  'DKI' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\DKI',\n",
    "                  'Jabar' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Jabar',\n",
    "                  'Jateng' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Jateng',\n",
    "                  'DIY' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\DIY',\n",
    "                  'Jatim' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Jatim',\n",
    "                  'Kalimantan' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Kalimantan',\n",
    "                  'Kalbar' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Kalbar',\n",
    "                  'Kalsel' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Kalsel',\n",
    "                  'Kalteng' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Kalteng',\n",
    "                  'Kaltim' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Kaltim',\n",
    "                  'Kaltara' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Kaltara',\n",
    "                  'Sulawesi'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Sulawesi',\n",
    "                  'Sulbar'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Sulbar',\n",
    "                  'Sulsel'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Sulsel',\n",
    "                  'Sulteng'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Sulteng',\n",
    "                  'Sultra'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Sultra',\n",
    "                  'Sulut'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Sulut',\n",
    "                  'Gorontalo'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Gorontalo',\n",
    "                  'Pulau_Papua'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Papua',\n",
    "                  'Papua'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Papua',\n",
    "                  'Papbar'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Papbar',\n",
    "                  'Papsel'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Papsel',\n",
    "                  'Papteng'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Papteng',\n",
    "                  'Papgun'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Papgun',\n",
    "                  'Papbarda'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Papbarda',\n",
    "                  }\n",
    "\n",
    "titik_grid = {'NTT' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_NTT',\n",
    "                  'NTB' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_NTB',\n",
    "                  'Bali' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Bali' ,\n",
    "                  'Malut' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Malut',\n",
    "                  'Maluku' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Maluku',\n",
    "                  'Kepri': r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Kepri',\n",
    "                  'Babel' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Babel',\n",
    "                  'NAD' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_NAD',\n",
    "                  'Sumut' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Sumut',\n",
    "                  'Sumbar' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Sumbar',\n",
    "                  'Riau' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Riau',\n",
    "                  'Jambi' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Jambi',\n",
    "                  'Sumsel' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Sumsel',\n",
    "                  'Bengkulu' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Bengkulu',\n",
    "                  'Lampung' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Lampung',\n",
    "                  'Banten' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Banten',\n",
    "                  'DKI' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_DKI',\n",
    "                  'Jabar' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Jabar',\n",
    "                  'Jateng' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Jateng',\n",
    "                  'DIY' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_DIY',\n",
    "                  'Jatim' :  r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Jatim',\n",
    "                  'Kalbar' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Kalbar',\n",
    "                  'Kalsel' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Kalsel',\n",
    "                  'Kalteng' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Kalteng',\n",
    "                  'Kaltim' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Kaltim',\n",
    "                  'Kaltara' : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Kaltara',\n",
    "                  'Sulbar'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Sulbar',\n",
    "                  'Sulsel'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Sulsel',\n",
    "                  'Sulteng'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Sulteng',\n",
    "                  'Sultra'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Sultra',\n",
    "                  'Sulut'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Sulut',\n",
    "                  'Gorontalo'  :   r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Gorontalo',\n",
    "                  'Papua'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Papua',\n",
    "                  'Papbar'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Papbar',\n",
    "                  'Papsel'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Papsel',\n",
    "                  'Papteng'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Papteng',\n",
    "                  'Papgun'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Papgun',\n",
    "                  'Papbarda'  : r'D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Titik_Grid_Papbarda',\n",
    "                  }\n",
    "\n",
    "\n",
    "pulau_merge = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Merge\"\n",
    "pulau_reference = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_All_Reference\"\n",
    "pulau_besar_merge = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\project_data_input.gdb\\Pulau_Besar_Merge\"\n",
    "fgdb_temp = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp5.gdb\"\n",
    "fgdb_input = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.gdb\"\n",
    "folder_csv = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\Folder_CSV\"\n",
    "\n",
    "mosaic_ch = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_CH\"\n",
    "mosaic_sh = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_SH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building processing class\n",
    "\n",
    "class Preprocessing():\n",
    "\n",
    "    def __init__(self, fgdb_temp):\n",
    "        self.fgdb_temp = fgdb_temp\n",
    "\n",
    "    \n",
    "    def Get_Excel(self, file_loc, output_name):\n",
    "        arcpy.conversion.ExcelToTable(\n",
    "            Input_Excel_File = file_loc,\n",
    "            Output_Table = os.path.join(self.fgdb_temp, output_name),\n",
    "            Sheet = \"Sheet 1\",\n",
    "            field_names_row = 1,\n",
    "            cell_range=\"\"\n",
    "        )\n",
    "\n",
    "        return os.path.join(self.fgdb_temp, output_name)\n",
    "    \n",
    "    def Excle_To_Feature(self, input_name, output_feature):\n",
    "        arcpy.management.XYTableToPoint(\n",
    "            in_table = input_name,\n",
    "            out_feature_class=output_feature,\n",
    "            x_field = \"LON\",\n",
    "            y_field = \"LAT\",\n",
    "            z_field = None,\n",
    "            coordinate_system = 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision'\n",
    "        )\n",
    "        \n",
    "        return output_feature\n",
    "    \n",
    "\n",
    "\n",
    "class Processing():\n",
    "    \n",
    "    def __init__(self, fgdb_temp, input_feature):\n",
    "        self.input_feature = input_feature\n",
    "        self.fgdb_temp = fgdb_temp\n",
    "    \n",
    "    def Interpolation_ACH(self, output_name, cell_size):\n",
    "        arcpy.ga.IDW(\n",
    "            in_features=self.input_feature,\n",
    "            z_field=\"CH\",\n",
    "            out_ga_layer=None,\n",
    "            out_raster=os.path.join(self.fgdb_temp, output_name),\n",
    "            cell_size=cell_size,\n",
    "            power=2,\n",
    "            search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12.2269298067831 S_MINOR=12.2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "            weight_field=None\n",
    "        )\n",
    "\n",
    "        return os.path.join(self.fgdb_temp, output_name)\n",
    "\n",
    "\n",
    "    def Interpolation_ASH(self, output_name, cell_size):\n",
    "        arcpy.ga.IDW(\n",
    "            in_features=self.input_feature,\n",
    "            z_field=\"SH%\",\n",
    "            out_ga_layer=None,\n",
    "            out_raster=os.path.join(self.fgdb_temp, output_name),\n",
    "            cell_size=cell_size,\n",
    "            power=2,\n",
    "            search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12.2269298067831 S_MINOR=12.2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "            weight_field=None\n",
    "            )\n",
    "        \n",
    "        return os.path.join(self.fgdb_temp, output_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACH Interpolation\n",
    "\n",
    "def get_excel(output_name, file_loc, output_location):\n",
    "    arcpy.conversion.ExcelToTable(\n",
    "    Input_Excel_File=file_loc,\n",
    "    Output_Table= os.path.join(fgdb_temp+\"/\"+output_name),\n",
    "    Sheet=\"Sheet 1\",\n",
    "    field_names_row=1,\n",
    "    cell_range=\"\"\n",
    ")\n",
    "    \n",
    "def excel_toXY(table_name, output_feature):\n",
    "    arcpy.management.XYTableToPoint(\n",
    "    in_table=os.path.join(fgdb_temp+\"/\"+output_name),\n",
    "    out_feature_class=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.gdb\\BlendGSMAP_POS_ExcelToTable_XY\",\n",
    "    x_field=\"LON\",\n",
    "    y_field=\"LAT\",\n",
    "    z_field=None,\n",
    "    coordinate_system='GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision'\n",
    ")\n",
    "    \n",
    "\n",
    "def interpolation_ach():\n",
    "    arcpy.ga.IDW(\n",
    "    in_features=\"BlendGSMAP_POS_Point\",\n",
    "    z_field=\"CH\",\n",
    "    out_ga_layer=None,\n",
    "    out_raster=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.gdb\\raster_CH\",\n",
    "    cell_size=0.005,\n",
    "    power=2,\n",
    "    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "    weight_field=None\n",
    ")\n",
    "    \n",
    "\n",
    "def interpolation_ash():\n",
    "    arcpy.ga.IDW(\n",
    "    in_features=\"BlendGSMAP_POS_Point\",\n",
    "    z_field=\"SH%\",\n",
    "    out_ga_layer=None,\n",
    "    out_raster=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.gdb\\raster_CH\",\n",
    "    cell_size=0.005,\n",
    "    power=2,\n",
    "    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "    weight_field=None\n",
    ")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.parallelProcessingFactor = \"50%\"\\\n",
    "\n",
    "\n",
    "ACH_to_merge = []\n",
    "ASH_to_merge = []\n",
    "CSV_to_merge = []\n",
    "\n",
    "\n",
    "with arcpy.da.SearchCursor(pulau_reference, [[\"Pulau_Singkat\", [\"Is_Besar\"]]]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "        try:\n",
    "            if r[1] == \"False\":  # val False = Pulau Kecil dan va True = Pulau Besar\n",
    "                pulau_kecil = r[0]\n",
    "                print(f\"Memulai Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "\n",
    "                ####### Proses untuk kategori pulau kecil\\\n",
    "                ####### Proses ACH untuk kategori pulau kecil\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features=os.path.join(fgdb_input, \"BlendGSMAP_POS_Point\"),\n",
    "                        z_field=\"CH\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(fgdb_temp, f\"Interpolasi_ACH_{pulau_kecil}_{year}{month}\"),\n",
    "                        cell_size=gridsize_pkecil,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "                raster_ach_pk = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ACH_{pulau_kecil}_{year}{month}\"))\n",
    "\n",
    "                print(f\"Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "                print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "                arcpy.management.AddRastersToMosaicDataset(\n",
    "                                in_mosaic_dataset= mosaic_ch,\n",
    "                                raster_type=\"Raster Dataset\",\n",
    "                                input_path= raster_ach_pk,\n",
    "                                update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                                update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                                update_overviews=\"NO_OVERVIEWS\",\n",
    "                                maximum_pyramid_levels=None,\n",
    "                                maximum_cell_size=0,\n",
    "                                minimum_dimension=1500,\n",
    "                                spatial_reference=None,\n",
    "                                filter=\"\",\n",
    "                                sub_folder=\"SUBFOLDERS\",\n",
    "                                duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                                build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                                calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                                build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                                operation_description=\"\",\n",
    "                                force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                                estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                                aux_inputs=None,\n",
    "                                enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                                cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "                print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai ...\")\n",
    "                titik_grid_extract_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}\")\n",
    "                arcpy.management.CopyFeatures(in_features=titik_grid[pulau_kecil], out_feature_class=titik_grid_extract_pk)\n",
    "                point_extracted_pk = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pk, [[raster_ach_pk, \"CH\"]], \"NONE\")\n",
    "                # point_extracted_ch.save()\n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} selesai\")\n",
    "\n",
    "                \n",
    "\n",
    "                print(f\"Proses Reclassify ACH Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                out_raster_ach_pk = arcpy.sa.Reclassify(\n",
    "                      in_raster=raster_ach_pk,\n",
    "                      reclass_field=\"VALUE\",\n",
    "                      remap=\"0 20 1;20 50 2;50 100 3;100 150 4;150 200 5;200 300 6;300 400 7;400 500 8;500 10000 9\",\n",
    "                      missing_values=\"DATA\")\n",
    "                \n",
    "                out_raster_ach_pk.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{pulau_kecil}_{year}{month}\"))\n",
    "                print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                Output_polygon_features_ach = os.path.join(fgdb_temp, f\"Polygon_ACH_{pulau_kecil}_{year}{month}\")\n",
    "                arcpy.conversion.RasterToPolygon(in_raster=out_raster_ach_pk, out_polygon_features=Output_polygon_features_ach)\n",
    "                arcpy.management.AddFields(in_table=Output_polygon_features_ach, field_description= \"CH TEXT # 255 # #;Kategori TEXT # 255 # #\")\n",
    "                arcpy.management.CalculateField(\n",
    "                            in_table=Output_polygon_features_ach,\n",
    "                            field=\"CH\",\n",
    "                            expression=\"ch(!gridcode!)\",\n",
    "                            expression_type=\"PYTHON3\",\n",
    "                            code_block=\"\"\"def ch(x):\n",
    "                            if x == 1:\n",
    "                                return \"0-20\"\n",
    "                            elif x == 2:\n",
    "                                return \"21-50\"\n",
    "                            elif x == 3:\n",
    "                                return \"51-100\"\n",
    "                            elif x == 4:\n",
    "                                return \"101-150\"\n",
    "                            elif x == 5:\n",
    "                                return \"151-200\"\n",
    "                            elif x == 6:\n",
    "                                return \"201-300\"\n",
    "                            elif x == 7:\n",
    "                                return \"301-400\"\n",
    "                            elif x == 8:\n",
    "                                return \"401-500\"\n",
    "                            elif x ==9 :\n",
    "                                return \">500\"\n",
    "                            \"\"\",\n",
    "                            field_type=\"TEXT\",\n",
    "                            enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                arcpy.management.CalculateField(\n",
    "                            in_table=Output_polygon_features_ach,\n",
    "                            field=\"Kategori\",\n",
    "                            expression=\"cat(!gridcode!)\",\n",
    "                            expression_type=\"PYTHON3\",\n",
    "                            code_block=\"\"\"def cat(x):\n",
    "                            if x == 1:\n",
    "                                return \"Rendah\"\n",
    "                            elif x == 2:\n",
    "                                return \"Rendah\"\n",
    "                            elif x == 3:\n",
    "                                return \"Rendah\"\n",
    "                            elif x == 4:\n",
    "                                return \"Menengah\"\n",
    "                            elif x == 5:\n",
    "                                return \"Menengah\"\n",
    "                            elif x == 6:\n",
    "                                return \"Menengah\"\n",
    "                            elif x == 7:\n",
    "                                return \"Tinggi\"\n",
    "                            elif x == 8:\n",
    "                                return \"Sangat Tinggi\"\n",
    "                            elif x ==9 :\n",
    "                                return \"Sangat Tinggi\"\n",
    "                            \"\"\",\n",
    "                            field_type=\"TEXT\",\n",
    "                            enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                # Menggabungkan polygon untuk di merge\n",
    "                ACH_to_merge.append(Output_polygon_features_ach)\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "                ####### Proses ASH untuk kategori pulau kecil\n",
    "                print(f\"Memulai Proses Interpolasi ASH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features=os.path.join(fgdb_input, \"BlendGSMAP_POS_Point\"),\n",
    "                        z_field=\"SH_\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(fgdb_temp, f\"interpolasi_ASH_{pulau_kecil}_{year}{month}\"),\n",
    "                        cell_size=gridsize_pkecil,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "\n",
    "                raster_ash_pk = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ACH_{pulau_kecil}_{year}{month}\"))\n",
    "                print(f\"Proses Interpolasi ASH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "                print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "                arcpy.management.AddRastersToMosaicDataset(\n",
    "                                in_mosaic_dataset= mosaic_sh,\n",
    "                                raster_type=\"Raster Dataset\",\n",
    "                                input_path= raster_ash_pk,\n",
    "                                update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                                update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                                update_overviews=\"NO_OVERVIEWS\",\n",
    "                                maximum_pyramid_levels=None,\n",
    "                                maximum_cell_size=0,\n",
    "                                minimum_dimension=1500,\n",
    "                                spatial_reference=None,\n",
    "                                filter=\"\",\n",
    "                                sub_folder=\"SUBFOLDERS\",\n",
    "                                duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                                build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                                calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                                build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                                operation_description=\"\",\n",
    "                                force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                                estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                                aux_inputs=None,\n",
    "                                enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                                cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_SH\")\n",
    "                print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "                \n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai . . .\")\n",
    "                point_extracted_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}\")\n",
    "                arcpy.sa.ExtractMultiValuesToPoints(point_extracted_pk, [[raster_ash_pk, \"SH\"]], \"NONE\")\n",
    "                # point_extracted_sh.save()\n",
    "                arcpy.management.AddFields(in_table=point_extracted_pk, field_description=[[\"LAT\", \"DOUBLE\", \"Latitude\", \"\", \"\", \"\"], [\"LONG\", \"DOUBLE\", \"Longitude\", \"\", \"\", \"\"]])[0]\n",
    "                arcpy.management.CalculateGeometryAttributes(in_features=point_extracted_pk, geometry_property=[[\"LAT\", \"POINT_Y\"], [\"LONG\", \"POINT_X\"]], coordinate_system=\"PROJCS[\\\"WGS_1984_Web_Mercator_Auxiliary_Sphere\\\",GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Mercator_Auxiliary_Sphere\\\"],PARAMETER[\\\"False_Easting\\\",0.0],PARAMETER[\\\"False_Northing\\\",0.0],PARAMETER[\\\"Central_Meridian\\\",0.0],PARAMETER[\\\"Standard_Parallel_1\\\",0.0],PARAMETER[\\\"Auxiliary_Sphere_Type\\\",0.0],UNIT[\\\"Meter\\\",1.0]]\", \n",
    "                                                                         coordinate_format=\"DD\")[0]\n",
    "                print(f\"Proses Extract Point Provinsi: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Export to csv Provinsi: {pulau_kecil} dimulai . . .\")\n",
    "                out_csv_table_pk = os.path.join(folder_csv, f\"Export_csv_ash_{pulau_kecil}_{year}0{month}.csv\")\n",
    "                arcpy.conversion.ExportTable(\n",
    "                                in_table= point_extracted_pk,\n",
    "                                out_table= out_csv_table_pk,\n",
    "                                where_clause=\"\",\n",
    "                                use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "                                field_mapping=None,\n",
    "                                sort_field=None)\n",
    "                \n",
    "                # Menggabungkan csv untuk di merge\n",
    "                CSV_to_merge.append(out_csv_table_pk)\n",
    "                print(f\"Proses Export to csv Provinsi: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "                print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                out_raster_ash_pk = arcpy.sa.Reclassify(\n",
    "                      in_raster=raster_ash_pk,\n",
    "                      reclass_field=\"VALUE\",\n",
    "                      remap=\"0 30 1;30 50 2;50 84 3;84 115 4;115 150 5;150 200 6;200 10000 7\",\n",
    "                      missing_values=\"DATA\")\n",
    "                \n",
    "                out_raster_ash_pk.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{pulau_kecil}_{year}{month}\"))\n",
    "                print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                Output_polygon_features_ash = os.path.join(fgdb_temp, f\"Polygon_ASH_{pulau_kecil}_{year}{month}\")\n",
    "                arcpy.conversion.RasterToPolygon(in_raster=out_raster_ash_pk, out_polygon_features=Output_polygon_features_ash)\n",
    "                arcpy.management.AddFields(in_table=Output_polygon_features_ash, field_description= \"SH TEXT # 255 # #;Kategori TEXT # 255 # #\")\n",
    "                arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"SH\",\n",
    "                                        expression=\"sh(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def sh(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"0-30\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"31-50\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"51-84\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"85-115\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"116-150\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"151-200\"\n",
    "                                        elif x == 7:\n",
    "                                            return \">200\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"Kategori\",\n",
    "                                        expression=\"kategori(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def kategori(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"Normal\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                \n",
    "                # menggabungkan polygon untuk di merge\n",
    "                ASH_to_merge.append(Output_polygon_features_ash)\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "            ####### Proses untuk kategori pulau besar\n",
    "            ####### Proses ACH Pulau Besar\n",
    "            else:\n",
    "                pulau_besar = r[0]\n",
    "                print(f\"Memulai Proses Interpolasi ACH Pulau Besar: {pulau_besar} . . .\")\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_besar], mask=pulau_feature[pulau_besar]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features=os.path.join(fgdb_input, \"BlendGSMAP_POS_Point\"),\n",
    "                        z_field=\"CH\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(fgdb_temp, f\"interpolasi_ACH_Pulau_{pulau_besar}_{year}{month}\"),\n",
    "                        cell_size=gridsize_pbesar,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "                raster_ach_pb = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ACH_Pulau_{pulau_besar}_{year}{month}\"))\n",
    "                print(f\"Proses Interpolasi ACH Pulau Besar: {pulau_besar} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "                ######### Proses Masking ACH\n",
    "                print(f\"Proses Masking ACH Pulau Besar: {pulau_besar} dimulai . . .\")\n",
    "                with arcpy.da.SearchCursor(pulau_besar_merge, [[\"Pulau\", [\"Provinsi_Singkat\"]]]) as masks:\n",
    "                    for r in masks:\n",
    "                        pulau_mask = r[0]\n",
    "                        provinsi = r[1]\n",
    "                        if pulau_mask == pulau_besar:\n",
    "                            print(f\"Memulai Mask Provinsi: {provinsi}  . . .\")\n",
    "                            Extract_rast_ch = os.path.join(fgdb_temp, f\"ACH_{provinsi}_{year}{month}\")\n",
    "                            Extract_by_Mask = Extract_rast_ch\n",
    "                            Extract_rast_ch = arcpy.sa.ExtractByMask(raster_ach_pb, pulau_feature[provinsi], \"INSIDE\", extent_pulau[provinsi])\n",
    "                            Extract_rast_ch.save(Extract_by_Mask)\n",
    "                            print(f\"Proses Mask Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "                            \n",
    "                            print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} dimulai . . .. \")\n",
    "                            arcpy.management.AddRastersToMosaicDataset(\n",
    "                                in_mosaic_dataset= mosaic_ch,\n",
    "                                raster_type=\"Raster Dataset\",\n",
    "                                input_path= Extract_rast_ch,\n",
    "                                update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                                update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                                update_overviews=\"NO_OVERVIEWS\",\n",
    "                                maximum_pyramid_levels=None,\n",
    "                                maximum_cell_size=0,\n",
    "                                minimum_dimension=1500,\n",
    "                                spatial_reference=None,\n",
    "                                filter=\"\",\n",
    "                                sub_folder=\"SUBFOLDERS\",\n",
    "                                duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                                build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                                calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                                build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                                operation_description=\"\",\n",
    "                                force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                                estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                                aux_inputs=None,\n",
    "                                enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                                cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "                            print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} selesai \")\n",
    "\n",
    "\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} dimulai ...\")\n",
    "                            titik_grid_extract_pb = os.path.join(fgdb_temp, f\"Titik_extract_{provinsi}_{year}{month}\")\n",
    "                            arcpy.management.CopyFeatures(in_features=titik_grid[provinsi], out_feature_class=titik_grid_extract_pb)\n",
    "                            point_extracted_pb = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pb, [[Extract_rast_ch, \"CH\"]], \"NONE\")\n",
    "                            # point_extracted_ch.save()\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Memulai Reclassify Provinsi: {provinsi}  . . .\")\n",
    "                            out_raster_ach_pb = arcpy.sa.Reclassify(in_raster=Extract_rast_ch,\n",
    "                                                             reclass_field=\"VALUE\",\n",
    "                                                             remap=\"0 20 1;20 50 2;50 100 3;100 150 4;150 200 5;200 300 6;300 400 7;400 500 8;500 10000 9\",\n",
    "                                                             missing_values=\"DATA\")\n",
    "                            \n",
    "                            out_raster_ach_pb.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{provinsi}_{year}{month}\"))\n",
    "                            print(f\"Proses Reclassify Provinsi: {provinsi} telah selesai\")\n",
    "                        \n",
    "\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} dimulai . . . . . . . . . . . .\")\n",
    "                            Output_polygon_features_ach = os.path.join(fgdb_temp, f\"Polygon_ACH_{provinsi}_{year}{month}\")\n",
    "                            arcpy.conversion.RasterToPolygon(in_raster=out_raster_ach_pb, out_polygon_features=Output_polygon_features_ach)\n",
    "                            arcpy.management.AddFields(in_table=Output_polygon_features_ach, field_description= \"CH TEXT # 255 # #;Kategori TEXT # 255 # #\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ach,\n",
    "                                        field=\"CH\",\n",
    "                                        expression=\"ch(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def ch(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"0-20\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"21-50\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"51-100\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"101-150\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"151-200\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"201-300\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"301-400\"\n",
    "                                        elif x == 8:\n",
    "                                            return \"401-500\"\n",
    "                                        elif x ==9 :\n",
    "                                            return \">500\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ach,\n",
    "                                        field=\"Kategori\",\n",
    "                                        expression=\"cat(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def cat(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"Rendah\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"Rendah\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"Rendah\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"Menengah\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"Menengah\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"Menengah\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"Tinggi\"\n",
    "                                        elif x == 8:\n",
    "                                            return \"Sangat Tinggi\"\n",
    "                                        elif x ==9 :\n",
    "                                            return \"Sangat Tinggi\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                            \n",
    "                            # Menggabungkan polygon untuk di merge\n",
    "                            ACH_to_merge.append(Output_polygon_features_ach)\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} telah selesai\")\n",
    "                            print(\"\\n\")\n",
    "\n",
    "                            \n",
    "\n",
    "\n",
    "                ####### Proses ASH Pulau Besar\n",
    "                ####### Proses Interpolasi ASH\n",
    "                print(f\"Memulai Proses Interpolasi ASH Pulau Besar: {pulau_besar}\")\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_besar], mask=pulau_feature[pulau_besar]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features=os.path.join(fgdb_input, \"BlendGSMAP_POS_Point\"),\n",
    "                        z_field=\"SH_\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(fgdb_temp, f\"interpolasi_ASH_Pulau_{pulau_besar}_{year}{month}\"),\n",
    "                        cell_size=gridsize_pbesar,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "\n",
    "                raster_ash = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ASH_Pulau_{pulau_besar}_{year}{month}\"))\n",
    "                print(f\"Proses Interpolasi ASH Pulau Besar: {pulau_besar} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "                ######### Proses Masking ASH\n",
    "                print(f\"Proses Masking ASH Pulau Besar: {pulau_besar} dimulai . . .\")\n",
    "                with arcpy.da.SearchCursor(pulau_besar_merge, [[\"Pulau\", [\"Provinsi_Singkat\"]]]) as masks:\n",
    "                    for r in masks:\n",
    "                        pulau_mask = r[0]\n",
    "                        provinsi = r[1]\n",
    "                        if pulau_mask == pulau_besar:\n",
    "                            print(f\"Memulai Mask ASH Provinsi: {provinsi}  . . .\")\n",
    "                            Extract_rast_sh = os.path.join(fgdb_temp, f\"ASH_{provinsi}_{year}{month}\")\n",
    "                            Extract_by_Mask = Extract_rast_sh\n",
    "                            Extract_rast_sh = arcpy.sa.ExtractByMask(raster_ash, pulau_feature[provinsi], \"INSIDE\", extent_pulau[provinsi])\n",
    "                            Extract_rast_sh.save(Extract_by_Mask)\n",
    "                            print(f\"Proses Mask Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} dimulai . . .\")\n",
    "                            point_extracted_pb = os.path.join(fgdb_temp, f\"Titik_extract_{provinsi}_{year}{month}\")\n",
    "                            arcpy.sa.ExtractMultiValuesToPoints(point_extracted_pb, [[Extract_rast_sh, \"SH\"]], \"NONE\")\n",
    "                            arcpy.management.AddFields(in_table=point_extracted_pb, field_description=[[\"LAT\", \"DOUBLE\", \"Latitude\", \"\", \"\", \"\"], [\"LONG\", \"DOUBLE\", \"Longitude\", \"\", \"\", \"\"]])[0]\n",
    "                            arcpy.management.CalculateGeometryAttributes(in_features=point_extracted_pb, geometry_property=[[\"LAT\", \"POINT_Y\"], [\"LONG\", \"POINT_X\"]],coordinate_system=\"PROJCS[\\\"WGS_1984_Web_Mercator_Auxiliary_Sphere\\\",GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Mercator_Auxiliary_Sphere\\\"],PARAMETER[\\\"False_Easting\\\",0.0],PARAMETER[\\\"False_Northing\\\",0.0],PARAMETER[\\\"Central_Meridian\\\",0.0],PARAMETER[\\\"Standard_Parallel_1\\\",0.0],PARAMETER[\\\"Auxiliary_Sphere_Type\\\",0.0],UNIT[\\\"Meter\\\",1.0]]\", \n",
    "                                                                         coordinate_format=\"DD\")[0]\n",
    "                            # point_extracted_sh.save()\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} selesai\")\n",
    "\n",
    "                            print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} dimulai . . .. \")\n",
    "                            arcpy.management.AddRastersToMosaicDataset(\n",
    "                                in_mosaic_dataset= mosaic_sh,\n",
    "                                raster_type=\"Raster Dataset\",\n",
    "                                input_path= Extract_rast_sh,\n",
    "                                update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                                update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                                update_overviews=\"NO_OVERVIEWS\",\n",
    "                                maximum_pyramid_levels=None,\n",
    "                                maximum_cell_size=0,\n",
    "                                minimum_dimension=1500,\n",
    "                                spatial_reference=None,\n",
    "                                filter=\"\",\n",
    "                                sub_folder=\"SUBFOLDERS\",\n",
    "                                duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                                build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                                calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                                build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                                operation_description=\"\",\n",
    "                                force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                                estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                                aux_inputs=None,\n",
    "                                enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                                cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_SH\")\n",
    "                            print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} selesai \")\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Proses Export to csv Provinsi: {provinsi} dimulai . . .\")\n",
    "                            out_csv_table_pb = os.path.join(folder_csv, f\"Export_csv_{provinsi}_{year}0{month}.csv\")\n",
    "                            arcpy.conversion.ExportTable(\n",
    "                                in_table= point_extracted_pb,\n",
    "                                out_table= out_csv_table_pb,\n",
    "                                where_clause=\"\",\n",
    "                                use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "                                field_mapping=None,\n",
    "                                sort_field=None)\n",
    "                            \n",
    "                            # Menggabungkan ke dalam list csv untuk di merge\n",
    "                            CSV_to_merge.append(out_csv_table_pb)\n",
    "                            print(f\"Proses Export to csv Provinsi: {provinsi} selesai\")\n",
    "                            \n",
    "\n",
    "\n",
    "                            print(f\"Memulai Reclassify Provinsi: {provinsi}  . . .\")\n",
    "                            out_raster_ash_pb = arcpy.sa.Reclassify(in_raster=Extract_rast_sh,\n",
    "                                                             reclass_field=\"VALUE\",\n",
    "                                                             remap=\"0 30 1;30 50 2;50 84 3;84 115 4;115 150 5;150 200 6;200 10000 7\",\n",
    "                                                             missing_values=\"DATA\")\n",
    "                            \n",
    "                            out_raster_ash_pb.save(os.path.join(fgdb_temp, f\"Reclass_ASH_{provinsi}_{year}{month}\"))\n",
    "                            print(f\"Proses Reclassify Provinsi: {provinsi} telah selesai\")\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} dimulai . . . . . . . . . . . .\")\n",
    "                            Output_polygon_features_ash = os.path.join(fgdb_temp, f\"Polygon_ASH_{provinsi}_{year}{month}\")\n",
    "                            arcpy.conversion.RasterToPolygon(in_raster=out_raster_ash_pb, out_polygon_features=Output_polygon_features_ash)\n",
    "                            arcpy.management.AddFields(in_table=Output_polygon_features_ash, field_description= \"SH TEXT # 255 # #;Kategori TEXT # 255 # #\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"SH\",\n",
    "                                        expression=\"sh(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def sh(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"0-30\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"31-50\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"51-84\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"85-115\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"116-150\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"151-200\"\n",
    "                                        elif x == 7:\n",
    "                                            return \">200\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"Kategori\",\n",
    "                                        expression=\"kategori(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def kategori(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"Normal\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                            \n",
    "                            # Menggabungkan output polygon untuk di merge\n",
    "                            ASH_to_merge.append(Output_polygon_features_ash)\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} telah selesai\")\n",
    "                            print(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred with island {r[0]}: {e}\")\n",
    "            continue  # Skip to the next island\n",
    "\n",
    "\n",
    "\n",
    "# Proses se Indonesia\n",
    "\n",
    "print(\"Proses Update Mosaic Dataset ACH: Indonesia dimulai . . .\")\n",
    "# Re-Calculate Statistic Mosaic Dataset\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_CH\",\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\",\n",
    "    area_of_interest=r\"in_memory\\feature_set1\")\n",
    "print(\"Proses Update Mosaic Dataset ACH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Proses Update Mosaic Dataset ASH: Indonesia dimulai . . .\")\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_SH\",\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\",\n",
    "    area_of_interest=r\"in_memory\\feature_set1\")\n",
    "print(\"Proses Update Mosaic Dataset ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Proses Merge Polygon ACH dan ASH: Indonesia dimulai . . .\")\n",
    "# Merge polygon menjadi se Indonesia\n",
    "arcpy.management.Merge(ACH_to_merge, os.path.join(fgdb_temp, f\"Polygon_ACH_Indonesia_{year}0{month}\"))\n",
    "\n",
    "arcpy.management.Merge(ASH_to_merge, os.path.join(fgdb_temp, f\"Polygon_ASH_Indonesia_{year}0{month}\"))\n",
    "print(\"Proses Merge Polygon ACH dan ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Proses Merge CSV ACH dan ASH: Indonesia dimulai . . .\")\n",
    "# Merge csv se Indonesia\n",
    "combined_df = pd.DataFrame()\n",
    "for file in CSV_to_merge:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file, delimiter=';')\n",
    "    # Append the DataFrame to the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "combined_df.to_csv(os.path.join(folder_csv, f\"Export_csv_Indonesia_{year}0{month}.csv\"), index=False)\n",
    "print(\"Proses Merge CSV ACH dan ASH: Indonesia selesai\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ACH_to_merge:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for file in ASH_to_merge:\n",
    "    x += 1\n",
    "    print(file)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for file in CSV_to_merge:\n",
    "    x += 1\n",
    "    print(file)\n",
    "    print((x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reporting\n",
    "# Funtion for Map\n",
    "\n",
    "def map1_pusat(aprx_path = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.aprx\", layout_name = \"peta_1_pusat\", output_location = r'D:\\Project\\BMKG SiPinter Iklim\\Map', output_name= 'map_pusat1.jpg'):\n",
    "    aprx_path = aprx_path\n",
    "    aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "    \n",
    "    layout_map1_pusat = aprx.listLayouts(layout_name)[0]  # Adjust \"Layout\" to match your layout's name\n",
    "    \n",
    "    # List all elements in the layout \n",
    "    elements = layout_map1_pusat.listElements()\n",
    "    \n",
    "    # Print the names of all element\n",
    "    print(\"Print Peta 1 Indonesia dimulai . . .\")\n",
    "    for element in elements:\n",
    "        if element.name == 'ash_bln':\n",
    "            element.text = element.text.replace('[BULAN]', f'{current_month_name}')\n",
    "        elif element.name == 'ash_thn':\n",
    "            element.text = element.text.replace('[TAHUN]', f'{current_year}')\n",
    "        elif element.name == 'ach_bln':\n",
    "            element.text = element.text.replace('[BULAN]', f'{current_month_name}')\n",
    "        elif element.name == 'ach_thn':\n",
    "            element.text = element.text.replace('[TAHUN]', f'{current_year}')\n",
    "            \n",
    "    layout_map1_pusat.exportToJPEG(os.path.join(output_location, output_name), resolution=300)\n",
    "    print(\"Print Peta 1 Indonesia selesai\")\n",
    "\n",
    "\n",
    "def map2_pusat(aprx_path = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.aprx\", layout_name = \"peta_2_pusat\", output_location = r'D:\\Project\\BMKG SiPinter Iklim\\Map', output_name= 'map_pusat2.jpg'):\n",
    "    aprx_path = aprx_path\n",
    "    aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "\n",
    "\n",
    "    layout_map2_pusat = aprx.listLayouts(layout_name)[0]  # Adjust \"Layout\" to match your layout's name\n",
    "    \n",
    "    # List all elements in the layout\n",
    "    elements = layout_map2_pusat.listElements()\n",
    "\n",
    "    # Print the names of all elements\n",
    "    print(\"Print Peta 2 Indonesia dimulai . . .\")\n",
    "    for element in elements:\n",
    "        if element.name == 'ash_wkt':\n",
    "            element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "        elif element.name == 'ach_wkt':\n",
    "            element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "        elif element.name == 'tgl_mut_ash':\n",
    "            element.text = element.text.replace('[tanggal]', f'{current_date_time} WIB')\n",
    "        elif element.name == 'tgl_mut_ach':\n",
    "            element.text = element.text.replace('[tanggal]', f'{current_date_time} WIB')\n",
    "\n",
    "    layout_map2_pusat.exportToJPEG(os.path.join(output_location, output_name), resolution=300)\n",
    "    print(\"Print Peta 2 Indonesia selesai\")\n",
    "\n",
    "\n",
    "def infog_laporan_pusat(tipe= 'Analisa Curah Hujan'):\n",
    "    \n",
    "    print(\"Proses Pembuatan Infografis dan Laporan Singkat dimulai . . .\")\n",
    "\n",
    "    if tipe == \"Analisa Curah Hujan\":\n",
    "        feature = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.gdb\\Polygon_ACH_Indonesia__ProvUBesar\" ####### NANTI SESUAIKAN DENGAN PROSES PENGOLAHAN DATA\n",
    "        tipe_name = 'ach'\n",
    "        sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "\n",
    "        data = sdf2[['Kategori', 'WADMPR', 'Pulau_B', 'area']]\n",
    "\n",
    "        \n",
    "        # Proses statistik wilayah Indonesia\n",
    "\n",
    "        sum_area = data['area'].sum()\n",
    "        cat_df = data.groupby('Kategori')['area'].sum()\n",
    "        indo_df = round(cat_df / sum_area, 4)\n",
    "        indo_df = indo_df.reset_index()\n",
    "        indo_df = indo_df.rename({'area' : 'Persentase',}, axis='columns')\n",
    "        indo_df['Persentase'] = round(indo_df['Persentase']*100,2)\n",
    "        indo_df['Persentase%'] = round(indo_df['Persentase'],2).astype(str) + '%'\n",
    "        indo_df.drop(indo_df.index[0], inplace=True)\n",
    "        indo_df[\"Pulau_B\"] = 'Indonesia'\n",
    "        indo_df_pivot = pd.pivot(indo_df, index='Pulau_B', columns='Kategori', values='Persentase')\n",
    "        indo_df_pivot = indo_df_pivot.reset_index()\n",
    "        indo_df_pivot.columns.name = None\n",
    "\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah wilayah Provinsi\n",
    "        province_area_sum = data.groupby('WADMPR')['area'].sum()\n",
    "        cat_df2 = data.groupby(['Kategori','WADMPR'])['area'].sum()\n",
    "        prov_df = round(cat_df2 / province_area_sum, 4)\n",
    "        prov_df = prov_df.reset_index()\n",
    "        prov_df = prov_df[(prov_df['Kategori'] != \"\") & (prov_df['area'] != 0)]\n",
    "        prov_df['Persentase%'] = round(prov_df['area']*100,2).astype(str) + '%'\n",
    "\n",
    "        top_13_areas = prov_df.groupby('Kategori').apply(lambda x: x.nlargest(13, 'area')).reset_index(drop=True)\n",
    "        wadmpr_by_kategori = top_13_areas.groupby('Kategori')['WADMPR'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "        sgt_tinggi = indo_df.loc[indo_df['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "        tinggi = indo_df.loc[indo_df['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "        rendah = indo_df.loc[indo_df['Kategori'] == 'Rendah', 'Persentase'].values[0]\n",
    "        menengah =  indo_df.loc[indo_df['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah Pulau Besar\n",
    "        pulau_area_sum = data.groupby('Pulau_B')['area'].sum()\n",
    "        cat_df3 = data.groupby(['Kategori','Pulau_B'])['area'].sum()\n",
    "        pulau_df = round(cat_df3 / pulau_area_sum, 4)\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df = pulau_df[(pulau_df['Kategori'] != \"\") & (pulau_df['area'] != 0)]\n",
    "        pulau_df['Persentase'] = round(pulau_df['area']*100, 2)\n",
    "        pulau_df = pd.pivot(pulau_df, index='Pulau_B', columns='Kategori', values='Persentase')\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df.columns.name = None\n",
    "        pulau_df.drop(pulau_df.index[0], inplace=True)\n",
    "        pulau_df = pd.concat([indo_df_pivot, pulau_df], ignore_index=True)\n",
    "        pulau_df.iloc[:, 1:] = pulau_df.iloc[:, 1:].div(pulau_df.iloc[:, 1:].sum(axis=1), axis=0) * 100\n",
    "        pulau_df.iloc[:, 1:] = pulau_df.iloc[:, 1:].round(2)\n",
    "        pulau_df = pulau_df.rename(columns={'Pulau_B': 'Wilayah', 'Rendah': 'Rendah (%)', 'Menengah': 'Menengah (%)','Tinggi': 'Tinggi (%)', 'Sangat Tinggi': 'Sangat Tinggi (%)'})\n",
    "        new_order = ['Wilayah', 'Rendah (%)', 'Menengah (%)', 'Tinggi (%)', 'Sangat Tinggi (%)']\n",
    "        pulau_df = pulau_df[new_order]\n",
    "        \n",
    "\n",
    "        # Proses pembuatan chart infografis\n",
    "        import plotly.io as pio\n",
    "\n",
    "        fig = px.bar(indo_df, x='Kategori', y='Persentase', width=800, height=400, text='Persentase%')\n",
    "        fig.update_xaxes(categoryorder='array', categoryarray= ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi'])\n",
    "        fig.update_traces(marker_color=['#ffff00','#8e2800', '#00450c','#8bd48b' ], showlegend=False)\n",
    "        fig.update_layout(yaxis_range=[0,100], xaxis_title=f'{tipe}',)\n",
    "        fig.update_traces(width=0.95)\n",
    "        fig.update_xaxes(visible=False, showticklabels=False)\n",
    "        fig.update_traces(textposition='inside', textfont=dict(size=16, family='Arial Black', color='black'), insidetextanchor='middle')\n",
    "        fig.update_traces(marker_line_color='black', marker_line_width=3.5, marker_line=dict(color='#fff', width=1), marker=dict(line_color='black'))\n",
    "\n",
    "        textpositions = []\n",
    "        for bar in fig.data[0].y:\n",
    "            if bar < 10:  # Adjust this threshold as needed\n",
    "                textpositions.append('outside')\n",
    "            else:\n",
    "                textpositions.append('inside')\n",
    "\n",
    "        fig.update_traces(textposition=textpositions, textfont=dict(size=16), insidetextanchor='middle')\n",
    "        fig.update_layout(\n",
    "            xaxis_title_font=dict(size=15, color='black', family=\"Arial\"),\n",
    "            yaxis_title_font=dict(size=18, color='black', family=\"Arial\"),\n",
    "            font=dict(size=14, color='black'),\n",
    "            plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot area background\n",
    "            paper_bgcolor='rgba(0,0,0,0)'  # Transparent paper background\n",
    "            )\n",
    "\n",
    "        fig.write_image(os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'ach_bar_chart_infog_indo.png'))\n",
    "\n",
    "\n",
    "        # PROSES PEMBUATAN INFOGRAFIS 1\n",
    "        print(\"Pembuatan Infografis dimulai . . .\")\n",
    "        aprx_path = os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\", 'BMKG_SiPinter.aprx')\n",
    "        aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "        layout_infog_1 = aprx.listLayouts(\"infografis_ach_pusat_1\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements = layout_infog_1.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements:\n",
    "            if element.name == \"periode\":\n",
    "                element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"waktu\":\n",
    "                element.text = element.text.replace('[WAKTU]', f' {current_month_name} {current_year}')\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        # PROSES PEMBUATAN INFOGRAFIS 2\n",
    "\n",
    "        aprx_path = os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\", 'BMKG_SiPinter.aprx')\n",
    "        aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "        layout_infog_2 = aprx.listLayouts(\"infografis_ach_pusat_2\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements = layout_infog_2.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements:\n",
    "            if element.name == 'chart':\n",
    "                    element.sourceImage = element.sourceImage.replace((os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'({tipe_name}_bar_chart_infog_indo.png)')), \n",
    "                                                                    (os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'({tipe_name}_bar_chart_infog_indo.png)'))) \n",
    "            elif element.name == \"waktu_update\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"waktu_ach\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"periode_ash\":\n",
    "                element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"deskripsi\":\n",
    "                element.text = element.text.replace('[REN]', f'{rendah}')\n",
    "                element.text = element.text.replace('[MNG]', f'{menengah}')\n",
    "                element.text = element.text.replace('[TIN]', f'{tinggi}')\n",
    "                element.text = element.text.replace('[STI]', f'{sgt_tinggi}')\n",
    "            elif element.name == \"area_ren\":\n",
    "                element.text = element.text.replace('[WILAYAH RENDAH]', f\"{wadmpr_by_kategori['Rendah']}\")\n",
    "            elif element.name == \"area_mgh\":\n",
    "                element.text = element.text.replace('[WILAYAH MENENGAH]', f\"{wadmpr_by_kategori['Menengah']}\")\n",
    "            elif element.name == \"area_tin\":\n",
    "                element.text = element.text.replace('[WILAYAH TINGGI]', f\"{wadmpr_by_kategori['Tinggi']}\")\n",
    "            elif element.name == \"area_sti\":\n",
    "                element.text = element.text.replace('[WILAYAH SANGAT TINGGI]', f\"{wadmpr_by_kategori['Sangat Tinggi']}\")\n",
    "                \n",
    "        \n",
    "        temp_pdf1 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\temp', f'{tipe_name}_infografis_indo_1.pdf')\n",
    "        temp_pdf2 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\temp', f'{tipe_name}_infografis_indo_2.pdf')\n",
    "        layout_infog_1.exportToPDF(temp_pdf1, resolution=300)\n",
    "        layout_infog_2.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "        # Combine PDFs\n",
    "        pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Infografis', f'{tipe_name}_Infografis_indo_ver_{year}{month}.pdf'))\n",
    "        pdf_doc.appendPages(temp_pdf1)\n",
    "        pdf_doc.appendPages(temp_pdf2)\n",
    "        pdf_doc.saveAndClose()\n",
    "\n",
    "        os.remove(temp_pdf1)\n",
    "        os.remove(temp_pdf2)\n",
    "\n",
    "        print(\"Pembuatan Infografis selesai\")\n",
    "\n",
    "\n",
    "\n",
    "        # PEMBUATAN LAPORAN SINGKAT\n",
    "\n",
    "        print(\"Pembuatan Laporan Singkat dimulai . . .\")\n",
    "\n",
    "        # Create a figure and axis\n",
    "        fig, ax = plt.subplots(figsize=(10, 2))  # You can adjust the size\n",
    "        ax.axis('off')  # Hide the axes\n",
    "        # Create a table\n",
    "        table = ax.table(cellText=pulau_df.values, colLabels=pulau_df.columns, cellLoc='center', loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(15)  # Adjust the font size here\n",
    "        table.scale(1.5, 3.5)\n",
    "        for (i, j), cell in table.get_celld().items():\n",
    "            if i == 0:  # Header row\n",
    "                cell.set_text_props(weight='bold')\n",
    "            cell.set_width(0.28)\n",
    "        # Save the table as an image\n",
    "        plt.savefig(os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Tabel', f'{tipe_name}_dataframe_image.png'), bbox_inches='tight', pad_inches=0.5)\n",
    "\n",
    "\n",
    "        # Pembuatan Peta laporan \n",
    "\n",
    "        layout_peta_laporan = aprx.listLayouts(\"map_ach_laporan\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "        layout_peta_laporan.exportToJPEG(os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f\"map_{tipe_name}_laporan.jpg\"), resolution=300)\n",
    "\n",
    "\n",
    "        # Pembuatan chart laporan\n",
    "\n",
    "        regions = pulau_df['Wilayah']\n",
    "        rendah_val = pulau_df['Rendah (%)']\n",
    "        menengah_val = pulau_df['Menengah (%)']\n",
    "        tinggi_val = pulau_df['Tinggi (%)']\n",
    "        sangat_tinggi_val = pulau_df['Sangat Tinggi (%)']\n",
    "        threshold=3.5  # threshold untuk ukuran bar memiliki label\n",
    "\n",
    "        # Add text label\n",
    "        menengah_text = [f'{val:.2f}%' if val >= threshold else '' for val in menengah_val]\n",
    "        rendah_text = [f'{val:.2f}%' if val >= threshold else '' for val in rendah_val]\n",
    "        sangat_tinggi_text = [f'{val:.2f}%' if val >= threshold else '' for val in sangat_tinggi_val]\n",
    "        tinggi_text = [f'{val:.2f}%' if val >= threshold else '' for val in tinggi_val]\n",
    "\n",
    "        # Create the plot\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add traces\n",
    "        fig.add_trace(go.Bar(y=regions,\n",
    "            x=rendah_val,\n",
    "            name='Rendah (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#8e2800'),\n",
    "            text=rendah_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=menengah_val,\n",
    "            name='Menengah (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#eaff00'),\n",
    "            text=menengah_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=tinggi_val,\n",
    "            name='Tinggi (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#8bd48b'),\n",
    "            text=tinggi_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=sangat_tinggi_val,\n",
    "            name='Sangat Tinggi (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#00450c'),\n",
    "            text=sangat_tinggi_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        # Customize layout\n",
    "        fig.update_layout(\n",
    "            barmode='stack',\n",
    "            title=dict(\n",
    "                text=f'Distribusi {tipe} Indonesia dan Pulau Besar Indonesia',\n",
    "                font=dict(size=23, color='black', family='Arial Black') ),\n",
    "            xaxis=dict(title=dict(\n",
    "                    text='Persentase (%)',\n",
    "                    font=dict(size=14)  # Set the font size for the x-axis title\n",
    "                ),\n",
    "                tickfont=dict(size=14)),\n",
    "            yaxis=dict(\n",
    "                tickfont=dict(size=14)  # Set the font size for the y-axis ticks\n",
    "            ),\n",
    "            legend=dict(title=dict(\n",
    "                    text='Kategori',\n",
    "                    font=dict(size=14)), \n",
    "                x=0.5,\n",
    "                y=-0.1,\n",
    "                xanchor='center',\n",
    "                yanchor='top',\n",
    "                orientation='h',\n",
    "                font=dict(size=14)),\n",
    "            width=1000,  # Set the width of the figure\n",
    "            height=800,\n",
    "            plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot background\n",
    "            paper_bgcolor='rgba(0,0,0,0)' \n",
    "        )\n",
    "\n",
    "        # Show the plot\n",
    "        fig.show()\n",
    "\n",
    "        fig.write_image(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ach.png\")\n",
    "\n",
    "\n",
    "        # Pembuatan laporan singkat\n",
    "        layout_laporan1 = aprx.listLayouts(\"laporan_ach_pusat_1\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "        layout_laporan2 = aprx.listLayouts(\"laporan_ach_pusat_2\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements1 = layout_laporan1.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements1:\n",
    "            if element.name == \"bulan\":\n",
    "                element.text = element.text.replace('[BULAN]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"peta\":\n",
    "                element.sourceImage = element.sourceImage.replace(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\map_ach_laporan.jpg\", r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\map_ach_laporan.jpg\") \n",
    "            elif element.name == \"deskripsi\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "                element.text = element.text.replace('[STI]', f'{sgt_tinggi}')\n",
    "                element.text = element.text.replace('[TIN]', f'{tinggi}')\n",
    "                element.text = element.text.replace('[MNG]', f'{menengah}')\n",
    "                element.text = element.text.replace('[REN]', f'{rendah}')\n",
    "                element.text = element.text.replace('[WILAYAH SANGAT TINGGI]', f\"{wadmpr_by_kategori['Sangat Tinggi']}\")\n",
    "                element.text = element.text.replace('[WILAYAH TINGGI]', f\"{wadmpr_by_kategori['Tinggi']}\")\n",
    "                element.text = element.text.replace('[WILAYAH MENENGAH]', f\"{wadmpr_by_kategori['Menengah']}\")\n",
    "                element.text = element.text.replace('[WILAYAH RENDAH]', f\"{wadmpr_by_kategori['Rendah']}\")\n",
    "\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements2 = layout_laporan2.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements2:\n",
    "            if element.name == \"bulan\":\n",
    "                element.text = element.text.replace('[BULAN]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"tabel\":\n",
    "                element.sourceImage = element.sourceImage.replace(r\"D:\\Project\\BMKG SiPinter Iklim\\table\\dataframe_image.png\", r\"D:\\Project\\BMKG SiPinter Iklim\\table\\dataframe_image.png\")\n",
    "            elif element.name == \"chart\":\n",
    "                element.sourceImage = element.sourceImage.replace(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ach.png\", r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ach.png\")  \n",
    "        \n",
    "\n",
    "        temp_pdf1 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\temp_laporan', 'temp1.pdf')\n",
    "        temp_pdf2 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\temp_laporan', 'temp2.pdf')\n",
    "\n",
    "        layout_laporan1.exportToPDF(temp_pdf1, resolution=300)\n",
    "        layout_laporan2.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "        # Combine PDFs\n",
    "        pdf_doc = arcpy.mp.PDFDocumentCreate(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Laporan_Singkat\\laporan_pusat_ach_1.pdf')\n",
    "        pdf_doc.appendPages(temp_pdf1)\n",
    "        pdf_doc.appendPages(temp_pdf2)\n",
    "        pdf_doc.saveAndClose()\n",
    "\n",
    "        # Clean up temporary files\n",
    "        os.remove(temp_pdf1)\n",
    "        os.remove(temp_pdf2)\n",
    "\n",
    "        print(\"Pembuatan Laporan Singkat selesai\")\n",
    "            \n",
    "    \n",
    "        \n",
    "    elif tipe == \"Analisa Sifat Hujan\":\n",
    "        feature = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.gdb\\Polygon_ASH_Indonesia__Union\"\n",
    "        tipe_name = 'ash'\n",
    "\n",
    "        sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "\n",
    "        data = sdf2[['Kategori', 'WADMPR', 'Pulau_B', 'area']]\n",
    "\n",
    "        \n",
    "        # Proses statistik wilayah Indonesia\n",
    "\n",
    "        sum_area = data['area'].sum()\n",
    "        cat_df = data.groupby('Kategori')['area'].sum()\n",
    "        indo_df = round(cat_df / sum_area, 4)\n",
    "        indo_df = indo_df.reset_index()\n",
    "        indo_df = indo_df.rename({'area' : 'Persentase',}, axis='columns')\n",
    "        indo_df['Persentase'] = round(indo_df['Persentase']*100,2)\n",
    "        indo_df['Persentase%'] = round(indo_df['Persentase'],2).astype(str) + '%'\n",
    "        indo_df.drop(indo_df.index[0], inplace=True)\n",
    "        indo_df[\"Pulau_B\"] = 'Indonesia'\n",
    "        indo_df_pivot = pd.pivot(indo_df, index='Pulau_B', columns='Kategori', values='Persentase')\n",
    "        indo_df_pivot = indo_df_pivot.reset_index()\n",
    "        indo_df_pivot.columns.name = None\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah wilayah Provinsi\n",
    "        province_area_sum = data.groupby('WADMPR')['area'].sum()\n",
    "        cat_df2 = data.groupby(['Kategori','WADMPR'])['area'].sum()\n",
    "        prov_df = round(cat_df2 / province_area_sum, 4)\n",
    "        prov_df = prov_df.reset_index()\n",
    "        prov_df = prov_df[(prov_df['Kategori'] != \"\") & (prov_df['area'] != 0)]\n",
    "        prov_df['Persentase%'] = round(prov_df['area']*100,2).astype(str) + '%'\n",
    "\n",
    "        top_13_areas = prov_df.groupby('Kategori').apply(lambda x: x.nlargest(13, 'area')).reset_index(drop=True)\n",
    "        wadmpr_by_kategori = top_13_areas.groupby('Kategori')['WADMPR'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "        atas_normal = indo_df.loc[indo_df['Kategori'] == 'Atas Normal', 'Persentase'].values[0]\n",
    "        normal = indo_df.loc[indo_df['Kategori'] == 'Normal', 'Persentase'].values[0]\n",
    "        bawah_normal = indo_df.loc[indo_df['Kategori'] == 'Bawah Normal', 'Persentase'].values[0]\n",
    "   \n",
    "\n",
    "\n",
    "        # Proses statistik wilayah Pulau Besar\n",
    "        pulau_area_sum = data.groupby('Pulau_B')['area'].sum()\n",
    "        cat_df3 = data.groupby(['Kategori','Pulau_B'])['area'].sum()\n",
    "        pulau_df = round(cat_df3 / pulau_area_sum, 4)\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df = pulau_df[(pulau_df['Kategori'] != \"\") & (pulau_df['area'] != 0)]\n",
    "        pulau_df['Persentase'] = round(pulau_df['area']*100, 2)\n",
    "        pulau_df = pd.pivot(pulau_df, index='Pulau_B', columns='Kategori', values='Persentase')\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df.columns.name = None\n",
    "        pulau_df.drop(pulau_df.index[0], inplace=True)\n",
    "        pulau_df = pd.concat([indo_df_pivot, pulau_df], ignore_index=True)\n",
    "        pulau_df.iloc[:, 1:] = pulau_df.iloc[:, 1:].div(pulau_df.iloc[:, 1:].sum(axis=1), axis=0) * 100\n",
    "        pulau_df.iloc[:, 1:] = pulau_df.iloc[:, 1:].round(2)\n",
    "        pulau_df = pulau_df.rename(columns={'Pulau_B': 'Wilayah', 'Bawah Normal': 'Bawah Normal (%)', 'Normal': 'Normal (%)','Atas Normal': 'Atas Normal (%)'})\n",
    "        new_order = ['Wilayah', 'Bawah Normal (%)', 'Normal (%)', 'Atas Normal (%)']\n",
    "        pulau_df = pulau_df[new_order]\n",
    "        \n",
    "\n",
    "\n",
    "        # Proses pembuatan chart infografis\n",
    "\n",
    "        fig = px.bar(indo_df, x='Kategori', y='Persentase', width=800, height=400, text='Persentase%')\n",
    "        fig.update_xaxes(categoryorder='array', categoryarray= ['Bawah Normal', 'Normal', 'Atas Normal'])\n",
    "        fig.update_traces(marker_color=['#8bd48b','#efa800', '#eaff00' ], showlegend=False)\n",
    "        fig.update_layout(yaxis_range=[0,100], xaxis_title=f'{tipe}',)\n",
    "        fig.update_traces(width=0.95)\n",
    "        fig.update_xaxes(visible=False, showticklabels=False)\n",
    "        fig.update_traces(textposition='inside', textfont=dict(size=16, family='Arial Black', color='black'), insidetextanchor='middle')\n",
    "        fig.update_traces(marker_line_color='black', marker_line_width=3.5, marker_line=dict(color='#fff', width=1), marker=dict(line_color='black'))\n",
    "\n",
    "        textpositions = []\n",
    "        for bar in fig.data[0].y:\n",
    "            if bar < 10:  # Adjust this threshold as needed\n",
    "                textpositions.append('outside')\n",
    "            else:\n",
    "                textpositions.append('inside')\n",
    "\n",
    "        fig.update_traces(textposition=textpositions, textfont=dict(size=16), insidetextanchor='middle')\n",
    "\n",
    "        fig.update_layout(\n",
    "            xaxis_title_font=dict(size=15, color='black', family=\"Arial\"),\n",
    "            yaxis_title_font=dict(size=18, color='black', family=\"Arial\"),\n",
    "            font=dict(size=14, color='black'),\n",
    "            plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot area background\n",
    "            paper_bgcolor='rgba(0,0,0,0)'  # Transparent paper background\n",
    "            )\n",
    "        fig.show()\n",
    "\n",
    "        fig.write_image(os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'ash_bar_chart_infog_indo.png'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # PROSES PEMBUATAN INFOGRAFIS 1\n",
    "        print(\"Pembuatan Infografis dimulai . . .\")\n",
    "        aprx_path = os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\", 'BMKG_SiPinter.aprx')\n",
    "        aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "\n",
    "        \n",
    "        layout_infog_1 = aprx.listLayouts(\"infografis_ash_pusat_1\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements = layout_infog_1.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements:\n",
    "            if element.name == \"periode\":\n",
    "                element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"waktu\":\n",
    "                element.text = element.text.replace('[WAKTU]', f' {current_month_name} {current_year}')\n",
    "            \n",
    "\n",
    "        # PROSES PEMBUATAN INFOGRAFIS 2\n",
    "\n",
    "        aprx_path = os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\", 'BMKG_SiPinter.aprx')\n",
    "        aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "        layout_infog_2 = aprx.listLayouts(\"infografis_ash_pusat_2\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements = layout_infog_2.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements:\n",
    "            if element.name == 'chart':\n",
    "                    element.sourceImage = element.sourceImage.replace((os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'({tipe_name}_bar_chart_infog_indo.png)')), \n",
    "                                                                    (os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'({tipe_name}_bar_chart_infog_indo.png)'))) \n",
    "            elif element.name == \"waktu_update\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"waktu_ach\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"periode_ash\":\n",
    "                element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"deskripsi\":\n",
    "                element.text = element.text.replace('[REN]', f'{bawah_normal}')\n",
    "                element.text = element.text.replace('[NOR]', f'{normal}')\n",
    "                element.text = element.text.replace('[STI]', f'{atas_normal}')\n",
    "            elif element.name == \"deskripsi2\":\n",
    "                element.text = element.text.replace('[WILAYAH RENDAH]', f\"{wadmpr_by_kategori['Bawah Normal']}\")\n",
    "                element.text = element.text.replace('[WILAYAH NORMAL]', f\"{wadmpr_by_kategori['Normal']}\")\n",
    "                element.text = element.text.replace('[WILAYAH TINGGI]', f\"{wadmpr_by_kategori['Atas Normal']}\")\n",
    "\n",
    "                \n",
    "        \n",
    "        temp_pdf1 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\temp', f'{tipe_name}_infografis_indo_1.pdf')\n",
    "        temp_pdf2 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\temp', f'{tipe_name}_infografis_indo_2.pdf')\n",
    "\n",
    "        layout_infog_1.exportToPDF(temp_pdf1, resolution=300)\n",
    "        layout_infog_2.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "        # Combine PDFs\n",
    "        pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Infografis', f'{tipe_name}_Infografis_indo_ver_{year}{month}.pdf'))\n",
    "        pdf_doc.appendPages(temp_pdf1)\n",
    "        pdf_doc.appendPages(temp_pdf2)\n",
    "        pdf_doc.saveAndClose()\n",
    "        os.remove(temp_pdf1)\n",
    "        os.remove(temp_pdf2)\n",
    "        print(\"Pembuatan Infografis selesai\")\n",
    "\n",
    "\n",
    "        # PEMBUATAN LAPORAN SINGKAT\n",
    "\n",
    "        print(\"Pembuatan Laporan Singkat dimulai . . .\")\n",
    "\n",
    "        # Create a figure and axis\n",
    "        fig, ax = plt.subplots(figsize=(10, 2))  # You can adjust the size\n",
    "        ax.axis('off')  # Hide the axes\n",
    "        # Create a table\n",
    "        table = ax.table(cellText=pulau_df.values, colLabels=pulau_df.columns, cellLoc='center', loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(15)  # Adjust the font size here\n",
    "        table.scale(1.5, 3.5)\n",
    "\n",
    "        for (i, j), cell in table.get_celld().items():\n",
    "            if i == 0:  # Header row\n",
    "                cell.set_text_props(weight='bold')\n",
    "            cell.set_width(0.30)\n",
    "\n",
    "        # Save the table as an image\n",
    "        plt.savefig(os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Tabel', f'{tipe_name}_dataframe_image.png'), bbox_inches='tight', pad_inches=0.5)\n",
    "\n",
    "\n",
    "        # Pembuatan Peta laporan \n",
    "\n",
    "        layout_peta_laporan = aprx.listLayouts(\"map_ash_laporan\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "        layout_peta_laporan.exportToJPEG(os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f\"map_{tipe_name}_laporan.jpg\"), resolution=300)\n",
    "\n",
    "\n",
    "        # Pembuatan chart laporan\n",
    "        regions = pulau_df['Wilayah']\n",
    "        bawah_normal_val = pulau_df['Bawah Normal (%)']\n",
    "        normal_val = pulau_df['Normal (%)']\n",
    "        atas_normal_val = pulau_df['Atas Normal (%)']\n",
    "        threshold=3.5  # threshold untuk ukuran bar memiliki label\n",
    "\n",
    "        # Add text label\n",
    "        bawah_normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in bawah_normal_val]\n",
    "        normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in normal_val]\n",
    "        atas_normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in atas_normal_val]\n",
    "\n",
    "\n",
    "        # Create the plot\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add traces\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=bawah_normal_val,\n",
    "            name='Bawah Normal (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#8e2800'),\n",
    "            text=bawah_normal_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=normal_val,\n",
    "            name='Normal (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#eaff00'),\n",
    "            text=normal_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=atas_normal_val,\n",
    "            name='Atas Normal (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#8bd48b'),\n",
    "            text=atas_normal_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "\n",
    "        # Customize layout\n",
    "        fig.update_layout(\n",
    "            barmode='stack',\n",
    "            title=dict(\n",
    "                text=f'Distribusi {tipe} Indonesia dan Pulau Besar Indonesia',\n",
    "                font=dict(size=23, color='black', family='Arial Black')  # Use a bold font family\n",
    "            ),\n",
    "            xaxis=dict(title=dict(\n",
    "                    text='Persentase (%)',\n",
    "                    font=dict(size=14)  # Set the font size for the x-axis title\n",
    "                ),\n",
    "                tickfont=dict(size=14)),\n",
    "            yaxis=dict(\n",
    "                tickfont=dict(size=14)  # Set the font size for the y-axis ticks\n",
    "            ),\n",
    "            legend=dict(title=dict(\n",
    "                    text='Kategori',\n",
    "                    font=dict(size=14)), \n",
    "                x=0.5,\n",
    "                y=-0.1,\n",
    "                xanchor='center',\n",
    "                yanchor='top',\n",
    "                orientation='h',\n",
    "                font=dict(size=14)),\n",
    "            width=1000,  # Set the width of the figure\n",
    "            height=800,\n",
    "            plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot background\n",
    "            paper_bgcolor='rgba(0,0,0,0)' )\n",
    "        # Show the plot\n",
    "        fig.show()\n",
    "        fig.write_image(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ash.png\")\n",
    "\n",
    "\n",
    "\n",
    "        # Pembuatan laporan singkat\n",
    "        layout_laporan1 = aprx.listLayouts(\"laporan_ash_pusat_1\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "        layout_laporan2 = aprx.listLayouts(\"laporan_ash_pusat_2\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "        # List all elements in the layout\n",
    "        elements1 = layout_laporan1.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements1:\n",
    "            if element.name == \"bulan\":\n",
    "                element.text = element.text.replace('[BULAN]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"peta\":\n",
    "                element.sourceImage = element.sourceImage.replace(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\map_ash_laporan.jpg\", r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\map_ash_laporan.jpg\") \n",
    "            elif element.name == \"deskripsi\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "                element.text = element.text.replace('[STI]', f'{atas_normal}')\n",
    "                element.text = element.text.replace('[NOR]', f'{normal}')\n",
    "                element.text = element.text.replace('[REN]', f'{bawah_normal}')\n",
    "                element.text = element.text.replace('[WILAYAH ATAS NORMAL]', f\"{wadmpr_by_kategori['Atas Normal']}\")\n",
    "                element.text = element.text.replace('[WILAYAH NORMAL]', f\"{wadmpr_by_kategori['Normal']}\")\n",
    "                element.text = element.text.replace('[WILAYAH BAWAH NORMAL]', f\"{wadmpr_by_kategori['Bawah Normal']}\")\n",
    "\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements2 = layout_laporan2.listElements()\n",
    "        # Print the names of all elements\n",
    "        for element in elements2:\n",
    "            if element.name == \"bulan\":\n",
    "                element.text = element.text.replace('[BULAN]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"tabel\":\n",
    "                element.sourceImage = element.sourceImage.replace(os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Tabel', f'{tipe_name}_dataframe_image.png'), \n",
    "                                                                  os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Tabel', f'{tipe_name}_dataframe_image.png'))\n",
    "            elif element.name == \"chart\":\n",
    "                element.sourceImage = element.sourceImage.replace(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ash.png\", \n",
    "                                                                  r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ash.png\")  \n",
    "        \n",
    "\n",
    "        temp_pdf1 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\temp_laporan', 'temp1.pdf')\n",
    "        temp_pdf2 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\temp_laporan', 'temp2.pdf')\n",
    "\n",
    "        layout_laporan1.exportToPDF(temp_pdf1, resolution=300)\n",
    "        layout_laporan2.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "        # Combine PDFs\n",
    "        pdf_doc = arcpy.mp.PDFDocumentCreate(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Laporan_Singkat\\laporan_pusat_ash_1.pdf')\n",
    "        pdf_doc.appendPages(temp_pdf1)\n",
    "        pdf_doc.appendPages(temp_pdf2)\n",
    "        pdf_doc.saveAndClose()\n",
    "\n",
    "        # Clean up temporary files\n",
    "        os.remove(temp_pdf1)\n",
    "        os.remove(temp_pdf2)\n",
    "\n",
    "        print(\"Pembuatan Laporan Singkat selesai\")\n",
    "        \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infog_laporan_pusat(tipe='Analisa Sifat Hujan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reporting\n",
    "# Funtion for Map\n",
    "\n",
    "def map1_upt(aprx_path = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.aprx\", layout_name = \"peta_1_pusat\", output_location = r'D:\\Project\\BMKG SiPinter Iklim\\Map', output_name= 'map_pusat1.jpg'):\n",
    "    aprx_path = aprx_path\n",
    "    aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "    \n",
    "    layout_map1_pusat = aprx.listLayouts(layout_name)[0]  # Adjust \"Layout\" to match your layout's name\n",
    "    \n",
    "    # List all elements in the layout \n",
    "    elements = layout_map1_pusat.listElements()\n",
    "    \n",
    "    # Print the names of all element\n",
    "    print(\"Print Peta 1 dimulai . . .\")\n",
    "    for element in elements:\n",
    "        if element.name == 'ash_bln':\n",
    "            element.text = element.text.replace('[BULAN]', f'{current_month_name}')\n",
    "        elif element.name == 'ash_thn':\n",
    "            element.text = element.text.replace('[TAHUN]', f'{current_year}')\n",
    "        elif element.name == 'ach_bln':\n",
    "            element.text = element.text.replace('[BULAN]', f'{current_month_name}')\n",
    "        elif element.name == 'ach_thn':\n",
    "            element.text = element.text.replace('[TAHUN]', f'{current_year}')\n",
    "            \n",
    "    layout_map1_pusat.exportToJPEG(os.path.join(output_location, output_name), resolution=300)\n",
    "    print(\"Print Peta 1 selesai\")\n",
    "\n",
    "\n",
    "def map2_upt(aprx_path = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.aprx\", layout_name = \"peta_2_pusat\", output_location = r'D:\\Project\\BMKG SiPinter Iklim\\Map', output_name= 'map_pusat2.jpg'):\n",
    "    aprx_path = aprx_path\n",
    "    aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "\n",
    "\n",
    "    layout_map2_pusat = aprx.listLayouts(layout_name)[0]  # Adjust \"Layout\" to match your layout's name\n",
    "    \n",
    "    # List all elements in the layout\n",
    "    elements = layout_map2_pusat.listElements()\n",
    "\n",
    "    # Print the names of all elements\n",
    "    print(\"Print Peta 2 dimulai . . .\")\n",
    "    for element in elements:\n",
    "        if element.name == 'ash_wkt':\n",
    "            element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "        elif element.name == 'ach_wkt':\n",
    "            element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "        elif element.name == 'tgl_mut_ash':\n",
    "            element.text = element.text.replace('[tanggal]', f'{current_date_time} WIB')\n",
    "        elif element.name == 'tgl_mut_ach':\n",
    "            element.text = element.text.replace('[tanggal]', f'{current_date_time} WIB')\n",
    "\n",
    "    layout_map2_pusat.exportToJPEG(os.path.join(output_location, output_name), resolution=300)\n",
    "    print(\"Print Peta 2 selesai\")\n",
    "\n",
    "\n",
    "def infog_laporan_upt(tipe= 'Analisa Curah Hujan'):\n",
    "    \n",
    "    print(\"Proses Pembuatan Infografis dan Laporan Singkat dimulai . . .\")\n",
    "\n",
    "    if tipe == \"Analisa Curah Hujan\":\n",
    "        feature = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.gdb\\Polygon_ACH_Kalbar_Union\" ####### NANTI SESUAIKAN DENGAN PROSES PENGOLAHAN DATA\n",
    "        tipe_name = 'ach'\n",
    "        sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "\n",
    "        data = sdf2[['Kategori', 'WADMKK', 'WADMPR', 'area']]\n",
    "\n",
    "        \n",
    "        # Proses statistik wilayah Prov\n",
    "\n",
    "        sum_area = data['area'].sum()\n",
    "        cat_df = data.groupby('Kategori')['area'].sum()\n",
    "        prov_df = round(cat_df / sum_area, 4)\n",
    "        prov_df = prov_df.reset_index()\n",
    "        prov_df = prov_df.rename({'area' : 'Persentase',}, axis='columns')\n",
    "        prov_df['Persentase'] = round(indo_df['Persentase']*100,2)\n",
    "        prov_df['Persentase%'] = round(indo_df['Persentase'],2).astype(str) + '%'\n",
    "        prov_df.drop(indo_df.index[0], inplace=True)\n",
    "        prov_df_pivot = pd.pivot(indo_df, index='WADMPR', columns='Kategori', values='Persentase')\n",
    "        prov_df_pivot = indo_df_pivot.reset_index()\n",
    "        prov_df_pivot.columns.name = None\n",
    "\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah wilayah Provinsi\n",
    "        province_area_sum = data.groupby('WADMPR')['area'].sum()\n",
    "        cat_df2 = data.groupby(['Kategori','WADMPR'])['area'].sum()\n",
    "        prov_df = round(cat_df2 / province_area_sum, 4)\n",
    "        prov_df = prov_df.reset_index()\n",
    "        prov_df = prov_df[(prov_df['Kategori'] != \"\") & (prov_df['area'] != 0)]\n",
    "        prov_df['Persentase%'] = round(prov_df['area']*100,2).astype(str) + '%'\n",
    "\n",
    "        top_13_areas = prov_df.groupby('Kategori').apply(lambda x: x.nlargest(13, 'area')).reset_index(drop=True)\n",
    "        wadmpr_by_kategori = top_13_areas.groupby('Kategori')['WADMPR'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "        sgt_tinggi = indo_df.loc[indo_df['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "        tinggi = indo_df.loc[indo_df['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "        rendah = indo_df.loc[indo_df['Kategori'] == 'Rendah', 'Persentase'].values[0]\n",
    "        menengah =  indo_df.loc[indo_df['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah Pulau Besar\n",
    "        pulau_area_sum = data.groupby('Pulau_B')['area'].sum()\n",
    "        cat_df3 = data.groupby(['Kategori','Pulau_B'])['area'].sum()\n",
    "        pulau_df = round(cat_df3 / pulau_area_sum, 4)\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df = pulau_df[(pulau_df['Kategori'] != \"\") & (pulau_df['area'] != 0)]\n",
    "        pulau_df['Persentase'] = round(pulau_df['area']*100, 2)\n",
    "        pulau_df = pd.pivot(pulau_df, index='Pulau_B', columns='Kategori', values='Persentase')\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df.columns.name = None\n",
    "        pulau_df.drop(pulau_df.index[0], inplace=True)\n",
    "        pulau_df = pd.concat([indo_df_pivot, pulau_df], ignore_index=True)\n",
    "        pulau_df.iloc[:, 1:] = pulau_df.iloc[:, 1:].div(pulau_df.iloc[:, 1:].sum(axis=1), axis=0) * 100\n",
    "        pulau_df.iloc[:, 1:] = pulau_df.iloc[:, 1:].round(2)\n",
    "        pulau_df = pulau_df.rename(columns={'Pulau_B': 'Wilayah', 'Rendah': 'Rendah (%)', 'Menengah': 'Menengah (%)','Tinggi': 'Tinggi (%)', 'Sangat Tinggi': 'Sangat Tinggi (%)'})\n",
    "        new_order = ['Wilayah', 'Rendah (%)', 'Menengah (%)', 'Tinggi (%)', 'Sangat Tinggi (%)']\n",
    "        pulau_df = pulau_df[new_order]\n",
    "        \n",
    "\n",
    "        # Proses pembuatan chart infografis\n",
    "        import plotly.io as pio\n",
    "\n",
    "        fig = px.bar(indo_df, x='Kategori', y='Persentase', width=800, height=400, text='Persentase%')\n",
    "        fig.update_xaxes(categoryorder='array', categoryarray= ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi'])\n",
    "        fig.update_traces(marker_color=['#ffff00','#8e2800', '#00450c','#8bd48b' ], showlegend=False)\n",
    "        fig.update_layout(yaxis_range=[0,100], xaxis_title=f'{tipe}',)\n",
    "        fig.update_traces(width=0.95)\n",
    "        fig.update_xaxes(visible=False, showticklabels=False)\n",
    "        fig.update_traces(textposition='inside', textfont=dict(size=16, family='Arial Black', color='black'), insidetextanchor='middle')\n",
    "        fig.update_traces(marker_line_color='black', marker_line_width=3.5, marker_line=dict(color='#fff', width=1), marker=dict(line_color='black'))\n",
    "\n",
    "        textpositions = []\n",
    "        for bar in fig.data[0].y:\n",
    "            if bar < 10:  # Adjust this threshold as needed\n",
    "                textpositions.append('outside')\n",
    "            else:\n",
    "                textpositions.append('inside')\n",
    "\n",
    "        fig.update_traces(textposition=textpositions, textfont=dict(size=16), insidetextanchor='middle')\n",
    "        fig.update_layout(\n",
    "            xaxis_title_font=dict(size=15, color='black', family=\"Arial\"),\n",
    "            yaxis_title_font=dict(size=18, color='black', family=\"Arial\"),\n",
    "            font=dict(size=14, color='black'),\n",
    "            plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot area background\n",
    "            paper_bgcolor='rgba(0,0,0,0)'  # Transparent paper background\n",
    "            )\n",
    "\n",
    "        fig.write_image(os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'ach_bar_chart_infog_indo.png'))\n",
    "\n",
    "\n",
    "        # PROSES PEMBUATAN INFOGRAFIS 1\n",
    "        print(\"Pembuatan Infografis dimulai . . .\")\n",
    "        aprx_path = os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\", 'BMKG_SiPinter.aprx')\n",
    "        aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "        layout_infog_1 = aprx.listLayouts(\"infografis_ach_pusat_1\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements = layout_infog_1.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements:\n",
    "            if element.name == \"periode\":\n",
    "                element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"waktu\":\n",
    "                element.text = element.text.replace('[WAKTU]', f' {current_month_name} {current_year}')\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        # PROSES PEMBUATAN INFOGRAFIS 2\n",
    "\n",
    "        aprx_path = os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\", 'BMKG_SiPinter.aprx')\n",
    "        aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "        layout_infog_2 = aprx.listLayouts(\"infografis_ach_pusat_2\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements = layout_infog_2.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements:\n",
    "            if element.name == 'chart':\n",
    "                    element.sourceImage = element.sourceImage.replace((os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'({tipe_name}_bar_chart_infog_indo.png)')), \n",
    "                                                                    (os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'({tipe_name}_bar_chart_infog_indo.png)'))) \n",
    "            elif element.name == \"waktu_update\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"waktu_ach\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"periode_ash\":\n",
    "                element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"deskripsi\":\n",
    "                element.text = element.text.replace('[REN]', f'{rendah}')\n",
    "                element.text = element.text.replace('[MNG]', f'{menengah}')\n",
    "                element.text = element.text.replace('[TIN]', f'{tinggi}')\n",
    "                element.text = element.text.replace('[STI]', f'{sgt_tinggi}')\n",
    "            elif element.name == \"area_ren\":\n",
    "                element.text = element.text.replace('[WILAYAH RENDAH]', f\"{wadmpr_by_kategori['Rendah']}\")\n",
    "            elif element.name == \"area_mgh\":\n",
    "                element.text = element.text.replace('[WILAYAH MENENGAH]', f\"{wadmpr_by_kategori['Menengah']}\")\n",
    "            elif element.name == \"area_tin\":\n",
    "                element.text = element.text.replace('[WILAYAH TINGGI]', f\"{wadmpr_by_kategori['Tinggi']}\")\n",
    "            elif element.name == \"area_sti\":\n",
    "                element.text = element.text.replace('[WILAYAH SANGAT TINGGI]', f\"{wadmpr_by_kategori['Sangat Tinggi']}\")\n",
    "                \n",
    "        \n",
    "        temp_pdf1 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\temp', f'{tipe_name}_infografis_indo_1.pdf')\n",
    "        temp_pdf2 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\temp', f'{tipe_name}_infografis_indo_2.pdf')\n",
    "        layout_infog_1.exportToPDF(temp_pdf1, resolution=300)\n",
    "        layout_infog_2.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "        # Combine PDFs\n",
    "        pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Infografis', f'{tipe_name}_Infografis_indo_ver_{year}{month}.pdf'))\n",
    "        pdf_doc.appendPages(temp_pdf1)\n",
    "        pdf_doc.appendPages(temp_pdf2)\n",
    "        pdf_doc.saveAndClose()\n",
    "\n",
    "        os.remove(temp_pdf1)\n",
    "        os.remove(temp_pdf2)\n",
    "\n",
    "        print(\"Pembuatan Infografis selesai\")\n",
    "\n",
    "\n",
    "\n",
    "        # PEMBUATAN LAPORAN SINGKAT\n",
    "\n",
    "        print(\"Pembuatan Laporan Singkat dimulai . . .\")\n",
    "\n",
    "        # Create a figure and axis\n",
    "        fig, ax = plt.subplots(figsize=(10, 2))  # You can adjust the size\n",
    "        ax.axis('off')  # Hide the axes\n",
    "        # Create a table\n",
    "        table = ax.table(cellText=pulau_df.values, colLabels=pulau_df.columns, cellLoc='center', loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(15)  # Adjust the font size here\n",
    "        table.scale(1.5, 3.5)\n",
    "        for (i, j), cell in table.get_celld().items():\n",
    "            if i == 0:  # Header row\n",
    "                cell.set_text_props(weight='bold')\n",
    "            cell.set_width(0.28)\n",
    "        # Save the table as an image\n",
    "        plt.savefig(os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Tabel', f'{tipe_name}_dataframe_image.png'), bbox_inches='tight', pad_inches=0.5)\n",
    "\n",
    "\n",
    "        # Pembuatan Peta laporan \n",
    "\n",
    "        layout_peta_laporan = aprx.listLayouts(\"map_ach_laporan\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "        layout_peta_laporan.exportToJPEG(os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f\"map_{tipe_name}_laporan.jpg\"), resolution=300)\n",
    "\n",
    "\n",
    "        # Pembuatan chart laporan\n",
    "\n",
    "        regions = pulau_df['Wilayah']\n",
    "        rendah_val = pulau_df['Rendah (%)']\n",
    "        menengah_val = pulau_df['Menengah (%)']\n",
    "        tinggi_val = pulau_df['Tinggi (%)']\n",
    "        sangat_tinggi_val = pulau_df['Sangat Tinggi (%)']\n",
    "        threshold=3.5  # threshold untuk ukuran bar memiliki label\n",
    "\n",
    "        # Add text label\n",
    "        menengah_text = [f'{val:.2f}%' if val >= threshold else '' for val in menengah_val]\n",
    "        rendah_text = [f'{val:.2f}%' if val >= threshold else '' for val in rendah_val]\n",
    "        sangat_tinggi_text = [f'{val:.2f}%' if val >= threshold else '' for val in sangat_tinggi_val]\n",
    "        tinggi_text = [f'{val:.2f}%' if val >= threshold else '' for val in tinggi_val]\n",
    "\n",
    "        # Create the plot\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add traces\n",
    "        fig.add_trace(go.Bar(y=regions,\n",
    "            x=rendah_val,\n",
    "            name='Rendah (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#8e2800'),\n",
    "            text=rendah_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=menengah_val,\n",
    "            name='Menengah (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#eaff00'),\n",
    "            text=menengah_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=tinggi_val,\n",
    "            name='Tinggi (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#8bd48b'),\n",
    "            text=tinggi_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=sangat_tinggi_val,\n",
    "            name='Sangat Tinggi (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#00450c'),\n",
    "            text=sangat_tinggi_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        # Customize layout\n",
    "        fig.update_layout(\n",
    "            barmode='stack',\n",
    "            title=dict(\n",
    "                text=f'Distribusi {tipe} Indonesia dan Pulau Besar Indonesia',\n",
    "                font=dict(size=23, color='black', family='Arial Black') ),\n",
    "            xaxis=dict(title=dict(\n",
    "                    text='Persentase (%)',\n",
    "                    font=dict(size=14)  # Set the font size for the x-axis title\n",
    "                ),\n",
    "                tickfont=dict(size=14)),\n",
    "            yaxis=dict(\n",
    "                tickfont=dict(size=14)  # Set the font size for the y-axis ticks\n",
    "            ),\n",
    "            legend=dict(title=dict(\n",
    "                    text='Kategori',\n",
    "                    font=dict(size=14)), \n",
    "                x=0.5,\n",
    "                y=-0.1,\n",
    "                xanchor='center',\n",
    "                yanchor='top',\n",
    "                orientation='h',\n",
    "                font=dict(size=14)),\n",
    "            width=1000,  # Set the width of the figure\n",
    "            height=800,\n",
    "            plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot background\n",
    "            paper_bgcolor='rgba(0,0,0,0)' \n",
    "        )\n",
    "\n",
    "        # Show the plot\n",
    "        fig.show()\n",
    "\n",
    "        fig.write_image(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ach.png\")\n",
    "\n",
    "\n",
    "        # Pembuatan laporan singkat\n",
    "        layout_laporan1 = aprx.listLayouts(\"laporan_ach_pusat_1\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "        layout_laporan2 = aprx.listLayouts(\"laporan_ach_pusat_2\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements1 = layout_laporan1.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements1:\n",
    "            if element.name == \"bulan\":\n",
    "                element.text = element.text.replace('[BULAN]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"peta\":\n",
    "                element.sourceImage = element.sourceImage.replace(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\map_ach_laporan.jpg\", r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\map_ach_laporan.jpg\") \n",
    "            elif element.name == \"deskripsi\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "                element.text = element.text.replace('[STI]', f'{sgt_tinggi}')\n",
    "                element.text = element.text.replace('[TIN]', f'{tinggi}')\n",
    "                element.text = element.text.replace('[MNG]', f'{menengah}')\n",
    "                element.text = element.text.replace('[REN]', f'{rendah}')\n",
    "                element.text = element.text.replace('[WILAYAH SANGAT TINGGI]', f\"{wadmpr_by_kategori['Sangat Tinggi']}\")\n",
    "                element.text = element.text.replace('[WILAYAH TINGGI]', f\"{wadmpr_by_kategori['Tinggi']}\")\n",
    "                element.text = element.text.replace('[WILAYAH MENENGAH]', f\"{wadmpr_by_kategori['Menengah']}\")\n",
    "                element.text = element.text.replace('[WILAYAH RENDAH]', f\"{wadmpr_by_kategori['Rendah']}\")\n",
    "\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements2 = layout_laporan2.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements2:\n",
    "            if element.name == \"bulan\":\n",
    "                element.text = element.text.replace('[BULAN]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"tabel\":\n",
    "                element.sourceImage = element.sourceImage.replace(r\"D:\\Project\\BMKG SiPinter Iklim\\table\\dataframe_image.png\", r\"D:\\Project\\BMKG SiPinter Iklim\\table\\dataframe_image.png\")\n",
    "            elif element.name == \"chart\":\n",
    "                element.sourceImage = element.sourceImage.replace(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ach.png\", r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ach.png\")  \n",
    "        \n",
    "\n",
    "        temp_pdf1 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\temp_laporan', 'temp1.pdf')\n",
    "        temp_pdf2 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\temp_laporan', 'temp2.pdf')\n",
    "\n",
    "        layout_laporan1.exportToPDF(temp_pdf1, resolution=300)\n",
    "        layout_laporan2.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "        # Combine PDFs\n",
    "        pdf_doc = arcpy.mp.PDFDocumentCreate(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Laporan_Singkat\\laporan_pusat_ach_1.pdf')\n",
    "        pdf_doc.appendPages(temp_pdf1)\n",
    "        pdf_doc.appendPages(temp_pdf2)\n",
    "        pdf_doc.saveAndClose()\n",
    "\n",
    "        # Clean up temporary files\n",
    "        os.remove(temp_pdf1)\n",
    "        os.remove(temp_pdf2)\n",
    "\n",
    "        print(\"Pembuatan Laporan Singkat selesai\")\n",
    "            \n",
    "    \n",
    "        \n",
    "    elif tipe == \"Analisa Sifat Hujan\":\n",
    "        feature = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.gdb\\Polygon_ASH_Indonesia__Union\"\n",
    "        tipe_name = 'ash'\n",
    "\n",
    "        sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "\n",
    "        data = sdf2[['Kategori', 'WADMPR', 'Pulau_B', 'area']]\n",
    "\n",
    "        \n",
    "        # Proses statistik wilayah Indonesia\n",
    "\n",
    "        sum_area = data['area'].sum()\n",
    "        cat_df = data.groupby('Kategori')['area'].sum()\n",
    "        indo_df = round(cat_df / sum_area, 4)\n",
    "        indo_df = indo_df.reset_index()\n",
    "        indo_df = indo_df.rename({'area' : 'Persentase',}, axis='columns')\n",
    "        indo_df['Persentase'] = round(indo_df['Persentase']*100,2)\n",
    "        indo_df['Persentase%'] = round(indo_df['Persentase'],2).astype(str) + '%'\n",
    "        indo_df.drop(indo_df.index[0], inplace=True)\n",
    "        indo_df[\"Pulau_B\"] = 'Indonesia'\n",
    "        indo_df_pivot = pd.pivot(indo_df, index='Pulau_B', columns='Kategori', values='Persentase')\n",
    "        indo_df_pivot = indo_df_pivot.reset_index()\n",
    "        indo_df_pivot.columns.name = None\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah wilayah Provinsi\n",
    "        province_area_sum = data.groupby('WADMPR')['area'].sum()\n",
    "        cat_df2 = data.groupby(['Kategori','WADMPR'])['area'].sum()\n",
    "        prov_df = round(cat_df2 / province_area_sum, 4)\n",
    "        prov_df = prov_df.reset_index()\n",
    "        prov_df = prov_df[(prov_df['Kategori'] != \"\") & (prov_df['area'] != 0)]\n",
    "        prov_df['Persentase%'] = round(prov_df['area']*100,2).astype(str) + '%'\n",
    "\n",
    "        top_13_areas = prov_df.groupby('Kategori').apply(lambda x: x.nlargest(13, 'area')).reset_index(drop=True)\n",
    "        wadmpr_by_kategori = top_13_areas.groupby('Kategori')['WADMPR'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "        atas_normal = indo_df.loc[indo_df['Kategori'] == 'Atas Normal', 'Persentase'].values[0]\n",
    "        normal = indo_df.loc[indo_df['Kategori'] == 'Normal', 'Persentase'].values[0]\n",
    "        bawah_normal = indo_df.loc[indo_df['Kategori'] == 'Bawah Normal', 'Persentase'].values[0]\n",
    "   \n",
    "\n",
    "\n",
    "        # Proses statistik wilayah Pulau Besar\n",
    "        pulau_area_sum = data.groupby('Pulau_B')['area'].sum()\n",
    "        cat_df3 = data.groupby(['Kategori','Pulau_B'])['area'].sum()\n",
    "        pulau_df = round(cat_df3 / pulau_area_sum, 4)\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df = pulau_df[(pulau_df['Kategori'] != \"\") & (pulau_df['area'] != 0)]\n",
    "        pulau_df['Persentase'] = round(pulau_df['area']*100, 2)\n",
    "        pulau_df = pd.pivot(pulau_df, index='Pulau_B', columns='Kategori', values='Persentase')\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df.columns.name = None\n",
    "        pulau_df.drop(pulau_df.index[0], inplace=True)\n",
    "        pulau_df = pd.concat([indo_df_pivot, pulau_df], ignore_index=True)\n",
    "        pulau_df.iloc[:, 1:] = pulau_df.iloc[:, 1:].div(pulau_df.iloc[:, 1:].sum(axis=1), axis=0) * 100\n",
    "        pulau_df.iloc[:, 1:] = pulau_df.iloc[:, 1:].round(2)\n",
    "        pulau_df = pulau_df.rename(columns={'Pulau_B': 'Wilayah', 'Bawah Normal': 'Bawah Normal (%)', 'Normal': 'Normal (%)','Atas Normal': 'Atas Normal (%)'})\n",
    "        new_order = ['Wilayah', 'Bawah Normal (%)', 'Normal (%)', 'Atas Normal (%)']\n",
    "        pulau_df = pulau_df[new_order]\n",
    "        \n",
    "\n",
    "\n",
    "        # Proses pembuatan chart infografis\n",
    "\n",
    "        fig = px.bar(indo_df, x='Kategori', y='Persentase', width=800, height=400, text='Persentase%')\n",
    "        fig.update_xaxes(categoryorder='array', categoryarray= ['Bawah Normal', 'Normal', 'Atas Normal'])\n",
    "        fig.update_traces(marker_color=['#8bd48b','#efa800', '#eaff00' ], showlegend=False)\n",
    "        fig.update_layout(yaxis_range=[0,100], xaxis_title=f'{tipe}',)\n",
    "        fig.update_traces(width=0.95)\n",
    "        fig.update_xaxes(visible=False, showticklabels=False)\n",
    "        fig.update_traces(textposition='inside', textfont=dict(size=16, family='Arial Black', color='black'), insidetextanchor='middle')\n",
    "        fig.update_traces(marker_line_color='black', marker_line_width=3.5, marker_line=dict(color='#fff', width=1), marker=dict(line_color='black'))\n",
    "\n",
    "        textpositions = []\n",
    "        for bar in fig.data[0].y:\n",
    "            if bar < 10:  # Adjust this threshold as needed\n",
    "                textpositions.append('outside')\n",
    "            else:\n",
    "                textpositions.append('inside')\n",
    "\n",
    "        fig.update_traces(textposition=textpositions, textfont=dict(size=16), insidetextanchor='middle')\n",
    "\n",
    "        fig.update_layout(\n",
    "            xaxis_title_font=dict(size=15, color='black', family=\"Arial\"),\n",
    "            yaxis_title_font=dict(size=18, color='black', family=\"Arial\"),\n",
    "            font=dict(size=14, color='black'),\n",
    "            plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot area background\n",
    "            paper_bgcolor='rgba(0,0,0,0)'  # Transparent paper background\n",
    "            )\n",
    "        fig.show()\n",
    "\n",
    "        fig.write_image(os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'ash_bar_chart_infog_indo.png'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # PROSES PEMBUATAN INFOGRAFIS 1\n",
    "        print(\"Pembuatan Infografis dimulai . . .\")\n",
    "        aprx_path = os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\", 'BMKG_SiPinter.aprx')\n",
    "        aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "\n",
    "        \n",
    "        layout_infog_1 = aprx.listLayouts(\"infografis_ash_pusat_1\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements = layout_infog_1.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements:\n",
    "            if element.name == \"periode\":\n",
    "                element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"waktu\":\n",
    "                element.text = element.text.replace('[WAKTU]', f' {current_month_name} {current_year}')\n",
    "            \n",
    "\n",
    "        # PROSES PEMBUATAN INFOGRAFIS 2\n",
    "\n",
    "        aprx_path = os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\", 'BMKG_SiPinter.aprx')\n",
    "        aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "        layout_infog_2 = aprx.listLayouts(\"infografis_ash_pusat_2\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements = layout_infog_2.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements:\n",
    "            if element.name == 'chart':\n",
    "                    element.sourceImage = element.sourceImage.replace((os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'({tipe_name}_bar_chart_infog_indo.png)')), \n",
    "                                                                    (os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f'({tipe_name}_bar_chart_infog_indo.png)'))) \n",
    "            elif element.name == \"waktu_update\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"waktu_ach\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"periode_ash\":\n",
    "                element.text = element.text.replace('[PERIODE]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"deskripsi\":\n",
    "                element.text = element.text.replace('[REN]', f'{bawah_normal}')\n",
    "                element.text = element.text.replace('[NOR]', f'{normal}')\n",
    "                element.text = element.text.replace('[STI]', f'{atas_normal}')\n",
    "            elif element.name == \"deskripsi2\":\n",
    "                element.text = element.text.replace('[WILAYAH RENDAH]', f\"{wadmpr_by_kategori['Bawah Normal']}\")\n",
    "                element.text = element.text.replace('[WILAYAH NORMAL]', f\"{wadmpr_by_kategori['Normal']}\")\n",
    "                element.text = element.text.replace('[WILAYAH TINGGI]', f\"{wadmpr_by_kategori['Atas Normal']}\")\n",
    "\n",
    "                \n",
    "        \n",
    "        temp_pdf1 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\temp', f'{tipe_name}_infografis_indo_1.pdf')\n",
    "        temp_pdf2 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\temp', f'{tipe_name}_infografis_indo_2.pdf')\n",
    "\n",
    "        layout_infog_1.exportToPDF(temp_pdf1, resolution=300)\n",
    "        layout_infog_2.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "        # Combine PDFs\n",
    "        pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Infografis', f'{tipe_name}_Infografis_indo_ver_{year}{month}.pdf'))\n",
    "        pdf_doc.appendPages(temp_pdf1)\n",
    "        pdf_doc.appendPages(temp_pdf2)\n",
    "        pdf_doc.saveAndClose()\n",
    "        os.remove(temp_pdf1)\n",
    "        os.remove(temp_pdf2)\n",
    "        print(\"Pembuatan Infografis selesai\")\n",
    "\n",
    "\n",
    "        # PEMBUATAN LAPORAN SINGKAT\n",
    "\n",
    "        print(\"Pembuatan Laporan Singkat dimulai . . .\")\n",
    "\n",
    "        # Create a figure and axis\n",
    "        fig, ax = plt.subplots(figsize=(10, 2))  # You can adjust the size\n",
    "        ax.axis('off')  # Hide the axes\n",
    "        # Create a table\n",
    "        table = ax.table(cellText=pulau_df.values, colLabels=pulau_df.columns, cellLoc='center', loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(15)  # Adjust the font size here\n",
    "        table.scale(1.5, 3.5)\n",
    "\n",
    "        for (i, j), cell in table.get_celld().items():\n",
    "            if i == 0:  # Header row\n",
    "                cell.set_text_props(weight='bold')\n",
    "            cell.set_width(0.30)\n",
    "\n",
    "        # Save the table as an image\n",
    "        plt.savefig(os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Tabel', f'{tipe_name}_dataframe_image.png'), bbox_inches='tight', pad_inches=0.5)\n",
    "\n",
    "\n",
    "        # Pembuatan Peta laporan \n",
    "\n",
    "        layout_peta_laporan = aprx.listLayouts(\"map_ash_laporan\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "        layout_peta_laporan.exportToJPEG(os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\", f\"map_{tipe_name}_laporan.jpg\"), resolution=300)\n",
    "\n",
    "\n",
    "        # Pembuatan chart laporan\n",
    "        regions = pulau_df['Wilayah']\n",
    "        bawah_normal_val = pulau_df['Bawah Normal (%)']\n",
    "        normal_val = pulau_df['Normal (%)']\n",
    "        atas_normal_val = pulau_df['Atas Normal (%)']\n",
    "        threshold=3.5  # threshold untuk ukuran bar memiliki label\n",
    "\n",
    "        # Add text label\n",
    "        bawah_normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in bawah_normal_val]\n",
    "        normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in normal_val]\n",
    "        atas_normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in atas_normal_val]\n",
    "\n",
    "\n",
    "        # Create the plot\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add traces\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=bawah_normal_val,\n",
    "            name='Bawah Normal (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#8e2800'),\n",
    "            text=bawah_normal_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=normal_val,\n",
    "            name='Normal (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#eaff00'),\n",
    "            text=normal_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=regions,\n",
    "            x=atas_normal_val,\n",
    "            name='Atas Normal (%)',\n",
    "            orientation='h',\n",
    "            marker=dict(color='#8bd48b'),\n",
    "            text=atas_normal_text,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "\n",
    "        # Customize layout\n",
    "        fig.update_layout(\n",
    "            barmode='stack',\n",
    "            title=dict(\n",
    "                text=f'Distribusi {tipe} Indonesia dan Pulau Besar Indonesia',\n",
    "                font=dict(size=23, color='black', family='Arial Black')  # Use a bold font family\n",
    "            ),\n",
    "            xaxis=dict(title=dict(\n",
    "                    text='Persentase (%)',\n",
    "                    font=dict(size=14)  # Set the font size for the x-axis title\n",
    "                ),\n",
    "                tickfont=dict(size=14)),\n",
    "            yaxis=dict(\n",
    "                tickfont=dict(size=14)  # Set the font size for the y-axis ticks\n",
    "            ),\n",
    "            legend=dict(title=dict(\n",
    "                    text='Kategori',\n",
    "                    font=dict(size=14)), \n",
    "                x=0.5,\n",
    "                y=-0.1,\n",
    "                xanchor='center',\n",
    "                yanchor='top',\n",
    "                orientation='h',\n",
    "                font=dict(size=14)),\n",
    "            width=1000,  # Set the width of the figure\n",
    "            height=800,\n",
    "            plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot background\n",
    "            paper_bgcolor='rgba(0,0,0,0)' )\n",
    "        # Show the plot\n",
    "        fig.show()\n",
    "        fig.write_image(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ash.png\")\n",
    "\n",
    "\n",
    "\n",
    "        # Pembuatan laporan singkat\n",
    "        layout_laporan1 = aprx.listLayouts(\"laporan_ash_pusat_1\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "        layout_laporan2 = aprx.listLayouts(\"laporan_ash_pusat_2\")[0]  # Adjust \"Layout\" to match your layout's name\n",
    "        # List all elements in the layout\n",
    "        elements1 = layout_laporan1.listElements()\n",
    "\n",
    "        # Print the names of all elements\n",
    "        for element in elements1:\n",
    "            if element.name == \"bulan\":\n",
    "                element.text = element.text.replace('[BULAN]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"peta\":\n",
    "                element.sourceImage = element.sourceImage.replace(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\map_ash_laporan.jpg\", r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\map_ash_laporan.jpg\") \n",
    "            elif element.name == \"deskripsi\":\n",
    "                element.text = element.text.replace('[WAKTU]', f'{current_month_name} {current_year}')\n",
    "                element.text = element.text.replace('[STI]', f'{atas_normal}')\n",
    "                element.text = element.text.replace('[NOR]', f'{normal}')\n",
    "                element.text = element.text.replace('[REN]', f'{bawah_normal}')\n",
    "                element.text = element.text.replace('[WILAYAH ATAS NORMAL]', f\"{wadmpr_by_kategori['Atas Normal']}\")\n",
    "                element.text = element.text.replace('[WILAYAH NORMAL]', f\"{wadmpr_by_kategori['Normal']}\")\n",
    "                element.text = element.text.replace('[WILAYAH BAWAH NORMAL]', f\"{wadmpr_by_kategori['Bawah Normal']}\")\n",
    "\n",
    "\n",
    "        # List all elements in the layout\n",
    "        elements2 = layout_laporan2.listElements()\n",
    "        # Print the names of all elements\n",
    "        for element in elements2:\n",
    "            if element.name == \"bulan\":\n",
    "                element.text = element.text.replace('[BULAN]', f'{current_month_name} {current_year}')\n",
    "            elif element.name == \"tabel\":\n",
    "                element.sourceImage = element.sourceImage.replace(os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Tabel', f'{tipe_name}_dataframe_image.png'), \n",
    "                                                                  os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Tabel', f'{tipe_name}_dataframe_image.png'))\n",
    "            elif element.name == \"chart\":\n",
    "                element.sourceImage = element.sourceImage.replace(r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ash.png\", \n",
    "                                                                  r\"D:\\Project\\BMKG SiPinter Iklim\\output_test\\Chart\\pelaporan__chart_ash.png\")  \n",
    "        \n",
    "\n",
    "        temp_pdf1 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\temp_laporan', 'temp1.pdf')\n",
    "        temp_pdf2 = os.path.join(r'D:\\Project\\BMKG SiPinter Iklim\\temp_laporan', 'temp2.pdf')\n",
    "\n",
    "        layout_laporan1.exportToPDF(temp_pdf1, resolution=300)\n",
    "        layout_laporan2.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "        # Combine PDFs\n",
    "        pdf_doc = arcpy.mp.PDFDocumentCreate(r'D:\\Project\\BMKG SiPinter Iklim\\output_test\\Laporan_Singkat\\laporan_pusat_ash_1.pdf')\n",
    "        pdf_doc.appendPages(temp_pdf1)\n",
    "        pdf_doc.appendPages(temp_pdf2)\n",
    "        pdf_doc.saveAndClose()\n",
    "\n",
    "        # Clean up temporary files\n",
    "        os.remove(temp_pdf1)\n",
    "        os.remove(temp_pdf2)\n",
    "\n",
    "        print(\"Pembuatan Laporan Singkat selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.gdb\\Polygon_ACH_Kalbar_Union\" ####### NANTI SESUAIKAN DENGAN PROSES PENGOLAHAN DATA\n",
    "sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "\n",
    "data = sdf2[['Kategori', 'WADMKK', 'WADMPR', 'area']]\n",
    "\n",
    "\n",
    "# Proses statistik wilayah Prov\n",
    "\n",
    "sum_area = data['area'].sum()\n",
    "cat_df = data.groupby(['Kategori', 'WADMPR'])['area'].sum()\n",
    "prov_df = round(cat_df / sum_area, 2)\n",
    "prov_df = prov_df.reset_index()\n",
    "prov_df = prov_df.rename({'area' : 'Persentase',}, axis='columns')\n",
    "prov_df['Persentase'] = round(prov_df['Persentase']*100,2)\n",
    "prov_df['Persentase%'] = round(prov_df['Persentase'],2).astype(str) + '%'\n",
    "prov_df.drop(prov_df.index[0], inplace=True)\n",
    "prov_df = prov_df[prov_df['WADMPR'].notna() & (prov_df['WADMPR'] != '')]\n",
    "remaining_sum_area = prov_df['Persentase'].sum()\n",
    "prov_df['Persentase'] = prov_df['Persentase'] / remaining_sum_area * 100\n",
    "prov_df['Persentase%'] = round(prov_df['Persentase'], 2).astype(str) + '%'\n",
    "# If you want to add a 'Provinsi' column based on 'WADMPR'\n",
    "# Assuming you want to use the first value of 'WADMPR' from the filtered data\n",
    "# Ensure all categories are present\n",
    "# Ensure all categories are present\n",
    "categories = ['Menengah', 'Tinggi', 'Sangat Tinggi', 'Rendah']\n",
    "for category in categories:\n",
    "    if category not in prov_df['Kategori'].unique():\n",
    "        new_row = pd.DataFrame({'Kategori': [category], 'WADMPR': [prov_df['WADMPR'].iloc[0]], 'Persentase': [0]})\n",
    "        prov_df = pd.concat([prov_df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "# Create the pivot table\n",
    "prov_df_pivot = pd.pivot_table(prov_df, values='Persentase', index='WADMPR', columns='Kategori', fill_value=0)\n",
    "prov_df_pivot = prov_df_pivot.reindex(columns=categories, fill_value=0).reset_index()\n",
    "prov_df_pivot.rename(columns={'WADMPR': 'Wilayah'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Proses statistik wilayah wilayah Kabupaten/Kpota\n",
    "kab_area_sum = data.groupby('WADMKK')['area'].sum()\n",
    "cat_df2 = data.groupby(['Kategori','WADMKK'])['area'].sum()\n",
    "kab_df = round(cat_df2 / kab_area_sum, 4)\n",
    "kab_df = kab_df.reset_index()\n",
    "kab_df = kab_df[(kab_df['Kategori'] != \"\") & (kab_df['area'] != 0)]\n",
    "kab_df['Persentase'] = round(kab_df['area']*100,2)\n",
    "kab_df = kab_df[kab_df['WADMKK'].notna() & (kab_df['WADMKK'] != '')]\n",
    "kab_df = kab_df.reset_index()\n",
    "kab_df.columns.name = None\n",
    "\n",
    "top_3_areas = kab_df.groupby('Kategori').apply(lambda x: x.nlargest(3, 'area')).reset_index(drop=True)\n",
    "wadmkk_by_kategori = top_3_areas.groupby('Kategori')['WADMKK'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "s_tinggi = kab_df.loc[kab_df['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "tinggi = kab_df.loc[kab_df['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "menengah = kab_df.loc[kab_df['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "categories = ['Menengah', 'Tinggi', 'Sangat Tinggi', 'Rendah']\n",
    "for category in categories:\n",
    "    if category not in kab_df['Kategori'].unique():\n",
    "        new_row = pd.DataFrame({'Kategori': [category], 'WADMKK': [kab_df['WADMKK'].iloc[0]], 'Persentase': [0]})\n",
    "        kab_df = pd.concat([kab_df, new_row], ignore_index=True)\n",
    "kab_df = pd.pivot(kab_df, index='WADMKK', columns='Kategori', values='Persentase')\n",
    "kab_df = kab_df.reset_index()\n",
    "kab_df.rename(columns={'WADMKK': 'Wilayah'}, inplace=True)\n",
    "kab_df = kab_df.fillna(0)\n",
    "kab_df = pd.concat([prov_df_pivot, kab_df], ignore_index=True)\n",
    "kab_df.iloc[:, 1:] = kab_df.iloc[:, 1:].div(kab_df.iloc[:, 1:].sum(axis=1), axis=0) * 100\n",
    "kab_df.iloc[:, 1:] = kab_df.iloc[:, 1:].round(2)\n",
    "new_order = ['Wilayah', 'Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "kab_df = kab_df[new_order]\n",
    "kab_df.to_csv('Table_Kalbar.csv')\n",
    "\n",
    "\n",
    "# Pembuatan chart laporan\n",
    "regions = kab_df['Wilayah']\n",
    "rendah_val = kab_df['Rendah']\n",
    "menengah_val = kab_df['Menengah']\n",
    "tinggi_val = kab_df['Tinggi']\n",
    "s_tinggi_val = kab_df['Sangat Tinggi']\n",
    "threshold=3.5  # threshold untuk ukuran bar memiliki label\n",
    "\n",
    "# Add text label\n",
    "rendah_text = [f'{val:.2f}%' if val >= threshold else '' for val in rendah_val]\n",
    "menengah_text = [f'{val:.2f}%' if val >= threshold else '' for val in menengah_val]\n",
    "tinggi_text = [f'{val:.2f}%' if val >= threshold else '' for val in tinggi_val]\n",
    "s_tinggi_text = [f'{val:.2f}%' if val >= threshold else '' for val in s_tinggi_val]\n",
    "\n",
    "\n",
    "# Create the plot\n",
    "# Create the plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Bar(y=regions,\n",
    "    x=rendah_val,\n",
    "    name='Rendah (%)',\n",
    "    orientation='h',\n",
    "    marker=dict(color='#8e2800'),\n",
    "    text=rendah_text,\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    y=regions,\n",
    "    x=menengah_val,\n",
    "    name='Menengah (%)',\n",
    "    orientation='h',\n",
    "    marker=dict(color='#eaff00'),\n",
    "    text=menengah_text,\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    y=regions,\n",
    "    x=tinggi_val,\n",
    "    name='Tinggi (%)',\n",
    "    orientation='h',\n",
    "    marker=dict(color='#8bd48b'),\n",
    "    text=tinggi_text,\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    y=regions,\n",
    "    x=s_tinggi_val,\n",
    "    name='Sangat Tinggi (%)',\n",
    "    orientation='h',\n",
    "    marker=dict(color='#00450c'),\n",
    "    text=s_tinggi_text,\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    title=dict(\n",
    "        text=f'Persentase Kategori CH',\n",
    "        font=dict(size=23, color='black', family='Arial Black') ),\n",
    "    xaxis=dict(title=dict(\n",
    "            text='Persentase (%)',\n",
    "            font=dict(size=14)  # Set the font size for the x-axis title\n",
    "        ),\n",
    "        tickfont=dict(size=14)),\n",
    "    yaxis=dict(\n",
    "        tickfont=dict(size=14)  # Set the font size for the y-axis ticks\n",
    "    ),\n",
    "    legend=dict(title=dict(\n",
    "            text='Kategori',\n",
    "            font=dict(size=14)), \n",
    "        x=0.5,\n",
    "        y=-0.1,\n",
    "        xanchor='center',\n",
    "        yanchor='top',\n",
    "        orientation='h',\n",
    "        font=dict(size=14)),\n",
    "    width=1000,  # Set the width of the figure\n",
    "    height=800,\n",
    "    plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot background\n",
    "    paper_bgcolor='rgba(0,0,0,0)' \n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kab_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wadmkk_by_kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "pulau=os.getenv(\"PULAU_REFERENCE\")\n",
    "grid_kecil= os.getenv(\"GRID_PKECIL\")\n",
    "grid_besar= os.getenv(\"GRID_PBESAR\")\n",
    "\n",
    "print(pulau, grid_kecil, grid_besar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "mosaic_bln_ch= os.getenv(\"MOSAIC_BLN_ACH\")\n",
    "\n",
    "output_level_ind = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "#output_level_prov2 = f'{prov}'\n",
    "output_tipe_bln = 'ANALISA-BULANAN'\n",
    "output_tipe_das = 'ANALISA-DASARIAN'\n",
    "output_tipe_peta1 = 'PETA-1'\n",
    "output_tipe_peta2 = 'PETA-2'\n",
    "output_tipe_csv = 'CSV'\n",
    "output_tipe_infografis = 'INFOGRAFIS'\n",
    "output_tipe_report = 'REPORT'\n",
    "output_tipe_tiff = 'TIFF'\n",
    "output_tipe_gdb = 'GDB'\n",
    "\n",
    "path_indo_bln_peta1 = os.path.join( output_folder, output_level_ind, output_tipe_bln, output_tipe_peta1)\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(path_indo_bln_peta1):\n",
    "    print(\"Path is exist\")\n",
    "else:\n",
    "    print('Not exist')\n",
    "\n",
    "print(path_indo_bln_peta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import extent_pulau, pulau_feature, titik_grid, nama_prov\n",
    "\n",
    "pulau_kecil = 'Kalbar'\n",
    "\n",
    "print(f'Nama panjang {pulau_kecil} adalah {nama_prov[pulau_kecil]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "from utils.dasarian import get_current_dasarian\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "current_dasarian = get_current_dasarian()\n",
    "\n",
    "\n",
    "output_prov = os.path.join(output_folder, output_level_prov)\n",
    "pulau_kecil = 'Kepri'\n",
    "\n",
    "output_prov_level1 = os.path.join(output_prov, f'{nama_prov[pulau_kecil]}')\n",
    "output_prov_level1_tiff_result = os.path.join(output_prov_level1, output_tipe_bln, output_tipe_tiff, f'{year}.{month}' )\n",
    "if not os.path.exists(output_prov_level1_tiff_result):\n",
    "    os.makedirs(output_prov_level1_tiff_result)\n",
    "else:\n",
    "    print(\"Already Exist\")\n",
    "\n",
    "print(output_prov_level1_tiff_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from config import extent_pulau, pulau_feature, titik_grid, nama_prov\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "output_folder = os.getenv('OUTPUT_FOLDER')\n",
    "output_level_indo = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA-BULANAN'\n",
    "output_tipe_das = 'ANALISA-DASARIAN'\n",
    "tipe = 'TIFF'\n",
    "\n",
    "pulau_kecil = 'NTT'\n",
    "\n",
    "\n",
    "\n",
    "pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "\n",
    "pembuatan_archiving.archive_indo(output_level_indo= output_level_indo, output_tipe_periode=output_tipe_bln, tipe=tipe)\n",
    "\n",
    "pembuatan_archiving.archive_prov(output_level_prov= output_level_prov, output_tipe_periode=output_tipe_das, tipe=tipe, nama_prov = nama_prov, pulau_kecil=pulau_kecil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from config import extent_pulau, pulau_feature, titik_grid, nama_prov\n",
    "\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "pulau_reference = os.getenv(\"PULAU_REFERENCE\")\n",
    "gridsize_pkecil = 0.001\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA-BULANAN_TEST'\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "current_dasarian = get_current_dasarian()\n",
    "\n",
    "input_data = os.path.join(fgdb_temp, 'output_2_proses1_feature_point_bln')\n",
    "\n",
    "i\n",
    "\n",
    "with arcpy.da.SearchCursor(pulau_reference, [[\"Pulau_Singkat\", [\"Is_Besar\"]]]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "        for r in cursors:\n",
    "            \n",
    "            if r[1] == \"False\":  # val False = Pulau Kecil dan va True = Pulau Besar\n",
    "                pulau_kecil = r[0]\n",
    "                print(f\"Memulai Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "\n",
    "                ####### Proses untuk kategori pulau kecil\\\n",
    "                ####### Proses ACH untuk kategori pulau kecil\n",
    "                # Create new folder\n",
    "                \n",
    "                pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                    output_tipe_periode=output_tipe_bln, tipe='TIFF', \n",
    "                                                                    nama_prov=nama_prov, pulau_kecil=pulau_kecil)\n",
    "\n",
    "                # Start Process\n",
    "\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features= input_data,\n",
    "                        z_field=\"CH\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(output_loc_tiff, f\"ach_bln_{pulau_kecil}_ver_{year}{month}\"),\n",
    "                        cell_size=gridsize_pkecil,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "                raster_ach_pk = arcpy.Raster(os.path.join(output_loc_tiff, f\"ach_bln_{pulau_kecil}_ver_{year}{month}.tif\"))\n",
    "\n",
    "                print(f\"Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "                # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "                # arcpy.management.AddRastersToMosaicDataset(\n",
    "                #                 in_mosaic_dataset= mosaic_bln_ch,\n",
    "                #                 raster_type=\"Raster Dataset\",\n",
    "                #                 input_path= raster_ach_pk,\n",
    "                #                 update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                #                 update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                #                 update_overviews=\"NO_OVERVIEWS\",\n",
    "                #                 maximum_pyramid_levels=None,\n",
    "                #                 maximum_cell_size=0,\n",
    "                #                 minimum_dimension=1500,\n",
    "                #                 spatial_reference=None,\n",
    "                #                 filter=\"\",\n",
    "                #                 sub_folder=\"SUBFOLDERS\",\n",
    "                #                 duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                #                 build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                #                 calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                #                 build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                #                 operation_description=\"\",\n",
    "                #                 force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                #                 estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                #                 aux_inputs=None,\n",
    "                #                 enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                #                 cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "                # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai ...\")\n",
    "\n",
    "                pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                output_loc_csv = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                    output_tipe_periode=output_tipe_bln, tipe='CSV', \n",
    "                                                                    nama_prov=nama_prov, pulau_kecil=pulau_kecil)\n",
    "                \n",
    "\n",
    "                titik_grid_extract_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}\")\n",
    "                arcpy.management.CopyFeatures(in_features=titik_grid[pulau_kecil], out_feature_class=titik_grid_extract_pk)\n",
    "                point_extracted_pk = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pk, [[raster_ach_pk, \"CH\"]], \"NONE\")\n",
    "                # point_extracted_ch.save()\n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} selesai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"out_raster_path: {output_loc_tiff} (type: {type(output_loc_tiff)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(month_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.analysis.Union(\n",
    "    in_features=\"idkec #;ash_bln_indo_ver_2024009 #\",\n",
    "    out_feature_class=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\BMKG_SiPinter.gdb\\idkec_Union\",\n",
    "    join_attributes=\"ALL\",\n",
    "    cluster_tolerance=None,\n",
    "    gaps=\"GAPS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "for root, dirs, files in os.walk(fgdb_temp):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = arcpy.ListDatasets(\"*\", \"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.proses1_archiving import ArchivingFolder\n",
    "nama_provinsi = \n",
    "\n",
    "buat_archive = ArchivingFolder()\n",
    "\n",
    "output_loc = buat_archive.archive_prov(output_tipe_periode='ANALISA-DASARIAN', output_level_prov='PROVINSI', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import arcpy\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "prov_referensi = os.getenv(\"POLY_PROV\")\n",
    "\n",
    "with arcpy.da.SearchCursor(prov_referensi, \"WADMPR\") as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "        wilayah_ref = r[0].lower()\n",
    "        print(wilayah_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['WADMPR']\n",
    "\n",
    "prov_referensi = os.getenv(\"POLY_PROV\")\n",
    "# Gunakan SearchCursor untuk membaca data\n",
    "with arcpy.da.SearchCursor(prov_referensi, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        # Akses nilai dari kolom WADMPR\n",
    "        wadmpr_value = row[0]\n",
    "        \n",
    "        # Lakukan sesuatu dengan nilai tersebut\n",
    "        print(f\"WADMPR: {wadmpr_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from config import nama_stasiun, nama_prov\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "prov_referensi = os.getenv(\"POLY_PROV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from config import nama_stasiun, nama_prov\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "\n",
    "\n",
    "# arcpy \n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "prov_referensi = os.getenv(\"POLY_PROV\")\n",
    "# Set waktu\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian = get_current_dasarian()\n",
    "\n",
    "aprx = arcpy.mp.ArcGISProject(r\"C:\\Users\\mjanuadi\\OneDrive - ESRI Indonesia\\Documents\\ArcGIS\\Packages\\bmkg_layout_d8ba3d\\p30\\bmkg_peta_cuaca1.aprx\")\n",
    "layout = aprx.listLayouts(\"peta1_upt1\") [0]\n",
    "\n",
    "map_frame_ch = layout.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame CH')[0]\n",
    "map_obj_ch = map_frame_ch.map\n",
    "prov_layer_ch = map_obj_ch.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_ch = map_obj_ch.listLayers(\"admin_kab\")[0]\n",
    "inset_frame_ch = layout.listElements(\"MAPFRAME_ELEMENT\", 'Inset CH')[0]\n",
    "inset_obj_ch = inset_frame_ch.map\n",
    "inset_prov_layer = inset_obj_ch.listLayers(\"admin_prov\")[0]\n",
    "\n",
    "\n",
    "map_frame_sh = layout.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame SH')[0]\n",
    "map_obj_sh = map_frame_sh.map\n",
    "prov_layer_sh = map_obj_sh.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_sh = map_obj_sh.listLayers(\"admin_kab\")[0]\n",
    "inset_frame_sh = layout.listElements(\"MAPFRAME_ELEMENT\", 'Inset SH')[0]\n",
    "inset_obj_sh = inset_frame_sh.map\n",
    "\n",
    "\n",
    "layers_to_hide = [prov_layer_ch, prov_layer_sh, inset_prov_layer]\n",
    "layers_to_show = [kab_layer_ch, kab_layer_sh]\n",
    "periode_informasi = 'ANALISA-DASARIAN'\n",
    "\n",
    "def store_initial_state(original_layout):\n",
    "    initial_state = {}\n",
    "    elements = original_layout.listElements()\n",
    "    for element in elements:\n",
    "        if hasattr(element, 'text'):\n",
    "            initial_state[element.name] = element.text\n",
    "    return initial_state\n",
    "\n",
    "# Function to reset elements to their initial state\n",
    "def reset_elements(modified_layout, initial_state):\n",
    "    elements = modified_layout.listElements()\n",
    "    for element in elements:\n",
    "        if element.name in initial_state:\n",
    "            try:\n",
    "                element.text = initial_state[element.name]\n",
    "            except Exception as e:\n",
    "                print(f\"Error resetting element '{element.name}': {e}\")\n",
    "\n",
    "with arcpy.da.SearchCursor(prov_referensi, [\"WADMPR\", \"SHAPE@\"]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "        wilayah_ref = r[0]\n",
    "        prov_geometry = r[1]\n",
    "        if wilayah_ref == 'Indonesia':\n",
    "            layout = aprx.listLayouts(\"peta_1_pusat\")[0]\n",
    "            print(wilayah_ref)\n",
    "\n",
    "            if periode_informasi == 'ANALISA-BULANAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                output_tipe_periode='ANALISA-BULANAN', tipe='PETA 1')\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                       \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                       \n",
    "\n",
    "                output_file = os.path.join(output_loc_peta1, f\"ach_bln_indo_ver_{year}{month}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                print(\"Peta 1 Sukses\")\n",
    "\n",
    "                \n",
    "            else:\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                output_tipe_periode='ANALISA-DASARIAN', tipe='PETA 1')\n",
    "                \n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "                        \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "                  \n",
    "                        \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta1, f\"ach_das_indo_ver_{year}{month}das0{current_dasarian}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                print(\"Peta 1 Sukses\")\n",
    "            \n",
    "              \n",
    "        \n",
    "\n",
    "        elif wilayah_ref == 'Jatim':\n",
    "            layout = aprx.listLayouts(\"Peta1_Jawa Timur\")[0]\n",
    "\n",
    "            if periode_informasi == 'ANALISA-BULANAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-BULANAN', tipe='PETA 1', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                       \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                       \n",
    "                   \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta1, f\"ach_bln_jatim_ver_{year}{month}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "\n",
    "                \n",
    "            else:\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-DASARIAN', tipe='PETA 1', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "                        \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "                  \n",
    "                        \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta1, f\"ach_das_jatim_ver_{year}{month}das0{current_dasarian}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "\n",
    "            \n",
    "        \n",
    "        elif wilayah_ref == 'Kepri':\n",
    "            layout = aprx.listLayouts(\"Peta1_Kepulauan Riau\")[0]\n",
    "\n",
    "            if periode_informasi == 'ANALISA-BULANAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-BULANAN', tipe='PETA 1', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta1, f\"ach_bln_kepri_ver_{year}{month}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "\n",
    "                \n",
    "            else:\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-DASARIAN', tipe='PETA 1', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "                   \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta1, f\"ach_das_kepri_ver_{year}{month}das0{current_dasarian}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "            \n",
    "\n",
    "        elif wilayah_ref == 'Sulut':\n",
    "            layout = aprx.listLayouts(\"Peta1_Sulawesi Utara\")[0]\n",
    "\n",
    "            if periode_informasi == 'ANALISA-BULANAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-BULANAN', tipe='PETA 1', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                     \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                       \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta1, f\"ach_bln_sulut_ver_{year}{month}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                print(\"Peta 1 sucess\")\n",
    "\n",
    "                \n",
    "            else:\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-DASARIAN', tipe='PETA 1', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN 0{current_dasarian} {month_name.upper()} {year}')\n",
    "                        \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN 0{current_dasarian} {month_name.upper()} {year}')\n",
    "                    \n",
    "                   \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta1, f\"ach_das_sulut_ver_{year}{month}das0{current_dasarian}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "\n",
    "                print(\"Peta 1 sucess\")\n",
    "        \n",
    "        else:\n",
    "\n",
    "        \n",
    "            layout = aprx.listLayouts(\"peta1_upt1\")[0]\n",
    "            initial_state = store_initial_state(layout)\n",
    "\n",
    "            if periode_informasi == 'ANALISA-BULANAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-BULANAN', tipe='PETA 1', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                \n",
    "                map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "                map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "                \n",
    "\n",
    "                for layer in layers_to_hide:\n",
    "                    if layer: \n",
    "                        try:\n",
    "                            layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                for layer in layers_to_show:\n",
    "                    if layer: \n",
    "                        try:\n",
    "                            layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                \n",
    "\n",
    "                elements = layout.listElements()\n",
    "                \n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        try:\n",
    "                            # Update the text by replacing placeholders\n",
    "                           \n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error updating element '{element.name}': {e}\")\n",
    "                     \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        try:\n",
    "                            # Update the text by replacing placeholders\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error updating element '{element.name}': {e}\")\n",
    "\n",
    "                    \n",
    "                    elif element.name == \"Teks-stasiun-ch\":\n",
    "                        element.text = element.text.replace('[STASIUN]', f'{nama_stasiun[wilayah_ref]}')\n",
    "\n",
    "                    elif element.name == \"Teks-stasiun-sh\":\n",
    "                        element.text = element.text.replace('[STASIUN]', f'{nama_stasiun[wilayah_ref]}')\n",
    "                \n",
    "       \n",
    "\n",
    "                output_file = os.path.join(output_loc_peta1, f\"ach_bln_{wilayah_ref.lower()}_ver_{year}{month}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                \n",
    "\n",
    "                reset_elements(layout, initial_state)\n",
    "                print(\"Peta 1 sucess\")\n",
    "\n",
    "                \n",
    "            else:\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-DASARIAN', tipe='PETA 1', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                \n",
    "                map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "                map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "                \n",
    "                \n",
    "\n",
    "                for layer in layers_to_hide:\n",
    "                    if layer: \n",
    "                        try:\n",
    "                            layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                for layer in layers_to_show:\n",
    "                    if layer: \n",
    "                        try:\n",
    "                            layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                \n",
    "\n",
    "                elements = layout.listElements()\n",
    "                print(nama_prov[wilayah_ref])\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        try:\n",
    "                            # Update the text by replacing placeholders\n",
    "                            \n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN 0{current_dasarian} {month_name.upper()} {year}')\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error updating element '{element.name}': {e}\")\n",
    "                        \n",
    "                        \n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        try:\n",
    "                            # Update the text by replacing placeholders\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN 0{current_dasarian} {month_name.upper()} {year}')\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error updating element '{element.name}': {e}\")\n",
    "                    \n",
    "\n",
    "                    elif element.name == \"Teks-stasiun-ch\":\n",
    "                        element.text = element.text.replace('[STASIUN]', f'{nama_stasiun[wilayah_ref]}')\n",
    "\n",
    "                    elif element.name == \"Teks-stasiun-sh\":\n",
    "                        element.text = element.text.replace('[STASIUN]', f'{nama_stasiun[wilayah_ref]}')\n",
    "\n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta1, f\"ach_das_{wilayah_ref.lower()}_ver_{year}{month}das0{current_dasarian}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "\n",
    "                \n",
    "                reset_elements(layout, initial_state)\n",
    "                print(\"Peta 1 success\")\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from config import nama_stasiun, nama_prov\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "\n",
    "\n",
    "# arcpy \n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "prov_referensi = os.getenv(\"POLY_PROV\")\n",
    "# Set waktu\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian = get_current_dasarian()\n",
    "\n",
    "aprx = arcpy.mp.ArcGISProject(r\"C:\\Users\\mjanuadi\\OneDrive - ESRI Indonesia\\Documents\\ArcGIS\\Packages\\bmkg_layout_d8ba3d\\p30\\bmkg_peta_cuaca1.aprx\")\n",
    "layout = aprx.listLayouts(\"peta2_upt1\") [0]\n",
    "\n",
    "map_frame_ch = layout.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame CH')[0]\n",
    "map_obj_ch = map_frame_ch.map\n",
    "prov_layer_ch = map_obj_ch.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_ch = map_obj_ch.listLayers(\"admin_kab\")[0]\n",
    "inset_frame_ch = layout.listElements(\"MAPFRAME_ELEMENT\", 'Inset CH')[0]\n",
    "inset_obj_ch = inset_frame_ch.map\n",
    "inset_prov_layer = inset_obj_ch.listLayers(\"admin_prov\")[0]\n",
    "\n",
    "\n",
    "map_frame_sh = layout.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame SH')[0]\n",
    "map_obj_sh = map_frame_sh.map\n",
    "prov_layer_sh = map_obj_sh.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_sh = map_obj_sh.listLayers(\"admin_kab\")[0]\n",
    "inset_frame_sh = layout.listElements(\"MAPFRAME_ELEMENT\", 'Inset SH')[0]\n",
    "inset_obj_sh = inset_frame_sh.map\n",
    "\n",
    "\n",
    "layers_to_hide = [prov_layer_ch, prov_layer_sh, inset_prov_layer]\n",
    "layers_to_show = [kab_layer_ch, kab_layer_sh]\n",
    "periode_informasi = 'ANALISA-DASARIAN'\n",
    "\n",
    "def store_initial_state(original_layout):\n",
    "    initial_state = {}\n",
    "    elements = original_layout.listElements()\n",
    "    for element in elements:\n",
    "        if hasattr(element, 'text'):\n",
    "            initial_state[element.name] = element.text\n",
    "    return initial_state\n",
    "\n",
    "# Function to reset elements to their initial state\n",
    "def reset_elements(modified_layout, initial_state):\n",
    "    elements = modified_layout.listElements()\n",
    "    for element in elements:\n",
    "        if element.name in initial_state:\n",
    "            try:\n",
    "                element.text = initial_state[element.name]\n",
    "            except Exception as e:\n",
    "                print(f\"Error resetting element '{element.name}': {e}\")\n",
    "\n",
    "with arcpy.da.SearchCursor(prov_referensi, [\"WADMPR\", \"SHAPE@\"]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "        wilayah_ref = r[0]\n",
    "        prov_geometry = r[1]\n",
    "        if wilayah_ref == 'Indonesia':\n",
    "            layout = aprx.listLayouts(\"peta_1_pusat\")[0]\n",
    "            print(wilayah_ref)\n",
    "\n",
    "            if periode_informasi == 'ANALISA-BULANAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta2 = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                output_tipe_periode='ANALISA-BULANAN', tipe='PETA 2')\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                       \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                       \n",
    "\n",
    "                output_file = os.path.join(output_loc_peta2, f\"ach_bln_indo_ver_{year}{month}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                print(\"Peta 1 Sukses\")\n",
    "\n",
    "                \n",
    "            else:\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta2 = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                output_tipe_periode='ANALISA-DASARIAN', tipe='PETA 2')\n",
    "                \n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "                        \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "                  \n",
    "                        \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta2, f\"ach_das_indo_ver_{year}{month}das0{current_dasarian}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                print(\"Peta 1 Sukses\")\n",
    "            \n",
    "              \n",
    "        \n",
    "\n",
    "        elif wilayah_ref == 'Jatim':\n",
    "            layout = aprx.listLayouts(\"peta2_jatim\")[0]\n",
    "\n",
    "            if periode_informasi == 'ANALISA-BULANAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta2 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-BULANAN', tipe='PETA 2', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                       \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                       \n",
    "                   \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta2, f\"ach_bln_jatim_ver_{year}{month}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "\n",
    "                \n",
    "            else:\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta2 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-DASARIAN', tipe='PETA 2', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "                        \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "                  \n",
    "                        \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta2, f\"ach_das_jatim_ver_{year}{month}das0{current_dasarian}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "\n",
    "            \n",
    "        \n",
    "        elif wilayah_ref == 'Kepri':\n",
    "            layout = aprx.listLayouts(\"peta2_kepri\")[0]\n",
    "\n",
    "            if periode_informasi == 'ANALISA-BULANAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta2 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-BULANAN', tipe='PETA 2', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta2, f\"ach_bln_kepri_ver_{year}{month}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "\n",
    "                \n",
    "            else:\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta1 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-DASARIAN', tipe='PETA 2', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "                   \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian} {month_name.upper()} {year}')\n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta2, f\"ach_das_kepri_ver_{year}{month}das0{current_dasarian}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "            \n",
    "\n",
    "        elif wilayah_ref == 'Sulut':\n",
    "            layout = aprx.listLayouts(\"peta2_sulut\")[0]\n",
    "\n",
    "            if periode_informasi == 'ANALISA-BULANAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta2 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-BULANAN', tipe='PETA 2', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                     \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                       \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta2, f\"ach_bln_sulut_ver_{year}{month}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                print(\"Peta 1 sucess\")\n",
    "\n",
    "                \n",
    "            else:\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta2 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-DASARIAN', tipe='PETA 2', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                elements = layout.listElements()\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN 0{current_dasarian} {month_name.upper()} {year}')\n",
    "                        \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        element.text = element.text.replace('[WAKTU]', f'DASARIAN 0{current_dasarian} {month_name.upper()} {year}')\n",
    "                    \n",
    "                   \n",
    "\n",
    "\n",
    "                output_file = os.path.join(output_loc_peta2, f\"ach_das_sulut_ver_{year}{month}das0{current_dasarian}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "\n",
    "                print(\"Peta 1 sucess\")\n",
    "        \n",
    "        else:\n",
    "\n",
    "        \n",
    "            layout = aprx.listLayouts(\"peta2_upt1\")[0]\n",
    "            initial_state = store_initial_state(layout)\n",
    "\n",
    "            if periode_informasi == 'ANALISA-BULANAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta2 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-BULANAN', tipe='PETA 2', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                \n",
    "                map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "                map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "                # inset_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "                # inset_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                for layer in layers_to_hide:\n",
    "                    if layer: \n",
    "                        try:\n",
    "                            layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                for layer in layers_to_show:\n",
    "                    if layer: \n",
    "                        try:\n",
    "                            layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                \n",
    "\n",
    "                elements = layout.listElements()\n",
    "                \n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        try:\n",
    "                            # Update the text by replacing placeholders\n",
    "                           \n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error updating element '{element.name}': {e}\")\n",
    "                     \n",
    "\n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        try:\n",
    "                            # Update the text by replacing placeholders\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error updating element '{element.name}': {e}\")\n",
    "\n",
    "       \n",
    "\n",
    "                output_file = os.path.join(output_loc_peta2, f\"ach_bln_{wilayah_ref.lower()}_ver_{year}{month}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                \n",
    "\n",
    "                reset_elements(layout, initial_state)\n",
    "                print(\"Peta 2 sucess\")\n",
    "\n",
    "                \n",
    "            else:\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_peta2 = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                output_tipe_periode='ANALISA-DASARIAN', tipe='PETA 2', \n",
    "                                                                nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                \n",
    "                map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "                map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "                # inset_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "                # inset_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "                \n",
    "\n",
    "                for layer in layers_to_hide:\n",
    "                    if layer: \n",
    "                        try:\n",
    "                            layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                for layer in layers_to_show:\n",
    "                    if layer: \n",
    "                        try:\n",
    "                            layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                \n",
    "\n",
    "                elements = layout.listElements()\n",
    "                print(nama_prov[wilayah_ref])\n",
    "                for element in elements:\n",
    "                    if element.name == 'Teks-Judul-CH':\n",
    "                        try:\n",
    "                            # Update the text by replacing placeholders\n",
    "                            \n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN 0{current_dasarian} {month_name.upper()} {year}')\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error updating element '{element.name}': {e}\")\n",
    "                        \n",
    "                        \n",
    "                    elif element.name == 'Teks-Judul-SH':\n",
    "                        try:\n",
    "                            # Update the text by replacing placeholders\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN 0{current_dasarian} {month_name.upper()} {year}')\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error updating element '{element.name}': {e}\")\n",
    "                    \n",
    "\n",
    "                output_file = os.path.join(output_loc_peta2, f\"ach_das_{wilayah_ref.lower()}_ver_{year}{month}das0{current_dasarian}.png\")\n",
    "                layout.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "\n",
    "                \n",
    "                reset_elements(layout, initial_state)\n",
    "                print(\"Peta 2 success\")\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "import os\n",
    "load_dotenv()\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "\n",
    "map_project = os.getenv(\"APRX_PROJECT\")\n",
    "\n",
    "pembuatan_peta = PembuatanPetaLaporan(map_project)\n",
    "# pembuatan_peta.peta_1(periode_informasi='ANALISA-BULANAN')\n",
    "# pembuatan_peta.peta_1(periode_informasi='ANALISA-DASARIAN')\n",
    "pembuatan_peta.peta_2(periode_informasi='ANALISA-BULANAN')\n",
    "pembuatan_peta.peta_2(periode_informasi='ANALISA-DASARIAN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "import os\n",
    "load_dotenv()\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "from utils.proses1_dataframe_process import dataframe_indo\n",
    "from utils.proses1_chart import chart_infografis_sh, chart_infografis_ch\n",
    "map_project = os.getenv(\"APRX_PROJECT\")\n",
    "\n",
    "\n",
    "feature = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ash_bln_indo_ver_202409.shp\"\n",
    "\n",
    "indo_df, pulau_df_complete, top_by_kategori, _, _, _ = dataframe_indo(feature=feature, tipe_informasi='ANALISA SIFAT HUJAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_by_kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.proses1_chart import chart_infografis_sh\n",
    "\n",
    "chart_infografis_sh(dataframe=indo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ach_bln_indo_ver_202409.shp\"\n",
    "indo_df, pulau_df_complete, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_indo(feature=feature, tipe_informasi='ANALISA CURAH HUJAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_infografis_ch(dataframe=indo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "tipe = 'ANAlISA CURAH HUJAN'\n",
    "\n",
    "fig = px.bar(indo_df, x='Kategori', y='Persentase', width=800, height=400, text='Persentase%')\n",
    "fig.update_xaxes(categoryorder='array', categoryarray= ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi'])\n",
    "fig.update_traces(marker_color=['#ffff00','#8e2800', '#00450c','#8bd48b' ], showlegend=False)\n",
    "fig.update_layout(yaxis_range=[0,100], xaxis_title=f'{tipe}',)\n",
    "fig.update_traces(width=0.95)\n",
    "fig.update_xaxes(visible=False, showticklabels=False)\n",
    "fig.update_traces(textposition='inside', textfont=dict(size=16, family='Arial Black', color='black'), insidetextanchor='middle')\n",
    "fig.update_traces(marker_line_color='black', marker_line_width=3.5, marker_line=dict(color='#fff', width=1), marker=dict(line_color='black'))\n",
    "\n",
    "textpositions = []\n",
    "for bar in fig.data[0].y:\n",
    "    if bar < 10:  # Adjust this threshold as needed\n",
    "        textpositions.append('outside')\n",
    "    else:\n",
    "        textpositions.append('inside')\n",
    "\n",
    "fig.update_traces(textposition=textpositions, textfont=dict(size=16), insidetextanchor='middle')\n",
    "fig.update_layout(\n",
    "    xaxis_title_font=dict(size=15, color='black', family=\"Arial\"),\n",
    "    yaxis_title_font=dict(size=18, color='black', family=\"Arial\"),\n",
    "    font=dict(size=14, color='black'),\n",
    "    plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot area background\n",
    "    paper_bgcolor='rgba(0,0,0,0)'  # Transparent paper background\n",
    "\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"figure.png\", engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipe_informasi = 'ANALISA CURAH HUJAN'\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "# Determine color and order based on 'tipe_informasi'\n",
    "\n",
    "if tipe_informasi == 'ANALISA SIFAT HUJAN':\n",
    "    categories = ['Bawah Normal', 'Normal', 'Atas Normal']\n",
    "    colors = ['#340900', '#eaff00', '#00450c']\n",
    "else:\n",
    "    categories = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "    colors = ['#ffff00', '#8e2800', '#00450c', '#8bd48b']\n",
    "\n",
    "# Reorder DataFrame based on categories\n",
    "indo_df['Kategori'] = pd.Categorical(indo_df['Kategori'], categories=categories)\n",
    "indo_df = indo_df.sort_values('Kategori')\n",
    "\n",
    "# Plot bars\n",
    "bars = ax.bar(indo_df['Kategori'], indo_df['Persentase'], color=colors, edgecolor='black', linewidth=0.5, width=0.95)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    if height < 10:  # Adjust this threshold as needed\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height}%', ha='center', va='bottom', fontsize=16, fontweight='bold')\n",
    "    else:\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height / 2, f'{height}%', ha='center', va='center', fontsize=16, fontweight='bold', color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from config import nama_stasiun, nama_prov\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "\n",
    "\n",
    "tipe_informasi = 'ANALISA CURAH HUJAN'\n",
    "\n",
    "output_location = os.getenv(\"ASSET\")\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "# Determine color and order based on 'tipe_informasi'\n",
    "\n",
    "if tipe_informasi == 'ANALISA SIFAT HUJAN':\n",
    "    categories = ['Bawah Normal', 'Normal', 'Atas Normal']\n",
    "    colors = ['#340900', '#eaff00', '#00450c']\n",
    "else:\n",
    "    categories = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "    colors = ['#340900', '#ffff00', '#8bd48b', '#00450c']\n",
    "\n",
    "# Reorder DataFrame based on categories\n",
    "indo_df['Kategori'] = pd.Categorical(indo_df['Kategori'], categories=categories)\n",
    "indo_df = indo_df.sort_values('Kategori')\n",
    "\n",
    "# Plot bars\n",
    "bars = ax.bar(indo_df['Kategori'], indo_df['Persentase'], color=colors, edgecolor='black', linewidth=0.5, width=0.95)\n",
    "\n",
    "# Add text labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    if height < 10:  # Adjust this threshold as needed\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height}%', ha='center', va='bottom', fontsize=16, fontweight='bold')\n",
    "    else:\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height / 2, f'{height}%', ha='center', va='center', fontsize=16, fontweight='bold', color='black')\n",
    "# Set y-axis range and labels\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_ylabel('Persentase', fontsize=18, color='black', fontfamily=\"Arial\")\n",
    "# Remove x-axis ticks and labels\n",
    "ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# Set background color to transparent\n",
    "fig.patch.set_alpha(0)\n",
    "ax.patch.set_alpha(0)\n",
    "# Set plot background color to transparent\n",
    "ax.set_facecolor('none')\n",
    "# Add gridlines for y-axis\n",
    "ax.yaxis.grid(True, color='grey', linestyle='--', linewidth=0.5, zorder=0)\n",
    "# Set bars zorder to 2 to ensure they are in front of the gridlines\n",
    "for bar in bars:\n",
    "    bar.set_zorder(2)\n",
    "# Save the figure\n",
    "fig.savefig(os.path.join(output_location,'chart', 'infografis', 'chart_infografis.png'), dpi=300, bbox_inches='tight', transparent=True)\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_infografis(dataframe = indo_df, tipe_informasi='ANALISA SIFAT HUJAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ash_bln_indo_ver_202409.shp\"\n",
    "sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "data = sdf2[['Kategori', 'PROPINSI', 'Pulau_B', 'Area_H']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_area = data['Area_H'].sum()\n",
    "cat_df = data.groupby('Kategori')['Area_H'].sum()\n",
    "indo_df = round(cat_df / sum_area, 4)\n",
    "indo_df = indo_df.reset_index()\n",
    "indo_df = indo_df.rename({'Area_H' : 'Persentase',}, axis='columns')\n",
    "indo_df['Persentase'] = round(indo_df['Persentase']*100,2)\n",
    "indo_df['Persentase%'] = round(indo_df['Persentase'],2).astype(str) + '%'\n",
    "indo_df.drop(indo_df.index[0], inplace=True)\n",
    "indo_df[\"Wilayah\"] = 'Indonesia'\n",
    "indo_df_pivot = pd.pivot(indo_df, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "indo_df_pivot = indo_df_pivot.reset_index()\n",
    "indo_df_pivot.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indo_df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_area_sum = data.groupby('PROPINSI')['Area_H'].sum()\n",
    "cat_df2 = data.groupby(['Kategori','PROPINSI'])['Area_H'].sum()\n",
    "prov_df = round(cat_df2 / province_area_sum, 4)\n",
    "prov_df = prov_df.reset_index()\n",
    "prov_df = prov_df.dropna(subset=['Kategori'])\n",
    "prov_df = prov_df[(prov_df['Kategori'] != ' ' ) ]\n",
    "prov_df['Persentase%'] = round(prov_df['Area_H']*100,2).astype(str) + '%'\n",
    "\n",
    "# Make sure all categories exist in each province. If not, make it 0 for that ctegories\n",
    "categories = ['Bawah Normal', 'Normal', 'Atas Normal']\n",
    "all_combinations = pd.MultiIndex.from_product([prov_df['PROPINSI'].unique(), categories], names=['PROPINSI', 'Kategori']).to_frame(index=False)\n",
    "complete_df = all_combinations.merge(prov_df, on=['PROPINSI', 'Kategori'], how='left')\n",
    "complete_df['Area_H'] = complete_df['Area_H'].fillna(0)\n",
    "complete_df['Persentase%'] = complete_df['Persentase%'].fillna('0%')\n",
    "complete_df['Persentase%'] = complete_df['Persentase%'].str.rstrip('%').astype(float)\n",
    "\n",
    "# Adjust percentages so that they sum up to 100% for each PROPINSI\n",
    "def adjust_percentages(group):\n",
    "    total_percentage = group['Persentase%'].sum()\n",
    "    if total_percentage != 100:\n",
    "        adjustment_factor = 100 / total_percentage\n",
    "        group['Persentase%'] = group['Persentase%'] * adjustment_factor\n",
    "    return group\n",
    "\n",
    "complete_df = complete_df.groupby('PROPINSI').apply(adjust_percentages)\n",
    "complete_df = complete_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Convert 'Persentase%' back to string format with '%' sign\n",
    "complete_df['Persentase%'] = complete_df['Persentase%'].round(2).astype(str) + '%'\n",
    "\n",
    "\n",
    "top_13_areas = complete_df.groupby('Kategori').apply(lambda x: x.nlargest(13, 'Area_H')).reset_index(drop=True)\n",
    "wadmpr_by_kategori = top_13_areas.groupby('Kategori')['PROPINSI'].apply(lambda x: ', '.join(x)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wadmpr_by_kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgt_tinggi = indo_df.loc[indo_df['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "tinggi = indo_df.loc[indo_df['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "rendah = indo_df.loc[indo_df['Kategori'] == 'Rendah', 'Persentase'].values[0]\n",
    "menengah =  indo_df.loc[indo_df['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "# Proses statistik wilayah Pulau Besar\n",
    "pulau_area_sum = data.groupby('Pulau_B')['Area_H'].sum()\n",
    "cat_df3 = data.groupby(['Kategori','Pulau_B'])['Area_H'].sum()\n",
    "pulau_df = round(cat_df3 / pulau_area_sum, 4)\n",
    "pulau_df = pulau_df.reset_index()\n",
    "pulau_df = pulau_df[(pulau_df['Kategori'] != \" \") | (pulau_df['Pulau_B'] != \" \")]\n",
    "pulau_df['Persentase'] = round(pulau_df['Area_H']*100, 2)\n",
    "categories = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "all_combinations = pd.MultiIndex.from_product([pulau_df['Pulau_B'].unique(), categories], names=['Pulau_B', 'Kategori']).to_frame(index=False)\n",
    "pulau_df_complete = all_combinations.merge(pulau_df, on=['Pulau_B', 'Kategori'], how='left')\n",
    "pulau_df_complete['Area_H'] = pulau_df_complete['Area_H'].fillna(0)\n",
    "pulau_df_complete['Persentase'] = pulau_df_complete['Persentase'].fillna(0)\n",
    "pulau_df_complete = pulau_df_complete[(pulau_df_complete['Kategori'] != \" \") & (pulau_df_complete['Pulau_B'] != \" \")]\n",
    "pulau_df_complete = pd.pivot(pulau_df_complete, index='Pulau_B', columns='Kategori', values='Persentase')\n",
    "pulau_df_complete = pulau_df_complete.reset_index()\n",
    "pulau_df_complete.columns.name = None\n",
    "pulau_df_complete.drop(pulau_df_complete.index[0], inplace=True)\n",
    "pulau_df_complete = pulau_df_complete.rename(columns={'Pulau_B': 'Wilayah'})\n",
    "pulau_df_complete = pd.concat([indo_df_pivot, pulau_df_complete], ignore_index=True)\n",
    "\n",
    "def adjust_percentages(row):\n",
    "    categories = ['Menengah', 'Rendah', 'Sangat Tinggi', 'Tinggi']\n",
    "    total = sum(row[categories])\n",
    "    rounded = [round(row[cat], 2) for cat in categories]\n",
    "    rounded_total = sum(rounded)\n",
    "    \n",
    "    # Distribute the rounding error\n",
    "    difference = 100 - rounded_total\n",
    "    if difference != 0:\n",
    "        # Find the category with the largest fractional part to adjust\n",
    "        fractional_parts = [(row[cat] - int(row[cat])) for cat in categories]\n",
    "        index_to_adjust = fractional_parts.index(max(fractional_parts))\n",
    "        rounded[index_to_adjust] += difference\n",
    "    \n",
    "    return pd.Series(rounded, index=categories)\n",
    "\n",
    "# Apply the adjustment\n",
    "pulau_df_complete[['Menengah', 'Rendah', 'Sangat Tinggi', 'Tinggi']] = pulau_df_complete.apply(adjust_percentages, axis=1)\n",
    "\n",
    "# pulau_df_complete.iloc[:, 1:] = pulau_df_complete.iloc[:, 1:].round(2)\n",
    "pulau_df_complete = pulau_df_complete.rename(columns={'Rendah': 'Rendah (%)', 'Menengah': 'Menengah (%)','Tinggi': 'Tinggi (%)', 'Sangat Tinggi': 'Sangat Tinggi (%)'})\n",
    "new_order = ['Wilayah', 'Rendah (%)', 'Menengah (%)', 'Tinggi (%)', 'Sangat Tinggi (%)']\n",
    "pulau_df_complete = pulau_df_complete[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulau_df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indo_df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "all_combinations = pd.MultiIndex.from_product([pulau_df['Pulau_B'].unique(), categories], names=['Pulau_B', 'Kategori']).to_frame(index=False)\n",
    "complete_df = all_combinations.merge(pulau_df, on=['Pulau_B', 'Kategori'], how='left')\n",
    "complete_df['Area_H'] = complete_df['Area_H'].fillna(0)\n",
    "complete_df['Persentase'] = complete_df['Persentase'].fillna(0)\n",
    "\n",
    "\n",
    "# Adjust percentages so that they sum up to 100% for each PROPINSI\n",
    "def adjust_percentages(group):\n",
    "    total_percentage = group['Persentase'].sum()\n",
    "    if total_percentage != 100:\n",
    "        adjustment_factor = 100 / total_percentage\n",
    "        group['Persentase'] = group['Persentase'] * adjustment_factor\n",
    "    return group\n",
    "\n",
    "complete_df = complete_df.groupby('Pulau_B').apply(adjust_percentages)\n",
    "complete_df = complete_df.reset_index(drop=True)\n",
    "\n",
    "# Convert 'Persentase%' back to string format with '%' sign\n",
    "complete_df = complete_df[(complete_df['Kategori'] != \" \") & (complete_df['Pulau_B'] != \" \")]\n",
    "complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "location = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\PROVINSI\\PROVINSI BANGKA BELITUNG\\ANALISA-BULANAN\\PETA 1\\2024.09\"\n",
    "original_image_path = os.path.join(location, 'bln_babel_ver_202409.png')\n",
    "img = imageio.imread(original_image_path)\n",
    "height, width = img.shape[:2]  # Get the height and width\n",
    "\n",
    "# Cut the image in half\n",
    "width_cutoff = width // 2\n",
    "s1 = img[:, :width_cutoff]\n",
    "s2 = img[:, width_cutoff:]\n",
    "\n",
    "# Save each half\n",
    "imageio.imwrite(os.path.join(location, \"ach_bln_babel_ver_202409.png\"), s1)\n",
    "imageio.imwrite(os.path.join(location, \"ash_bln_babel_ver_202409.png\"), s2)\n",
    "\n",
    "os.remove(original_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_image(original_image_path, ach_path, ash_path):\n",
    "    import os\n",
    "    import imageio\n",
    "    \n",
    "    img = imageio.imread(original_image_path)\n",
    "    height, width = img.shape[:2]  # Get the height and width\n",
    "\n",
    "    # Cut the image in half\n",
    "    width_cutoff = width // 2\n",
    "    s1 = img[:, :width_cutoff]\n",
    "    s2 = img[:, width_cutoff:]\n",
    "\n",
    "    # Save each half\n",
    "    imageio.imwrite(ach_path, s1)\n",
    "    imageio.imwrite(ash_path, s2)\n",
    "\n",
    "    os.remove(original_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\PROVINSI\\PROVINSI BANTEN\\ANALISA-BULANAN\\PETA 1\\2024.09\\bln_banten_ver_202409.png\"\n",
    "ach_path = os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\PROVINSI\\PROVINSI BANTEN\\ANALISA-BULANAN\\PETA 1\\2024.09\", \"ach_banten.png\")\n",
    "ash_path = os.path.join(r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\PROVINSI\\PROVINSI BANTEN\\ANALISA-BULANAN\\PETA 1\\2024.09\", \"ash_banten.png\")\n",
    "\n",
    "cut_image(original_image_path=original_img, ach_path=ach_path, ash_path=ash_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilayah_upt = 'SUMATERA UTARA'\n",
    "sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "data = sdf2[['Kategori', 'PROPINSI', 'KABUPATEN', 'Area_H']]\n",
    "\n",
    "data = data[data['PROPINSI'] == wilayah_upt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipe_informasi = 'ANALISA CURAH HUJAN'\n",
    "\n",
    "# Agregasi Propinsi\n",
    "sum_area = data['Area_H'].sum()\n",
    "cat_df = data.groupby('Kategori')['Area_H'].sum()\n",
    "prov_df = round(cat_df / sum_area, 4)\n",
    "prov_df = prov_df.reset_index()\n",
    "prov_df = prov_df.rename({'Area_H' : 'Persentase',}, axis='columns')\n",
    "prov_df['Persentase'] = round(prov_df['Persentase']*100,2)\n",
    "prov_df['Persentase%'] = round(prov_df['Persentase'],2).astype(str) + '%'\n",
    "prov_df.drop(prov_df.index[0], inplace=True)\n",
    "prov_df[\"Wilayah\"] = f'PROVINSI {wilayah_upt}'\n",
    "\n",
    "categories_ch = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "categories_sh = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "\n",
    "if tipe_informasi == 'ANALISA CURAH HUJAN':\n",
    "    all_combinations = pd.MultiIndex.from_product([prov_df['Wilayah'].unique(), categories_ch], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "    prov_df_complete = all_combinations.merge(prov_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "    prov_df_complete['Persentase'] = prov_df_complete['Persentase'].fillna(0)\n",
    "    prov_df_complete['Persentase%'] = prov_df_complete['Persentase%'].fillna('0%')\n",
    "    non_zero_df = prov_df_complete[prov_df_complete['Persentase'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Persentase'].sum()\n",
    "    non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "    prov_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "    if 'Persentase%' in prov_df_complete.columns:\n",
    "        prov_df_complete['Persentase%'] = prov_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "    prov_df_pivot = pd.pivot(prov_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "    prov_df_pivot = prov_df_pivot.reset_index()\n",
    "    prov_df_pivot.columns.name = None\n",
    "\n",
    "    # Agregasi Kabupaten\n",
    "    kab_area_sum = data.groupby('KABUPATEN')['Area_H'].sum()\n",
    "    kab_cat_area_sum = data.groupby(['Kategori','KABUPATEN'])['Area_H'].sum()\n",
    "    kab_df = round(kab_cat_area_sum / kab_area_sum, 4)\n",
    "    kab_df = kab_df.reset_index()\n",
    "    kab_df = kab_df[(kab_df['Kategori'] != \" \") & (kab_df['KABUPATEN'] != \" \")]\n",
    "    kab_df['Area_H'] = round(kab_df['Area_H']*100, 2)\n",
    "    all_combinations_kab = pd.MultiIndex.from_product([kab_df['KABUPATEN'].unique(), categories_ch], names=['KABUPATEN', 'Kategori']).to_frame(index=False)\n",
    "    kab_df_complete = all_combinations_kab.merge(kab_df, on=['KABUPATEN', 'Kategori'], how='left')\n",
    "    kab_df_complete['Area_H'] = kab_df_complete['Area_H'].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "    top_5_areas = kab_df_complete.groupby('Kategori').apply(lambda x: x.nlargest(5, 'Area_H')).reset_index(drop=True)\n",
    "    top_by_kategori = top_5_areas.groupby('Kategori')['KABUPATEN'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "    kab_df_complete = pd.pivot(kab_df_complete, index='KABUPATEN', columns='Kategori', values='Area_H')\n",
    "    kab_df_complete = kab_df_complete.reset_index()\n",
    "    kab_df_complete.columns.name = None\n",
    "    kab_df_complete.drop(kab_df_complete.index[0], inplace=True)\n",
    "\n",
    "\n",
    "    # Concat Propinsi to kabupaten\n",
    "    kab_df_complete = kab_df_complete.rename(columns={'KABUPATEN': 'Wilayah'})\n",
    "    kab_df_complete = pd.concat([prov_df_pivot, kab_df_complete], ignore_index=True)\n",
    "\n",
    "    # Get kategori value for agregasi propinsi\n",
    "    sgt_tinggi = prov_df.loc[prov_df['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "    tinggi = prov_df.loc[prov_df['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "    rendah = prov_df.loc[prov_df['Kategori'] == 'Rendah', 'Persentase'].values[0]\n",
    "    menengah =  prov_df.loc[prov_df['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "    \n",
    "    \n",
    "    # return prov_df_complete, kab_df_complete, sgt_tinggi, tinggi, menengah, rendah\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "else:                    #tipe_informasi == 'ANALISA SIFAT HUJAN':\n",
    "    all_combinations = pd.MultiIndex.from_product([prov_df['Wilayah'].unique(), categories_sh], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "    prov_df_complete = all_combinations.merge(prov_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "    prov_df_complete['Persentase'] = prov_df_complete['Persentase'].fillna(0)\n",
    "    prov_df_complete['Persentase%'] = prov_df_complete['Persentase%'].fillna('0%')\n",
    "    non_zero_df = prov_df_complete[prov_df_complete['Persentase'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Persentase'].sum()\n",
    "    non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "    prov_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "\n",
    "    # Update the 'Persentase%' column if it exists\n",
    "    if 'Persentase%' in prov_df_complete.columns:\n",
    "        prov_df_complete['Persentase%'] = prov_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "    prov_df_pivot = pd.pivot(prov_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "    prov_df_pivot = prov_df_pivot.reset_index()\n",
    "    prov_df_pivot.columns.name = None\n",
    "\n",
    "    # Agregasi Kabupaten\n",
    "    kab_area_sum = data.groupby('KABUPATEN')['Area_H'].sum()\n",
    "    kab_cat_area_sum = data.groupby(['Kategori','KABUPATEN'])['Area_H'].sum()\n",
    "    kab_df = round(kab_cat_area_sum / kab_area_sum, 4)\n",
    "    kab_df = kab_df.reset_index()\n",
    "    kab_df = kab_df[(kab_df['Kategori'] != \" \") & (kab_df['KABUPATEN'] != \" \")]\n",
    "    kab_df['Area_H'] = round(kab_df['Area_H']*100, 2)\n",
    "    all_combinations_kab = pd.MultiIndex.from_product([kab_df['KABUPATEN'].unique(), categories_sh], names=['KABUPATEN', 'Kategori']).to_frame(index=False)\n",
    "    kab_df_complete = all_combinations_kab.merge(kab_df, on=['KABUPATEN', 'Kategori'], how='left')\n",
    "    kab_df_complete['Area_H'] = kab_df_complete['Area_H'].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "    top_5_areas = kab_df_complete.groupby('Kategori').apply(lambda x: x.nlargest(5, 'Area_H')).reset_index(drop=True)\n",
    "    top_by_kategori = top_5_areas.groupby('Kategori')['KABUPATEN'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "    kab_df_complete = pd.pivot(kab_df_complete, index='KABUPATEN', columns='Kategori', values='Area_H')\n",
    "    kab_df_complete = kab_df_complete.reset_index()\n",
    "    kab_df_complete.columns.name = None\n",
    "    kab_df_complete.drop(kab_df_complete.index[0], inplace=True)\n",
    "\n",
    "\n",
    "    # Concat Propinsi to kabupaten\n",
    "    kab_df_complete = kab_df_complete.rename(columns={'KABUPATEN': 'Wilayah'})\n",
    "    kab_df_complete = pd.concat([prov_df_pivot, kab_df_complete], ignore_index=True)\n",
    "\n",
    "    # Get kategori value for agregasi propinsi\n",
    "    atas_normal = prov_df.loc[prov_df['Kategori'] == 'Atas Normal', 'Persentase'].values[0]\n",
    "    normal = prov_df.loc[prov_df['Kategori'] == 'Normal', 'Persentase'].values[0]\n",
    "    bawah_normal = prov_df.loc[prov_df['Kategori'] == 'Bawah Normal', 'Persentase'].values[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # return prov_df_complete, kab_df_complete, atas_normal, normal, bawah_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_by_kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgt_tinggi, tinggi, menengah, rendah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kab_df_complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_infografis_ch(prov_df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate to make sure all the total 100%\n",
    "non_zero_df = prov_df_complete[prov_df_complete['Persentase'] > 0].copy()\n",
    "total_non_zero = non_zero_df['Persentase'].sum()\n",
    "non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "prov_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "\n",
    "# Update the 'Persentase%' column if it exists\n",
    "if 'Persentase%' in prov_df_complete.columns:\n",
    "    prov_df_complete['Persentase%'] = prov_df_complete['Persentase'].astype(str) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ash_bln_indo_ver_202409.shp\"\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "# wilayah_upt = 'SUMATERA UTARA'\n",
    "# sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "# data = sdf2[['Kategori', 'PROPINSI', 'Pulau_B', 'Area_H']]\n",
    "\n",
    "\n",
    "\n",
    "tipe_informasi = 'ANALISA SIFAT HUJAN'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Pulau_B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_indo(feature, tipe_informasi):\n",
    "    sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "    data = sdf2[['Kategori', 'PROPINSI', 'Pulau_B', 'Area_H']]\n",
    "\n",
    "    # Agregasi Indonesia\n",
    "    sum_area = data['Area_H'].sum()\n",
    "    cat_df = data.groupby('Kategori')['Area_H'].sum()\n",
    "    indo_df = round(cat_df / sum_area, 4)\n",
    "    indo_df = indo_df.reset_index()\n",
    "    indo_df = indo_df.rename({'Area_H' : 'Persentase',}, axis='columns')\n",
    "    indo_df['Persentase'] = round(indo_df['Persentase']*100,2)\n",
    "    indo_df['Persentase%'] = round(indo_df['Persentase'],2).astype(str) + '%'\n",
    "    indo_df.drop(indo_df.index[0], inplace=True)\n",
    "    indo_df[\"Wilayah\"] = 'Indonesia'\n",
    "\n",
    "\n",
    "    categories_ch = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "    categories_sh = ['Bawah Normal', 'Normal', 'Atas Normal']\n",
    "\n",
    "    if tipe_informasi == 'ANALISA CURAH HUJAN':\n",
    "        all_combinations = pd.MultiIndex.from_product([indo_df['Wilayah'].unique(), categories_ch], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "        indo_df_complete = all_combinations.merge(indo_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "        indo_df_complete['Persentase'] = indo_df_complete['Persentase'].fillna(0)\n",
    "        indo_df_complete['Persentase%'] = indo_df_complete['Persentase%'].fillna('0%')\n",
    "        non_zero_df = indo_df_complete[indo_df_complete['Persentase'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Persentase'].sum()\n",
    "        non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "        indo_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "        if 'Persentase%' in indo_df_complete.columns:\n",
    "            indo_df_complete['Persentase%'] = indo_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "        indo_df_pivot = pd.pivot(indo_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "        indo_df_pivot = indo_df_pivot.reset_index()\n",
    "        indo_df_pivot.columns.name = None\n",
    "\n",
    "        # Proses statistik wilayah wilayah Provinsi\n",
    "        prov_area_sum = data.groupby('PROPINSI')['Area_H'].sum()\n",
    "        prov_cat_area_sum = data.groupby(['Kategori','PROPINSI'])['Area_H'].sum()\n",
    "        prov_df = round(prov_cat_area_sum / prov_area_sum, 2)\n",
    "        prov_df = prov_df.reset_index()\n",
    "        prov_df = prov_df[(prov_df['Kategori'] != \" \") & (prov_df['PROPINSI'] != \" \")]\n",
    "        prov_df['Area_H'] = round(prov_df['Area_H']*100, 2)\n",
    "        all_combinations_prov = pd.MultiIndex.from_product([prov_df['PROPINSI'].unique(), categories_ch], names=['PROPINSI', 'Kategori']).to_frame(index=False)\n",
    "        prov_df_complete = all_combinations_prov.merge(prov_df, on=['PROPINSI', 'Kategori'], how='left')\n",
    "        prov_df_complete['Area_H'] = prov_df_complete['Area_H'].fillna(0)\n",
    "        prov_df_complete_clean = pd.DataFrame()\n",
    "        for name, group in prov_df_complete.groupby('PROPINSI'):\n",
    "            non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "            total_non_zero = non_zero_df['Area_H'].sum()\n",
    "            \n",
    "            if total_non_zero > 0:\n",
    "                non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "            \n",
    "            group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "            prov_df_complete_clean = pd.concat([prov_df_complete_clean, group])\n",
    "\n",
    "        prov_df_complete_clean = prov_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "        top_13_areas = prov_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(13, 'Area_H')).reset_index(drop=True)\n",
    "        top_by_kategori = top_13_areas.groupby('Kategori')['PROPINSI'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "\n",
    "        prov_df_complete_clean = pd.pivot(prov_df_complete_clean, index='PROPINSI', columns='Kategori', values='Area_H')\n",
    "        prov_df_complete_clean = prov_df_complete_clean.reset_index()\n",
    "        prov_df_complete_clean.columns.name = None\n",
    "        prov_df_complete_clean.drop(prov_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "        # Concat Agregasi Indo to Propinsi\n",
    "        prov_df_complete_clean = prov_df_complete_clean.rename(columns={'PROPINSI': 'Wilayah'})\n",
    "        prov_df_complete_clean = pd.concat([indo_df_pivot, prov_df_complete_clean], ignore_index=True)\n",
    "\n",
    "        # Get kategori value for agregasi propinsi\n",
    "        sgt_tinggi = indo_df.loc[indo_df['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "        tinggi = indo_df.loc[indo_df['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "        rendah = indo_df.loc[indo_df['Kategori'] == 'Rendah', 'Persentase'].values[0]\n",
    "        menengah =  indo_df.loc[indo_df['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah Pulau Besar\n",
    "        pulau_area_sum = data.groupby('Pulau_B')['Area_H'].sum()\n",
    "        pulau_cat_df3 = data.groupby(['Kategori','Pulau_B'])['Area_H'].sum()\n",
    "        pulau_df = round(pulau_cat_df3 / pulau_area_sum, 2)\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df = pulau_df[(pulau_df['Kategori'] != \" \") & (pulau_df['Pulau_B'] != \" \")]\n",
    "\n",
    "        pulau_df['Area_H'] = round(pulau_df['Area_H']*100, 2)\n",
    "        all_combinations_pulau = pd.MultiIndex.from_product([pulau_df['Pulau_B'].unique(), categories_ch], names=['Pulau_B', 'Kategori']).to_frame(index=False)\n",
    "        pulau_df_complete = all_combinations_pulau.merge(pulau_df, on=['Pulau_B', 'Kategori'], how='left')\n",
    "        pulau_df_complete['Area_H'] = pulau_df_complete['Area_H'].fillna(0)\n",
    "        pulau_df_complete_clean = pd.DataFrame()\n",
    "        for name, group in pulau_df_complete.groupby('Pulau_B'):\n",
    "            non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "            total_non_zero = non_zero_df['Area_H'].sum()\n",
    "            \n",
    "            if total_non_zero > 0:\n",
    "                non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "            \n",
    "            group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "            pulau_df_complete_clean = pd.concat([pulau_df_complete_clean, group])\n",
    "\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "        pulau_df_complete_clean = pd.pivot(pulau_df_complete_clean, index='Pulau_B', columns='Kategori', values='Area_H')\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.reset_index()\n",
    "        pulau_df_complete_clean.columns.name = None\n",
    "        pulau_df_complete_clean.drop(pulau_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "        # Concat Agregasi Indo to Pulau_B\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Pulau_B': 'Wilayah'})\n",
    "        pulau_df_complete_clean = pd.concat([indo_df_pivot, pulau_df_complete_clean], ignore_index=True)\n",
    "\n",
    "\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Rendah': 'Rendah (%)', 'Menengah': 'Menengah (%)','Tinggi': 'Tinggi (%)', 'Sangat Tinggi': 'Sangat Tinggi (%)'})\n",
    "        new_order = ['Wilayah', 'Rendah (%)', 'Menengah (%)', 'Tinggi (%)', 'Sangat Tinggi (%)']\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean[new_order]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        return indo_df_complete, prov_df_complete_clean, sgt_tinggi, tinggi, menengah, rendah\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    else:    # tipe_informasi == 'ANALISA SIFAT HUJAN'\n",
    "\n",
    "        all_combinations = pd.MultiIndex.from_product([indo_df['Wilayah'].unique(), categories_sh], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "        indo_df_complete = all_combinations.merge(indo_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "        indo_df_complete['Persentase'] = indo_df_complete['Persentase'].fillna(0)\n",
    "        indo_df_complete['Persentase%'] = indo_df_complete['Persentase%'].fillna('0%')\n",
    "        non_zero_df = indo_df_complete[indo_df_complete['Persentase'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Persentase'].sum()\n",
    "        non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "        indo_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "        if 'Persentase%' in indo_df_complete.columns:\n",
    "            indo_df_complete['Persentase%'] = indo_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "        indo_df_pivot = pd.pivot(indo_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "        indo_df_pivot = indo_df_pivot.reset_index()\n",
    "        indo_df_pivot.columns.name = None\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah wilayah Provinsi\n",
    "        prov_area_sum = data.groupby('PROPINSI')['Area_H'].sum()\n",
    "        prov_cat_area_sum = data.groupby(['Kategori','PROPINSI'])['Area_H'].sum()\n",
    "        prov_df = round(prov_cat_area_sum / prov_area_sum, 2)\n",
    "        prov_df = prov_df.reset_index()\n",
    "        prov_df = prov_df[(prov_df['Kategori'] != \" \") & (prov_df['PROPINSI'] != \" \")]\n",
    "        prov_df['Area_H'] = round(prov_df['Area_H']*100, 2)\n",
    "        all_combinations_prov = pd.MultiIndex.from_product([prov_df['PROPINSI'].unique(), categories_sh], names=['PROPINSI', 'Kategori']).to_frame(index=False)\n",
    "        prov_df_complete = all_combinations_prov.merge(prov_df, on=['PROPINSI', 'Kategori'], how='left')\n",
    "        prov_df_complete['Area_H'] = prov_df_complete['Area_H'].fillna(0)\n",
    "        prov_df_complete_clean = pd.DataFrame()\n",
    "        for name, group in prov_df_complete.groupby('PROPINSI'):\n",
    "            non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "            total_non_zero = non_zero_df['Area_H'].sum()\n",
    "            \n",
    "            if total_non_zero > 0:\n",
    "                non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "            \n",
    "            group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "            prov_df_complete_clean = pd.concat([prov_df_complete_clean, group])\n",
    "\n",
    "        prov_df_complete_clean = prov_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "        top_13_areas = prov_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(13, 'Area_H')).reset_index(drop=True)\n",
    "        top_by_kategori = top_13_areas.groupby('Kategori')['PROPINSI'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "\n",
    "        prov_df_complete_clean = pd.pivot(prov_df_complete_clean, index='PROPINSI', columns='Kategori', values='Area_H')\n",
    "        prov_df_complete_clean = prov_df_complete_clean.reset_index()\n",
    "        prov_df_complete_clean.columns.name = None\n",
    "        prov_df_complete_clean.drop(prov_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "        # Concat Agregasi Indo to Propinsi\n",
    "        prov_df_complete_clean = prov_df_complete_clean.rename(columns={'PROPINSI': 'Wilayah'})\n",
    "        prov_df_complete_clean = pd.concat([indo_df_pivot, prov_df_complete_clean], ignore_index=True)\n",
    "\n",
    "        # Get kategori value for agregasi propinsi\n",
    "        atas_normal = indo_df.loc[indo_df['Kategori'] == 'Atas Normal', 'Persentase'].values[0]\n",
    "        normal = indo_df.loc[indo_df['Kategori'] == 'Normal', 'Persentase'].values[0]\n",
    "        bawah_normal = indo_df.loc[indo_df['Kategori'] == 'Bawah Normal', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah Pulau Besar\n",
    "        pulau_area_sum = data.groupby('Pulau_B')['Area_H'].sum()\n",
    "        pulau_cat_df3 = data.groupby(['Kategori','Pulau_B'])['Area_H'].sum()\n",
    "        pulau_df = round(pulau_cat_df3 / pulau_area_sum, 2)\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df = pulau_df[(pulau_df['Kategori'] != \" \") & (pulau_df['Pulau_B'] != \" \")]\n",
    "\n",
    "        pulau_df['Area_H'] = round(pulau_df['Area_H']*100, 2)\n",
    "        all_combinations_pulau = pd.MultiIndex.from_product([pulau_df['Pulau_B'].unique(), categories_sh], names=['Pulau_B', 'Kategori']).to_frame(index=False)\n",
    "        pulau_df_complete = all_combinations_pulau.merge(pulau_df, on=['Pulau_B', 'Kategori'], how='left')\n",
    "        pulau_df_complete['Area_H'] = pulau_df_complete['Area_H'].fillna(0)\n",
    "        pulau_df_complete_clean = pd.DataFrame()\n",
    "        for name, group in pulau_df_complete.groupby('Pulau_B'):\n",
    "            non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "            total_non_zero = non_zero_df['Area_H'].sum()\n",
    "            \n",
    "            if total_non_zero > 0:\n",
    "                non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "            \n",
    "            group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "            pulau_df_complete_clean = pd.concat([pulau_df_complete_clean, group])\n",
    "\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "        pulau_df_complete_clean = pd.pivot(pulau_df_complete_clean, index='Pulau_B', columns='Kategori', values='Area_H')\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.reset_index()\n",
    "        pulau_df_complete_clean.columns.name = None\n",
    "        pulau_df_complete_clean.drop(pulau_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "        # Concat Agregasi Indo to Pulau_B\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Pulau_B': 'Wilayah'})\n",
    "        pulau_df_complete_clean = pd.concat([indo_df_pivot, pulau_df_complete_clean], ignore_index=True)\n",
    "\n",
    "\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Bawah Normal': 'Bawah Normal (%)', 'Normal': 'Normal (%)','Atas Normal': 'Atas Normal (%)'})\n",
    "        new_order = ['Wilayah', 'Bawah Normal (%)', 'Normal (%)', 'Atas Normal (%)']\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean[new_order]\n",
    "        \n",
    "        \n",
    "        return indo_df_complete, pulau_df_complete_clean, atas_normal, normal, bawah_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indo_df_complete, pulau_df_complete_clean, atas_normal, normal, bawah_normal = dataframe_indo(feature, tipe_informasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indo_df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulau_df_complete_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Create table\n",
    "table = ax.table(cellText=pulau_df_complete_clean.values, colLabels=pulau_df_complete_clean.columns, cellLoc='center', loc='center')\n",
    "\n",
    "# Set font size\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "\n",
    "# Adjust column width\n",
    "table.scale(1.2, 1.2)\n",
    "\n",
    "# Save the table as a PNG image\n",
    "# plt.savefig('dataframe_table.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Display the plot (optional)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "data = sdf2[['Kategori', 'PROPINSI', 'Pulau_B', 'Area_H']]\n",
    "\n",
    "# Agregasi Indonesia\n",
    "sum_area = data['Area_H'].sum()\n",
    "cat_df = data.groupby('Kategori')['Area_H'].sum()\n",
    "indo_df = round(cat_df / sum_area, 4)\n",
    "indo_df = indo_df.reset_index()\n",
    "indo_df = indo_df.rename({'Area_H' : 'Persentase',}, axis='columns')\n",
    "indo_df['Persentase'] = round(indo_df['Persentase']*100,2)\n",
    "indo_df['Persentase%'] = round(indo_df['Persentase'],2).astype(str) + '%'\n",
    "indo_df.drop(indo_df.index[0], inplace=True)\n",
    "indo_df[\"Wilayah\"] = 'Indonesia'\n",
    "\n",
    "categories_ch = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "categories_sh = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "\n",
    "categories_ch = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "categories_sh = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "\n",
    "if tipe_informasi == 'ANALISA CURAH HUJAN':\n",
    "    all_combinations = pd.MultiIndex.from_product([indo_df['Wilayah'].unique(), categories_ch], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "    indo_df_complete = all_combinations.merge(indo_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "    indo_df_complete['Persentase'] = indo_df_complete['Persentase'].fillna(0)\n",
    "    indo_df_complete['Persentase%'] = indo_df_complete['Persentase%'].fillna('0%')\n",
    "    non_zero_df = indo_df_complete[indo_df_complete['Persentase'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Persentase'].sum()\n",
    "    non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "    indo_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "    if 'Persentase%' in indo_df_complete.columns:\n",
    "        indo_df_complete['Persentase%'] = indo_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "    indo_df_pivot = pd.pivot(indo_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "    indo_df_pivot = indo_df_pivot.reset_index()\n",
    "    indo_df_pivot.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from config import nama_stasiun, nama_prov, nama_prov_union_shp\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_chart import cut_image\n",
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "from utils.proses1_chart import chart_infografis_ch, chart_infografis_sh\n",
    "\n",
    "\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "tipe_informasi = 'ANALISA SIFAT HUJAN'\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "feature = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ash_bln_indo_ver_202409.shp\"\n",
    "dataframe = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "\n",
    "aprx = arcpy.mp.ArcGISProject(r\"C:\\Users\\mjanuadi\\OneDrive - ESRI Indonesia\\Documents\\ArcGIS\\Packages\\bmkg_layout_d8ba3d\\p30\\bmkg_peta_cuaca1.aprx\")\n",
    "\n",
    "layout_infog1_ach = aprx.listLayouts(\"Infografis_ach_pusat_1\")[0]\n",
    "layout_infog2_ach = aprx.listLayouts(\"Infografis_ach_pusat_2\")[0]\n",
    "layout_infog1_ash = aprx.listLayouts(\"Infografis_ash_pusat_1\")[0]\n",
    "layout_infog2_ash = aprx.listLayouts(\"Infografis_ash_pusat_2\")[0]\n",
    "\n",
    "\n",
    "\n",
    "map_frame_ch = layout_infog1_ach.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame CH')[0]\n",
    "map_obj_ch = map_frame_ch.map\n",
    "prov_layer_ch = map_obj_ch.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_ch = map_obj_ch.listLayers(\"admin_kab\")[0]\n",
    "kec_layer_ch = map_obj_ch.listLayers(\"idkec\")[0]\n",
    "\n",
    "\n",
    "map_frame_sh = layout_infog1_ash.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame SH')[0]\n",
    "map_obj_sh = map_frame_sh.map\n",
    "prov_layer_sh = map_obj_sh.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_sh = map_obj_sh.listLayers(\"admin_kab\")[0]\n",
    "kec_layer_sh = map_obj_sh.listLayers(\"idkec\")[0]\n",
    "\n",
    "\n",
    "layers_to_hide = [prov_layer_ch, prov_layer_sh]\n",
    "layers_to_show = [kab_layer_ch, kab_layer_sh]\n",
    "\n",
    "\n",
    "def store_initial_state(original_layout):\n",
    "        initial_state = {}\n",
    "        elements = original_layout.listElements()\n",
    "        for element in elements:\n",
    "            if hasattr(element, 'text'):\n",
    "                initial_state[element.name] = element.text\n",
    "        return initial_state\n",
    "\n",
    "\n",
    "def reset_elements( modified_layout, initial_state):\n",
    "        elements = modified_layout.listElements()\n",
    "        for element in elements:\n",
    "            if element.name in initial_state:\n",
    "                try:\n",
    "                    element.text = initial_state[element.name]\n",
    "                except Exception as e:\n",
    "                    print(f\"Error resetting element '{element.name}': {e}\")\n",
    "\n",
    "\n",
    "print(\"Proses Pembuatan Infografis dimulai . . .\")\n",
    "\n",
    "prov_referensi = os.getenv(\"POLY_PROV\")\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "folder_aset = os.getenv(\"ASSET\")\n",
    "\n",
    "\n",
    "with arcpy.da.SearchCursor(prov_referensi, [\"WADMPR\", \"SHAPE@\"]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "        try:\n",
    "            wilayah_ref = r[0]\n",
    "            prov_geometry = r[1]\n",
    "            if wilayah_ref == 'Indonesia':\n",
    "                print(wilayah_ref)\n",
    "                \n",
    "                # initial_state_infog1 = self.store_initial_state(layout_infog1_ach)\n",
    "                # initial_state_infog2 = self.store_initial_state(layout_infog2_ach)\n",
    "\n",
    "                if tipe_informasi == 'ANALISA CURAH HUJAN':\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_infog = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                    output_tipe_periode='ANALISA-BULANAN', tipe='INFOGRAFIS')\n",
    "\n",
    "\n",
    "                    indo_df_complete, prov_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_indo(dataframe, tipe_informasi)\n",
    "\n",
    "                    wilayah_sgt_tinggi = top_by_kategori['Sangat Tinggi']\n",
    "                    wilayah_tinggi = top_by_kategori['Tinggi']\n",
    "                    wilayah_menengah = top_by_kategori['Menengah']\n",
    "                    wilayah_rendah = top_by_kategori['Rendah']\n",
    "\n",
    "\n",
    "                    chart_infografis_ch(indo_df_complete)\n",
    "\n",
    "                    print(\"Print Infografis 1\")\n",
    "                    # Set extent sesuai geometry\n",
    "                    \n",
    "                    map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                    prov_layer_ch.visible = False\n",
    "                    kab_layer_ch.visible = False\n",
    "                    kec_layer_ch.visible = False\n",
    "\n",
    "                    # output_file = os.path.join(folder_aset, 'maps', f\"peta_infografis.png\")\n",
    "                    # output_ach = os.path.join(folder_aset, 'maps', f\"peta_infografis_ach.png\")\n",
    "                    # output_ash = os.path.join(folder_aset, 'maps', f\"peta_infografis_ash.png\")\n",
    "\n",
    "                    # layout_peta.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                    # cut_image(output_file, output_ach, output_ash)\n",
    "\n",
    "\n",
    "                    elements_infog1 = layout_infog1_ach.listElements()\n",
    "\n",
    "                    for element in elements_infog1:\n",
    "                        if element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "\n",
    "                    \n",
    "\n",
    "                    print(\"Print Infografis 2\")\n",
    "\n",
    "                    elements_infog2 = layout_infog2_ach.listElements()\n",
    "\n",
    "                    for element in elements_infog2:\n",
    "                        if element.name == 'CHART':\n",
    "                                element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png')))\n",
    "                        elif element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        elif element.name == \"SUBJUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        elif element.name == 'TEXT1':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Curah Hujan</BOL>, umumnya wilayah Indonesia akan mengalami curah hujan <BOL>SANGAT TINGGI sebesar {sgt_tinggi}%</BOL>, <BOL>TINGGI sebesar {tinggi}%</BOL>, <BOL>MENENGAH sebesar {menengah}%</BOL>, dan <BOL>RENDAH sebesar {rendah}%</BOL>.''')\n",
    "                        elif element.name == 'TEXT2':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>SANGAT TINGGI</BOL> meliputi: {wilayah_sgt_tinggi}. Wilayah dominan <BOL>TINGGI</BOL> meliputi: {wilayah_tinggi}. Wilayah dominan <BOL>MENENGAH</BOL> meliputi: {wilayah_menengah}. Wilayah dominan <BOL>RENDAH</BOL> meliputi: {wilayah_rendah}.''')\n",
    "\n",
    "\n",
    "                    temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                    temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                    layout_infog1_ach.exportToPDF(temp_pdf1, resolution=300)\n",
    "                    layout_infog2_ach.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                    pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ach_bln_indo_ver_{year}{month}.pdf'))\n",
    "                    pdf_doc.appendPages(temp_pdf1)\n",
    "                    pdf_doc.appendPages(temp_pdf2)\n",
    "                    pdf_doc.saveAndClose()\n",
    "\n",
    "                    os.remove(temp_pdf1)\n",
    "                    os.remove(temp_pdf2)\n",
    "\n",
    "                else: # tipe_informasi == 'ANALISA SIFAT HUJAN'\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_infog = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                    output_tipe_periode='ANALISA-BULANAN', tipe='INFOGRAFIS')\n",
    "\n",
    "\n",
    "                    indo_df_complete, prov_df_complete_clean, top_by_kategori,  atas_normal, normal, bawah_normal= dataframe_indo(dataframe, tipe_informasi)\n",
    "\n",
    "                    wilayah_atas_normal = top_by_kategori['Atas Normal']\n",
    "                    wilayah_normal = top_by_kategori['Normal']\n",
    "                    wilayah_bawah_normal = top_by_kategori['Bawah Normal']\n",
    "\n",
    "\n",
    "                    chart_infografis_sh(indo_df_complete)\n",
    "\n",
    "                    print(\"Print Infografis 1\")\n",
    "                    # Set extent sesuai geometry\n",
    "                    \n",
    "                    map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                    prov_layer_sh.visible = False\n",
    "                    kab_layer_sh.visible = False\n",
    "                    kec_layer_sh.visible = False\n",
    "\n",
    "\n",
    "\n",
    "                    elements_infog1 = layout_infog1_ash.listElements()\n",
    "\n",
    "                    for element in elements_infog1:\n",
    "                        if element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "\n",
    "                    \n",
    "\n",
    "                    print(\"Print Infografis 2\")\n",
    "\n",
    "                    elements_infog2 = layout_infog2_ash.listElements()\n",
    "\n",
    "                    for element in elements_infog2:\n",
    "                        if element.name == 'CHART':\n",
    "                                element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png')))\n",
    "                        elif element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        elif element.name == \"SUBJUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        elif element.name == 'TEXT1':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Sifat Hujan</BOL>, umumnya wilayah Indonesia akan mengalami sifat hujan <BOL>ATAS NORMAL sebesar {atas_normal}%</BOL>, <BOL>NORMAL sebesar {normal}%</BOL>, <BOL>BAWAH NORMAL sebesar {bawah_normal}%</BOL>.''')\n",
    "                        elif element.name == 'TEXT2':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>ATAS NORMAL</BOL> meliputi: {wilayah_atas_normal}. Wilayah dominan <BOL>NORMAL</BOL> meliputi: {wilayah_normal}. Wilayah dominan <BOL>BAWAH NORMAL</BOL> meliputi: {wilayah_bawah_normal}.''')\n",
    "\n",
    "\n",
    "                    temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                    temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                    layout_infog1_ash.exportToPDF(temp_pdf1, resolution=300)\n",
    "                    layout_infog2_ash.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                    pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ash_bln_indo_ver_{year}{month}.pdf'))\n",
    "                    pdf_doc.appendPages(temp_pdf1)\n",
    "                    pdf_doc.appendPages(temp_pdf2)\n",
    "                    pdf_doc.saveAndClose()\n",
    "\n",
    "                    os.remove(temp_pdf1)\n",
    "                    os.remove(temp_pdf2)\n",
    "\n",
    "\n",
    "            else: # wilayah_ref == UPT\n",
    "                wilayah_upt = nama_prov_union_shp[wilayah_ref]\n",
    "        \n",
    "                print(wilayah_ref)\n",
    "                if tipe_informasi == 'ANALISA CURAH HUJAN':\n",
    "                    \n",
    "                    initial_state_infog1 = store_initial_state(layout_infog1_ach)\n",
    "                    initial_state_infog2 = store_initial_state(layout_infog2_ach)\n",
    "\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_infog = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                            output_tipe_periode='ANALISA-BULANAN', tipe='INFOGRAFIS', \n",
    "                                                                            nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                    \n",
    "\n",
    "                    prov_df_complete, kab_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_upt(dataframe, tipe_informasi, nama_prov_union_shp[wilayah_ref])\n",
    "\n",
    "                    wilayah_sgt_tinggi = top_by_kategori['Sangat Tinggi']\n",
    "                    wilayah_tinggi = top_by_kategori['Tinggi']\n",
    "                    wilayah_menengah = top_by_kategori['Menengah']\n",
    "                    wilayah_rendah = top_by_kategori['Rendah']\n",
    "\n",
    "                    chart_infografis_ch(prov_df_complete)\n",
    "\n",
    "                    print(\"Print Infografis 1\")\n",
    "                    map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                    \n",
    "\n",
    "                    # if kab_layer_ch.isFeatureLayer:\n",
    "                    #     for lbl_class in kab_layer_ch.listLabelClasses():\n",
    "                    #         lbl_class.showClassLabels = True\n",
    "                    #         lbl_class.symbol.fontSize = 10\n",
    "                    #     kab_layer_ch.showLabels = True\n",
    "\n",
    "\n",
    "\n",
    "                    for layer in layers_to_hide:\n",
    "                            if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            for layer in layers_to_show:\n",
    "                                if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            \n",
    "\n",
    "                    elements_infog1 = layout_infog1_ach.listElements()\n",
    "\n",
    "                    for element in elements_infog1:\n",
    "                        if element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "\n",
    "\n",
    "                    \n",
    "                    print(\"Print Infografis 2\")\n",
    "\n",
    "                    elements_infog2 = layout_infog2_ach.listElements()\n",
    "\n",
    "                    for element in elements_infog2:\n",
    "                        if element.name == 'CHART':\n",
    "                            element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png')))\n",
    "                        elif element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        elif element.name == \"SUBJUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        elif element.name == 'TEXT1':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Curah Hujan</BOL>, umumnya wilayah {nama_prov[wilayah_ref]} akan mengalami curah hujan <BOL>SANGAT TINGGI sebesar {sgt_tinggi}%</BOL>, <BOL>TINGGI sebesar {tinggi}%</BOL>, <BOL>MENENGAH sebesar {menengah}%</BOL>, dan <BOL>RENDAH sebesar {rendah}%</BOL>.''')\n",
    "                        elif element.name == 'TEXT2':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>SANGAT TINGGI</BOL> meliputi: {wilayah_sgt_tinggi}. Wilayah dominan <BOL>TINGGI</BOL> meliputi: {wilayah_tinggi}. Wilayah dominan <BOL>MENENGAH</BOL> meliputi: {wilayah_menengah}. Wilayah dominan <BOL>RENDAH</BOL> meliputi: {wilayah_rendah}.''')\n",
    "\n",
    "\n",
    "                    temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                    temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                    layout_infog1_ach.exportToPDF(temp_pdf1, resolution=300)\n",
    "                    layout_infog2_ach.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                    pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ach_bln_{wilayah_ref.lower()}_ver_{year}{month}.pdf'))\n",
    "                    pdf_doc.appendPages(temp_pdf1)\n",
    "                    pdf_doc.appendPages(temp_pdf2)\n",
    "                    pdf_doc.saveAndClose()\n",
    "\n",
    "                    os.remove(temp_pdf1)\n",
    "                    os.remove(temp_pdf2)\n",
    "\n",
    "                    reset_elements(layout_infog1_ach, initial_state_infog1)\n",
    "                    reset_elements(layout_infog2_ach, initial_state_infog2)\n",
    "\n",
    "                else: # tipe_informasi == 'ANALISA SIFAT HUJAN'\n",
    "                    \n",
    "                    initial_state_infog1 = store_initial_state(layout_infog1_ash)\n",
    "                    initial_state_infog2 = store_initial_state(layout_infog2_ash)\n",
    "\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_infog = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                            output_tipe_periode='ANALISA-BULANAN', tipe='INFOGRAFIS', \n",
    "                                                                            nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                    \n",
    "\n",
    "                    prov_df_complete, kab_df_complete_clean, top_by_kategori, atas_normal, normal, bawah_normal = dataframe_upt(dataframe, tipe_informasi, nama_prov_union_shp[wilayah_ref])\n",
    "\n",
    "                    wilayah_atas_normal = top_by_kategori['Atas Normal']\n",
    "                    wilayah_normal = top_by_kategori['Normal']\n",
    "                    wilayah_bawah_normal = top_by_kategori['Bawah Normal']\n",
    "\n",
    "                    chart_infografis_sh(prov_df_complete)\n",
    "\n",
    "                    print(\"Print Infografis 1\")\n",
    "                    map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "\n",
    "                    # if kab_layer_sh.isFeatureLayer:\n",
    "                    #     for lbl_class in kab_layer_sh.listLabelClasses():\n",
    "                    #         lbl_class.showClassLabels = True\n",
    "                    #         lbl_class.symbol.fontSize = 10\n",
    "                    #     kab_layer_sh.showLabels = True\n",
    "\n",
    "\n",
    "                    for layer in layers_to_hide:\n",
    "                            if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            for layer in layers_to_show:\n",
    "                                if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            \n",
    "\n",
    "                    elements_infog1 = layout_infog1_ash.listElements()\n",
    "\n",
    "                    for element in elements_infog1:\n",
    "                        if element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "\n",
    "\n",
    "                    \n",
    "                    print(\"Print Infografis 2\")\n",
    "\n",
    "                    elements_infog2 = layout_infog2_ash.listElements()\n",
    "\n",
    "                    for element in elements_infog2:\n",
    "                        if element.name == 'CHART':\n",
    "                            element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png')))\n",
    "                        elif element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        elif element.name == \"SUBJUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                        elif element.name == 'TEXT1':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Sifat Hujan</BOL>, umumnya wilayah {nama_prov[wilayah_ref]} akan mengalami sifat hujan <BOL>ATAS NORMAL sebesar {atas_normal}%</BOL>, <BOL>NORMAL sebesar {normal}%</BOL>, <BOL>BAWAH NORMAL sebesar {bawah_normal}%</BOL>.''')\n",
    "                        elif element.name == 'TEXT2':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>ATAS NORMAL</BOL> meliputi: {wilayah_atas_normal}. Wilayah dominan <BOL>NORMAL</BOL> meliputi: {wilayah_normal}. Wilayah dominan <BOL>BAWAH NORMAL</BOL> meliputi: {wilayah_bawah_normal}.''')\n",
    "\n",
    "\n",
    "                    temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                    temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                    layout_infog1_ash.exportToPDF(temp_pdf1, resolution=300)\n",
    "                    layout_infog2_ash.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                    pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ash_bln_{wilayah_ref.lower()}_ver_{year}{month}.pdf'))\n",
    "                    pdf_doc.appendPages(temp_pdf1)\n",
    "                    pdf_doc.appendPages(temp_pdf2)\n",
    "                    pdf_doc.saveAndClose()\n",
    "\n",
    "                    os.remove(temp_pdf1)\n",
    "                    os.remove(temp_pdf2)\n",
    "\n",
    "                    reset_elements(layout_infog1_ash, initial_state_infog1)\n",
    "                    reset_elements(layout_infog2_ash, initial_state_infog2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error di pengolahan Pulau/Provinsi {wilayah_ref}: {e}\")\n",
    "            continue  # Skip to the next island\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ash = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ash_bln_indo_ver_202409.shp\"\n",
    "dataframe_ash = pd.DataFrame.spatial.from_featureclass(feature_ash)\n",
    "feature_ach = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ach_bln_indo_ver_202409.shp\"\n",
    "dataframe_ach = pd.DataFrame.spatial.from_featureclass(feature_ach)\n",
    "aprx = os.getenv(\"APRX_PROJECT\")\n",
    "\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "laporan = PembuatanPetaLaporan(map_project=aprx)\n",
    "\n",
    "infog_ach_bln = laporan.infografis_bln(feature=feature_ach, tipe_informasi='ANALISA CURAH HUJAN')\n",
    "\n",
    "infog_ash_bln = laporan.infografis_bln(feature=feature_ash, tipe_informasi='ANALISA SIFAT HUJAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ash = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ash_bln_indo_ver_202409.shp\"\n",
    "dataframe_ash = pd.DataFrame.spatial.from_featureclass(feature_ash)\n",
    "feature_ach = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ach_bln_indo_ver_202409.shp\"\n",
    "dataframe_ach = pd.DataFrame.spatial.from_featureclass(feature_ach)\n",
    "aprx = os.getenv(\"APRX_PROJECT\")\n",
    "\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "laporan = PembuatanPetaLaporan(map_project=aprx)\n",
    "\n",
    "infog_ach_bln = laporan.infografis_das(feature=feature_ach, tipe_informasi='ANALISA CURAH HUJAN')\n",
    "\n",
    "infog_ash_bln = laporan.infografis_das(feature=feature_ash, tipe_informasi='ANALISA SIFAT HUJAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from config import nama_stasiun, nama_prov, nama_prov_union_shp\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_chart import cut_image\n",
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "from utils.proses1_chart import chart_infografis_ch, chart_infografis_sh\n",
    "\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ash_bln_indo_ver_202409.shp\"\n",
    "# sdf2 = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "# data = sdf2[['Kategori', 'PROPINSI', 'Pulau_B', 'Area_H']]\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame.spatial.from_featureclass(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tipe_informasi = 'ANALISA CURAH HUJAN'\n",
    "tipe_informasi = 'ANALISA SIFAT HUJAN'\n",
    "\n",
    "wilayah_upt = 'ACEH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataframe[['Kategori', 'PROPINSI', 'KABUPATEN', 'Area_H']]\n",
    "\n",
    "data = data[data['PROPINSI'] == wilayah_upt]\n",
    "\n",
    "# Agregasi Propinsi\n",
    "sum_area = data['Area_H'].sum()\n",
    "cat_df = data.groupby('Kategori')['Area_H'].sum()\n",
    "prov_df = round(cat_df / sum_area, 4)\n",
    "prov_df = prov_df.reset_index()\n",
    "prov_df = prov_df.rename({'Area_H' : 'Persentase',}, axis='columns')\n",
    "prov_df['Persentase'] = round(prov_df['Persentase']*100,2)\n",
    "prov_df['Persentase%'] = round(prov_df['Persentase'],2).astype(str) + '%'\n",
    "prov_df.drop(prov_df.index[0], inplace=True)\n",
    "prov_df[\"Wilayah\"] = f'PROVINSI {wilayah_upt}'\n",
    "\n",
    "categories_ch = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "categories_sh = ['Bawah Normal', 'Normal', 'Atas Normal']\n",
    "\n",
    "if tipe_informasi == 'ANALISA CURAH HUJAN':\n",
    "    all_combinations = pd.MultiIndex.from_product([prov_df['Wilayah'].unique(), categories_ch], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "    prov_df_complete = all_combinations.merge(prov_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "    prov_df_complete['Persentase'] = prov_df_complete['Persentase'].fillna(0)\n",
    "    prov_df_complete['Persentase%'] = prov_df_complete['Persentase%'].fillna('0%')\n",
    "    non_zero_df = prov_df_complete[prov_df_complete['Persentase'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Persentase'].sum()\n",
    "    non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "    prov_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "    if 'Persentase%' in prov_df_complete.columns:\n",
    "        prov_df_complete['Persentase%'] = prov_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "    prov_df_pivot = pd.pivot(prov_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "    prov_df_pivot = prov_df_pivot.reset_index()\n",
    "    prov_df_pivot.columns.name = None\n",
    "\n",
    "    # Agregasi Kabupaten\n",
    "    kab_area_sum = data.groupby('KABUPATEN')['Area_H'].sum()\n",
    "    kab_cat_area_sum = data.groupby(['Kategori','KABUPATEN'])['Area_H'].sum()\n",
    "    kab_df = round(kab_cat_area_sum / kab_area_sum, 4)\n",
    "    kab_df = kab_df.reset_index()\n",
    "    kab_df = kab_df[(kab_df['Kategori'] != \" \") & (kab_df['KABUPATEN'] != \" \")]\n",
    "    kab_df['Area_H'] = round(kab_df['Area_H']*100, 2)\n",
    "    all_combinations_kab = pd.MultiIndex.from_product([kab_df['KABUPATEN'].unique(), categories_ch], names=['KABUPATEN', 'Kategori']).to_frame(index=False)\n",
    "    kab_df_complete = all_combinations_kab.merge(kab_df, on=['KABUPATEN', 'Kategori'], how='left')\n",
    "    kab_df_complete['Area_H'] = kab_df_complete['Area_H'].fillna(0)\n",
    "    kab_df_complete_clean = pd.DataFrame()\n",
    "    for name, group in kab_df_complete.groupby('KABUPATEN'):\n",
    "        non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Area_H'].sum()\n",
    "        \n",
    "        if total_non_zero > 0:\n",
    "            non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "        \n",
    "        group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "        kab_df_complete_clean = pd.concat([kab_df_complete_clean, group])\n",
    "\n",
    "    kab_df_complete_clean = kab_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    top_5_areas = kab_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(5, 'Area_H')).reset_index(drop=True)\n",
    "    top_by_kategori = top_5_areas.groupby('Kategori')['KABUPATEN'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "    kab_df_complete_clean = pd.pivot(kab_df_complete_clean, index='KABUPATEN', columns='Kategori', values='Area_H')\n",
    "    kab_df_complete_clean = kab_df_complete_clean.reset_index()\n",
    "    kab_df_complete_clean.columns.name = None\n",
    "    kab_df_complete_clean.drop(kab_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "\n",
    "    # # Concat Propinsi to kabupaten\n",
    "    kab_df_complete_clean = kab_df_complete_clean.rename(columns={'KABUPATEN': 'Wilayah'})\n",
    "    kab_df_complete_clean = pd.concat([prov_df_pivot, kab_df_complete_clean], ignore_index=True)\n",
    "\n",
    "    # Get kategori value for agregasi propinsi\n",
    "    sgt_tinggi = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "    tinggi = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "    rendah = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Rendah', 'Persentase'].values[0]\n",
    "    menengah =  prov_df_complete.loc[prov_df_complete['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "    \n",
    "\n",
    "    kab_df_complete_clean = kab_df_complete_clean.rename(columns={'Rendah': 'Rendah (%)', 'Menengah': 'Menengah (%)','Tinggi': 'Tinggi (%)', 'Sangat Tinggi': 'Sangat Tinggi (%)'})\n",
    "    new_order = ['Wilayah', 'Rendah (%)', 'Menengah (%)', 'Tinggi (%)', 'Sangat Tinggi (%)']\n",
    "    kab_df_complete_clean = kab_df_complete_clean[new_order]\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "elif tipe_informasi == 'ANALISA SIFAT HUJAN':\n",
    "    all_combinations = pd.MultiIndex.from_product([prov_df['Wilayah'].unique(), categories_sh], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "    prov_df_complete = all_combinations.merge(prov_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "    prov_df_complete['Persentase'] = prov_df_complete['Persentase'].fillna(0)\n",
    "    prov_df_complete['Persentase%'] = prov_df_complete['Persentase%'].fillna('0%')\n",
    "    non_zero_df = prov_df_complete[prov_df_complete['Persentase'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Persentase'].sum()\n",
    "    non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "    prov_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "\n",
    "    # Update the 'Persentase%' column if it exists\n",
    "    if 'Persentase%' in prov_df_complete.columns:\n",
    "        prov_df_complete['Persentase%'] = prov_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "    prov_df_pivot = pd.pivot(prov_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "    prov_df_pivot = prov_df_pivot.reset_index()\n",
    "    prov_df_pivot.columns.name = None\n",
    "\n",
    "    # Agregasi Kabupaten\n",
    "    kab_area_sum = data.groupby('KABUPATEN')['Area_H'].sum()\n",
    "    kab_cat_area_sum = data.groupby(['Kategori','KABUPATEN'])['Area_H'].sum()\n",
    "    kab_df = round(kab_cat_area_sum / kab_area_sum, 4)\n",
    "    kab_df = kab_df.reset_index()\n",
    "    kab_df = kab_df[(kab_df['Kategori'] != \" \") & (kab_df['KABUPATEN'] != \" \")]\n",
    "    kab_df['Area_H'] = round(kab_df['Area_H']*100, 2)\n",
    "    all_combinations_kab = pd.MultiIndex.from_product([kab_df['KABUPATEN'].unique(), categories_sh], names=['KABUPATEN', 'Kategori']).to_frame(index=False)\n",
    "    kab_df_complete = all_combinations_kab.merge(kab_df, on=['KABUPATEN', 'Kategori'], how='left')\n",
    "    kab_df_complete['Area_H'] = kab_df_complete['Area_H'].fillna(0)\n",
    "    kab_df_complete_clean = pd.DataFrame()\n",
    "    for name, group in kab_df_complete.groupby('KABUPATEN'):\n",
    "        non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Area_H'].sum()\n",
    "        \n",
    "        if total_non_zero > 0:\n",
    "            non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "        \n",
    "        group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "        kab_df_complete_clean = pd.concat([kab_df_complete_clean, group])\n",
    "\n",
    "    kab_df_complete_clean = kab_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    top_5_areas = kab_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(5, 'Area_H')).reset_index(drop=True)\n",
    "    top_by_kategori = top_5_areas.groupby('Kategori')['KABUPATEN'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "    kab_df_complete_clean = pd.pivot(kab_df_complete_clean, index='KABUPATEN', columns='Kategori', values='Area_H')\n",
    "    kab_df_complete_clean = kab_df_complete_clean.reset_index()\n",
    "    kab_df_complete_clean.columns.name = None\n",
    "    kab_df_complete_clean.drop(kab_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "\n",
    "    # # Concat Propinsi to kabupaten\n",
    "    kab_df_complete_clean = kab_df_complete_clean.rename(columns={'KABUPATEN': 'Wilayah'})\n",
    "    kab_df_complete_clean = pd.concat([prov_df_pivot, kab_df_complete_clean], ignore_index=True)\n",
    "\n",
    "    # Get kategori value for agregasi propinsi\n",
    "    atas_normal = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Atas Normal', 'Persentase'].values[0]\n",
    "    normal = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Normal', 'Persentase'].values[0]\n",
    "    bawah_normal = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Bawah Normal', 'Persentase'].values[0]\n",
    "    \n",
    "\n",
    "    kab_df_complete_clean = kab_df_complete_clean.rename(columns={'Bawah Normal': 'Bawah Normal (%)', 'Normal': 'Normal (%)','Atas Normal': 'Atas Normal (%)'})\n",
    "    new_order = ['Wilayah', 'Bawah Normal (%)', 'Normal (%)', 'Atas Normal (%)']\n",
    "    kab_df_complete_clean = kab_df_complete_clean[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipe_informasi = 'ANALISA SIFAT HUJAN'\n",
    "prov_df_complete, kab_df_complete_clean, top_by_kategori, atas_normal, normal, bawah_normal= dataframe_upt(dataframe, tipe_informasi, wilayah_upt='BALI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_infografis_sh(dataframe):\n",
    "    output_location = os.getenv(\"ASSET\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    categories = ['Bawah Normal', 'Normal', 'Atas Normal']\n",
    "    colors = ['#340900', '#ffff00', '#00450c']\n",
    "\n",
    "    # Reorder DataFrame based on categories\n",
    "    dataframe['Kategori'] = pd.Categorical(dataframe['Kategori'], categories=categories)\n",
    "    dataframe = dataframe.sort_values('Kategori')\n",
    "    # Plot bars\n",
    "    bars = ax.bar(dataframe['Kategori'], dataframe['Persentase'], color=colors, edgecolor='black', linewidth=0.5, width=0.95)\n",
    "    # Add text labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height < 10:  # Adjust this threshold as needed\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height}%', ha='center', va='bottom', fontsize=16, fontweight='bold', color='red')\n",
    "        else:\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, height / 2, f'{height}%', ha='center', va='center', fontsize=16, fontweight='bold', color='red')\n",
    "    # Set y-axis range and labels\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_ylabel('Persentase', fontsize=18, color='black', fontfamily=\"Arial\")\n",
    "    # Remove x-axis ticks and labels\n",
    "    ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    # Set background color to transparent\n",
    "    fig.patch.set_alpha(0)\n",
    "    ax.patch.set_alpha(0)\n",
    "    # Set plot background color to transparent\n",
    "    ax.set_facecolor('none')\n",
    "    # Add gridlines for y-axis\n",
    "    ax.yaxis.grid(True, color='grey', linestyle='--', linewidth=0.5, zorder=0)\n",
    "    # Set bars zorder to 2 to ensure they are in front of the gridlines\n",
    "    for bar in bars:\n",
    "        bar.set_zorder(2)\n",
    "    # Save the figure\n",
    "    fig.savefig(os.path.join(output_location,'chart', 'infografis', 'chart_infografis_sh.png'), dpi=300, bbox_inches='tight', transparent=True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_infografis_sh(prov_df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laporan_tabel(dataframe):\n",
    "    folder_aset = os.getenv(\"ASSET\")\n",
    "    row_count = dataframe.shape[0]\n",
    "    fig_height = 0.1 * row_count + 2  # Adjust the multiplier and base height as needed\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, fig_height))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Convert column labels to uppercase\n",
    "    col_labels = [label.upper() for label in dataframe.columns]\n",
    "\n",
    "    # Create table\n",
    "    table = ax.table(cellText=dataframe.values, colLabels=col_labels, cellLoc='center', loc='center')\n",
    "\n",
    "    # Set font size\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "\n",
    "    # Make the heading bold and set cell borders\n",
    "    for key, cell in table.get_celld().items():\n",
    "        if key[0] == 0:  # This is the header row\n",
    "            cell.set_text_props(fontweight='bold')\n",
    "        cell.set_edgecolor('black')  # Set edge color for all cells\n",
    "        cell.set_linewidth(1)        # Set line width for all cells\n",
    "\n",
    "    # Adjust cell width\n",
    "    for i, col in enumerate(dataframe.columns):\n",
    "        max_col_width = max(dataframe[col].astype(str).apply(len).max(), len(col)) + 2\n",
    "        table.auto_set_column_width([i])\n",
    "        for key, cell in table.get_celld().items():\n",
    "            if key[1] == i:\n",
    "                cell.set_width(max_col_width * 0.1)\n",
    "\n",
    "    # Adjust column width\n",
    "    table.scale(1.2, 1.2)\n",
    "\n",
    "    output_file = os.path.join(folder_aset, 'table', 'table_laporan.png')\n",
    "    plt.savefig(output_file, bbox_inches='tight', pad_inches=0.1, transparent=True)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laporan_tabel(kab_df_complete_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_laporan_sh(dataframe):\n",
    "    # Pembuatan chart laporan\n",
    "    regions = dataframe['Wilayah']\n",
    "    bawah_normal_val = dataframe['Bawah Normal (%)']\n",
    "    normal_val = dataframe['Normal (%)']\n",
    "    atas_normal_val = dataframe['Atas Normal (%)']\n",
    "    threshold=3.5  # threshold untuk ukuran bar memiliki label\n",
    "\n",
    "    # Add text label\n",
    "    bawah_normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in bawah_normal_val]\n",
    "    normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in normal_val]\n",
    "    atas_normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in atas_normal_val]\n",
    "\n",
    "\n",
    "    # Create the plot\n",
    "    # Create the plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add traces\n",
    "    fig.add_trace(go.Bar(y=regions,\n",
    "        x=bawah_normal_val,\n",
    "        name='Bawah Normal (%)',\n",
    "        orientation='h',\n",
    "        marker=dict(color='#8e2800'),\n",
    "        text=rendah_text,\n",
    "        textposition='auto'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=regions,\n",
    "        x=normal_val,\n",
    "        name='Normal (%)',\n",
    "        orientation='h',\n",
    "        marker=dict(color='#eaff00'),\n",
    "        text=menengah_text,\n",
    "        textposition='auto'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=regions,\n",
    "        x=atas_normal_val,\n",
    "        name='Atas Normal (%)',\n",
    "        orientation='h',\n",
    "        marker=dict(color='#8bd48b'),\n",
    "        text=tinggi_text,\n",
    "        textposition='auto'\n",
    "    ))\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        barmode='stack',\n",
    "        title=dict(\n",
    "            text=f'Persentase Kategori CH',\n",
    "            font=dict(size=23, color='black', family='Arial Black') ),\n",
    "        xaxis=dict(title=dict(\n",
    "                text='Persentase (%)',\n",
    "                font=dict(size=14)  # Set the font size for the x-axis title\n",
    "            ),\n",
    "            tickfont=dict(size=14)),\n",
    "        yaxis=dict(\n",
    "            tickfont=dict(size=14)  # Set the font size for the y-axis ticks\n",
    "        ),\n",
    "        legend=dict(title=dict(\n",
    "                text='Kategori',\n",
    "                font=dict(size=14)), \n",
    "            x=0.5,\n",
    "            y=-0.1,\n",
    "            xanchor='center',\n",
    "            yanchor='top',\n",
    "            orientation='h',\n",
    "            font=dict(size=14)),\n",
    "        width=1000,  # Set the width of the figure\n",
    "        height=800,\n",
    "        plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot background\n",
    "        paper_bgcolor='rgba(0,0,0,0)' \n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def chart_laporan_sh(dataframe):\n",
    "    folder_aset = os.getenv(\"ASSET\")\n",
    "    regions = dataframe['Wilayah']\n",
    "    bawah_normal_val = dataframe['Bawah Normal (%)']\n",
    "    normal_val = dataframe['Normal (%)']\n",
    "    atas_normal_val = dataframe['Atas Normal (%)']\n",
    "    threshold = 3.5  # threshold for bar label visibility\n",
    "\n",
    "    # Add text label\n",
    "    bawah_normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in bawah_normal_val]\n",
    "    normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in normal_val]\n",
    "    atas_normal_text = [f'{val:.2f}%' if val >= threshold else '' for val in atas_normal_val]\n",
    "\n",
    "    bar_width = 0.8  # Width of the bars\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    # Create the stacked bar chart\n",
    "    bars_bawah_normal = ax.barh(regions, bawah_normal_val, color='#340900', edgecolor='white', height=bar_width, label='Bawah Normal (%)')\n",
    "    bars_normal = ax.barh(regions, normal_val, left=bawah_normal_val, color='#eaff00', edgecolor='white', height=bar_width, label='Normal (%)')\n",
    "    bars_atas_normal = ax.barh(regions, atas_normal_val, left=bawah_normal_val + normal_val, color='#00450c', edgecolor='white', height=bar_width, label='Atas Normal (%)')\n",
    "\n",
    "    # Add text labels inside the bars\n",
    "    for bars, text in zip([bars_bawah_normal, bars_normal, bars_atas_normal], [bawah_normal_text, normal_text, atas_normal_text]):\n",
    "        for bar, label in zip(bars, text):\n",
    "            if label:  # Only add label if it's not an empty string\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2, bar.get_y() + bar.get_height() / 2, label, va='center', ha='center', fontsize=10, color='red', weight='bold')\n",
    "\n",
    "    # Customize layout\n",
    "    # ax.set_title('Persentase Kategori CH', fontsize=23, fontweight='bold', family='DejaVu Sans')\n",
    "    ax.set_xlabel('Persentase (%)', fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    legend = ax.legend(title='Kategori Sifat Hujan', fontsize=14, title_fontsize=14, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)\n",
    "    legend.get_frame().set_linewidth(0.0)  # Remove the legend box line\n",
    "    legend.get_frame().set_edgecolor('none') \n",
    "\n",
    "    # Set the background color\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Remove gridlines and outline\n",
    "    ax.grid(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    output_file = os.path.join(folder_aset, 'chart','laporan', 'chart_laporan.png')\n",
    "    plt.savefig(output_file, bbox_inches='tight', pad_inches=0.1, transparent=True)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage\n",
    "# df = pd.DataFrame({\n",
    "#     'Wilayah': ['Region A', 'Region B', 'Region C'],\n",
    "#     'Bawah Normal (%)': [10, 20, 30],\n",
    "#     'Normal (%)': [40, 30, 20],\n",
    "#     'Atas Normal (%)': [50, 50, 50]\n",
    "# })\n",
    "# chart_laporan_sh(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_laporan_sh(kab_df_complete_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_laporan_ch(dataframe):\n",
    "    folder_aset = os.getenv(\"ASSET\")\n",
    "    regions = dataframe['Wilayah']\n",
    "    rendah_val = dataframe['Rendah (%)']\n",
    "    menengah_val = dataframe['Menengah (%)']\n",
    "    tinggi_val = dataframe['Tinggi (%)']\n",
    "    sgt_tinggi_val = dataframe['Sangat Tinggi (%)']\n",
    "    threshold = 3.5  # threshold for bar label visibility\n",
    "\n",
    "    # Add text label\n",
    "    rendah_text = [f'{val:.2f}%' if val >= threshold else '' for val in rendah_val]\n",
    "    menengah_text = [f'{val:.2f}%' if val >= threshold else '' for val in menengah_val]\n",
    "    tinggi_text = [f'{val:.2f}%' if val >= threshold else '' for val in tinggi_val]\n",
    "    sgt_tinggi_text = [f'{val:.2f}%' if val >= threshold else '' for val in sgt_tinggi_val]\n",
    "\n",
    "    bar_width = 0.8  # Width of the bars\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    # Create the stacked bar chart\n",
    "    bars_rendah = ax.barh(regions, rendah_val, color='#340900', edgecolor='white', height=bar_width, label='Rendah (%)')\n",
    "    bars_menengah = ax.barh(regions, menengah_val, left=rendah_val, color='#eaff00', edgecolor='white', height=bar_width, label='Menengah (%)')\n",
    "    bars_tinggi = ax.barh(regions, tinggi_val, left=rendah_val + menengah_val, color='#8bd48b', edgecolor='white', height=bar_width, label='Tinggi (%)')\n",
    "    bars_sgt_tinggi = ax.barh(regions, tinggi_val, left=rendah_val + menengah_val + tinggi_val, color='#00450c', edgecolor='white', height=bar_width, label='Sangat Tinggi (%)')\n",
    "\n",
    "    # Add text labels inside the bars\n",
    "    for bars, text in zip([bars_rendah, bars_menengah, bars_tinggi, bars_sgt_tinggi], [rendah_text, menengah_text, tinggi_text, sgt_tinggi_text]):\n",
    "        for bar, label in zip(bars, text):\n",
    "            if label:  # Only add label if it's not an empty string\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2, bar.get_y() + bar.get_height() / 2, label, va='center', ha='center', fontsize=10, color='red', weight='bold')\n",
    "\n",
    "    # Customize layout\n",
    "    # ax.set_title('Persentase Kategori CH', fontsize=23, fontweight='bold', family='DejaVu Sans')\n",
    "    ax.set_xlabel('Persentase (%)', fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    legend = ax.legend(title='Kategori Curah Hujan', fontsize=14, title_fontsize=14, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)\n",
    "    legend.get_frame().set_linewidth(0.0)  # Remove the legend box line\n",
    "    legend.get_frame().set_edgecolor('none') \n",
    "\n",
    "    # Set the background color\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Remove gridlines and outline\n",
    "    ax.grid(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def chart_laporan_ch(dataframe):\n",
    "    regions = dataframe['Wilayah']\n",
    "    rendah_val = dataframe['Rendah (%)']\n",
    "    menengah_val = dataframe['Menengah (%)']\n",
    "    tinggi_val = dataframe['Tinggi (%)']\n",
    "    sgt_tinggi_val = dataframe['Sangat Tinggi (%)']\n",
    "    threshold = 3.5  # threshold for bar label visibility\n",
    "\n",
    "    # Add text label\n",
    "    rendah_text = [f'{val:.2f}%' if val >= threshold else '' for val in rendah_val]\n",
    "    menengah_text = [f'{val:.2f}%' if val >= threshold else '' for val in menengah_val]\n",
    "    tinggi_text = [f'{val:.2f}%' if val >= threshold else '' for val in tinggi_val]\n",
    "    sgt_tinggi_text = [f'{val:.2f}%' if val >= threshold else '' for val in sgt_tinggi_val]\n",
    "\n",
    "    bar_height = 0.8  # Height of the bars, reduced to make the distance between bars narrower\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    # Create the stacked bar chart\n",
    "    bars_rendah = ax.barh(regions, rendah_val, color='#340900', edgecolor='white', height=bar_height, label='Rendah (%)')\n",
    "    bars_menengah = ax.barh(regions, menengah_val, left=rendah_val, color='#eaff00', edgecolor='white', height=bar_height, label='Menengah (%)')\n",
    "    bars_tinggi = ax.barh(regions, tinggi_val, left=rendah_val + menengah_val, color='#8bd48b', edgecolor='white', height=bar_height, label='Tinggi (%)')\n",
    "    bars_sgt_tinggi = ax.barh(regions, sgt_tinggi_val, left=rendah_val + menengah_val + tinggi_val, color='#00450c', edgecolor='white', height=bar_height, label='Sangat Tinggi (%)')\n",
    "\n",
    "    # Add text labels inside the bars\n",
    "    for bars, text in zip([bars_rendah, bars_menengah, bars_tinggi, bars_sgt_tinggi], [rendah_text, menengah_text, tinggi_text, sgt_tinggi_text]):\n",
    "        for bar, label in zip(bars, text):\n",
    "            if label:  # Only add label if it's not an empty string\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2, bar.get_y() + bar.get_height() / 2, label, va='center', ha='center', fontsize=10, color='red', weight='bold')\n",
    "\n",
    "    # Customize layout\n",
    "    ax.set_xlabel('Persentase (%)', fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    legend = ax.legend(title='Kategori Curah Hujan', fontsize=14, title_fontsize=14, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=4)\n",
    "    legend.get_frame().set_linewidth(0.0)  # Remove the legend box line\n",
    "    legend.get_frame().set_edgecolor('none')  # Ensure no edge color\n",
    "\n",
    "    # Remove gridlines and outline\n",
    "    ax.grid(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "    # Set the background color\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# df = pd.DataFrame({\n",
    "#     'Wilayah': ['Region A', 'Region B', 'Region C'],\n",
    "#     'Rendah (%)': [10, 20, 30],\n",
    "#     'Menengah (%)': [20, 30, 20],\n",
    "#     'Tinggi (%)': [30, 20, 30],\n",
    "#     'Sangat Tinggi (%)': [40, 30, 20]\n",
    "# })\n",
    "# chart_laporan_sh(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kab_df_complete_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_laporan_ch(kab_df_complete_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from config import nama_stasiun, nama_prov, nama_prov_union_shp\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_chart import cut_image\n",
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "from utils.proses1_chart import chart_infografis_ch, chart_infografis_sh, laporan_tabel, chart_laporan_ch, chart_laporan_sh\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_project = os.getenv(\"APRX_PROJECT\")\n",
    "prov_referensi = os.getenv(\"POLY_PROV\")\n",
    "laporan = PembuatanPetaLaporan(map_project=map_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_ch = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ach_bln_indo_ver_202409.shp\"\n",
    "\n",
    "feature_sh = r\"D:\\Project\\BMKG SiPinter Iklim\\OUTPUT_FOLDER\\PINTER-IKLIM\\INDONESIA\\ANALISA-BULANAN\\SHP\\2024.09\\ash_bln_indo_ver_202409.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_ch = pd.DataFrame.spatial.from_featureclass(feature_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prov_df_complete, kab_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_upt(dataframe = dataframe_ch, tipe_informasi = 'ANALISA CURAH HUJAN', wilayah_upt = 'BALI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laporan.laporan_bln(feature_ch, tipe_informasi='ANALISA CURAH HUJAN')\n",
    "# laporan.laporan_bln(feature_sh, tipe_informasi='ANALISA SIFAT HUJAN')\n",
    "# laporan.laporan_das(feature_ch, tipe_informasi='ANALISA CURAH HUJAN')\n",
    "# laporan.laporan_das(feature_sh, tipe_informasi='ANALISA SIFAT HUJAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "tipe_informasi = 'ANALISA CURAH HUJAN'\n",
    "\n",
    "indo_df_complete, prov_df_complete_clean,pulau_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_indo(dataframe, tipe_informasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bln 2\n",
    "\n",
    "feature = feature_ch\n",
    "tipe_informasi = 'ANALISA CURAH HUJAN'\n",
    "        \n",
    "aprx = arcpy.mp.ArcGISProject(map_project)\n",
    "\n",
    "layout_laporan1_ach = aprx.listLayouts(\"laporan_ach_pusat_1\")[0]\n",
    "layout_laporan2_ach = aprx.listLayouts(\"laporan_ach_pusat_2\")[0]\n",
    "layout_laporan1_ash = aprx.listLayouts(\"laporan_ash_pusat_1\")[0]\n",
    "layout_laporan2_ash = aprx.listLayouts(\"laporan_ash_pusat_2\")[0]\n",
    "layout_laporan_ach_upt = aprx.listLayouts(\"laporan_ach_upt\")[0]\n",
    "layout_laporan_ash_upt = aprx.listLayouts(\"laporan_ash_upt\")[0]\n",
    "\n",
    "map_frame_ch = layout_laporan1_ach.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame CH')[0]\n",
    "map_obj_ch = map_frame_ch.map\n",
    "prov_layer_ch = map_obj_ch.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_ch = map_obj_ch.listLayers(\"admin_kab\")[0]\n",
    "kec_layer_ch = map_obj_ch.listLayers(\"idkec\")[0]\n",
    "\n",
    "map_frame_sh = layout_laporan1_ash.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame SH')[0]\n",
    "map_obj_sh = map_frame_sh.map\n",
    "prov_layer_sh = map_obj_sh.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_sh = map_obj_sh.listLayers(\"admin_kab\")[0]\n",
    "kec_layer_sh = map_obj_sh.listLayers(\"idkec\")[0]\n",
    "\n",
    "# UPT\n",
    "map_frame_ch_upt = layout_laporan_ach_upt.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame CH')[0]\n",
    "map_obj_ch = map_frame_ch_upt.map\n",
    "prov_layer_ch_upt = map_obj_ch.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_ch_upt = map_obj_ch.listLayers(\"admin_kab\")[0]\n",
    "kec_layer_ch_upt = map_obj_ch.listLayers(\"idkec\")[0]\n",
    "\n",
    "map_frame_sh_upt = layout_laporan_ash_upt.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame SH')[0]\n",
    "map_obj_sh = map_frame_sh_upt.map\n",
    "prov_layer_sh_upt = map_obj_sh.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_sh_upt = map_obj_sh.listLayers(\"admin_kab\")[0]\n",
    "kec_layer_sh_upt = map_obj_sh.listLayers(\"idkec\")[0]\n",
    "\n",
    "\n",
    "layers_to_hide = [prov_layer_ch, prov_layer_sh, prov_layer_ch_upt, prov_layer_sh_upt]\n",
    "layers_to_show = [kab_layer_ch, kab_layer_sh, kab_layer_ch_upt, kab_layer_sh_upt]\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "\n",
    "\n",
    "print(\"Proses Pembuatan Infografis dimulai . . .\")\n",
    "\n",
    "prov_referensi = os.getenv(\"POLY_PROV\")\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "folder_aset = os.getenv(\"ASSET\")\n",
    "\n",
    "with arcpy.da.SearchCursor(prov_referensi, [\"WADMPR\", \"SHAPE@\"]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "        try:\n",
    "            wilayah_ref = r[0]\n",
    "            prov_geometry = r[1]\n",
    "            if wilayah_ref == 'Indonesia':\n",
    "                print(wilayah_ref)\n",
    "                \n",
    "                # initial_state_infog1 = self.store_initial_state(layout_infog1_ach)\n",
    "                # initial_state_infog2 = self.store_initial_state(layout_infog2_ach)\n",
    "\n",
    "                if tipe_informasi == 'ANALISA CURAH HUJAN':\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_report = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                    output_tipe_periode='ANALISA-BULANAN', tipe='REPORT')\n",
    "\n",
    "\n",
    "                    indo_df_complete, prov_df_complete_clean, pulau_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_indo(dataframe, tipe_informasi)\n",
    "\n",
    "                    wilayah_sgt_tinggi = top_by_kategori['Sangat Tinggi']\n",
    "                    wilayah_tinggi = top_by_kategori['Tinggi']\n",
    "                    wilayah_menengah = top_by_kategori['Menengah']\n",
    "                    wilayah_rendah = top_by_kategori['Rendah']\n",
    "\n",
    "\n",
    "                    laporan_tabel(pulau_df_complete_clean)\n",
    "                    chart_laporan_ch(pulau_df_complete_clean)\n",
    "\n",
    "                    print(\"Print Laporan 1\")\n",
    "                    # Set extent sesuai geometry\n",
    "                    \n",
    "                    map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                    prov_layer_ch.visible = False\n",
    "                    kab_layer_ch.visible = False\n",
    "                    kec_layer_ch.visible = False\n",
    "\n",
    "                    # output_file = os.path.join(folder_aset, 'maps', f\"peta_infografis.png\")\n",
    "                    # output_ach = os.path.join(folder_aset, 'maps', f\"peta_infografis_ach.png\")\n",
    "                    # output_ash = os.path.join(folder_aset, 'maps', f\"peta_infografis_ash.png\")\n",
    "\n",
    "                    # layout_peta.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                    # cut_image(output_file, output_ach, output_ash)\n",
    "\n",
    "\n",
    "                    elements_laporan1 = layout_laporan1_ach.listElements()\n",
    "\n",
    "                    for element in elements_laporan1:\n",
    "                        if element.name == \"JUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year} INDONESIA DAN PULAU BESAR')\n",
    "                        elif element.name == \"TEKS\":\n",
    "                            element.text = element.text.replace('[TEKS]', f'Pada bulan {month_name} {year}, umumnya wilayah Indonesia akan mengalami curah hujan kategori <BOL>SANGAT TINGGI {sgt_tinggi}%</BOL>, <BOL>TINGGI {tinggi}%</BOL>, <BOL>MENENGAH {menengah}%</BOL>, dan <BOL>RENDAH {rendah}%</BOL>. Wilayah yang dominan <BOL>SANGAT TINGGI </BOL> yaitu {wilayah_sgt_tinggi}. Wilayah yang dominan <BOL>TINGGI</BOL> yaitu {wilayah_tinggi}. Wilayah yang dominan <BOL>MENENGAH</BOL> yaitu {wilayah_menengah}. Wilayah yang dominan <BOL>RENDAH</BOL> yaitu {wilayah_rendah}.')\n",
    "\n",
    "                    \n",
    "                    print(\"Print Laporan 2\")\n",
    "\n",
    "                    elements_laporan2 = layout_laporan2_ach.listElements()\n",
    "\n",
    "                    for element in elements_laporan2:\n",
    "                        if element.name == 'TABEL':\n",
    "                                element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'table', 'table_laporan.png'), \n",
    "                                                                                (os.path.join(folder_aset,'table', 'table_laporan.png')))\n",
    "                        elif element.name == 'CHART':\n",
    "                                element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'laporan', 'chart_laporan.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'laporan', 'chart_laporan.png')))\n",
    "                        elif element.name == \"JUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year} INDONESIA DAN PULAU BESAR')\n",
    "                        elif element.name == \"JUDUL-TABEL\":\n",
    "                            element.text = element.text.replace('[WILAYAH]', 'Indonesia dan Pulau Besar')\n",
    "                        elif element.name == \"JUDUL-CHART\":\n",
    "                            element.text = element.text.replace('[WILAYAH]', 'Indonesia dan Pulau Besar')\n",
    "                        \n",
    "\n",
    "\n",
    "                    temp_pdf1 = os.path.join(output_loc_report, 'infog1.pdf')\n",
    "                    temp_pdf2 = os.path.join(output_loc_report, 'infog2.pdf')\n",
    "                    layout_laporan1_ach.exportToPDF(temp_pdf1, resolution=300)\n",
    "                    layout_laporan2_ach.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                    pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_report, f'report_ach_bln_indo_ver_{year}{month}.pdf'))\n",
    "                    pdf_doc.appendPages(temp_pdf1)\n",
    "                    pdf_doc.appendPages(temp_pdf2)\n",
    "                    pdf_doc.saveAndClose()\n",
    "\n",
    "                    os.remove(temp_pdf1)\n",
    "                    os.remove(temp_pdf2)\n",
    "\n",
    "                else: # tipe_informasi == 'ANALISA SIFAT HUJAN'\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_report = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                    output_tipe_periode='ANALISA-BULANAN', tipe='REPORT')\n",
    "\n",
    "\n",
    "                    indo_df_complete, prov_df_complete_clean, pulau_df_complete_clean, top_by_kategori,  atas_normal, normal, bawah_normal= dataframe_indo(dataframe, tipe_informasi)\n",
    "\n",
    "                    wilayah_atas_normal = top_by_kategori['Atas Normal']\n",
    "                    wilayah_normal = top_by_kategori['Normal']\n",
    "                    wilayah_bawah_normal = top_by_kategori['Bawah Normal']\n",
    "\n",
    "\n",
    "                    laporan_tabel(pulau_df_complete_clean)\n",
    "                    chart_laporan_sh(pulau_df_complete_clean)\n",
    "\n",
    "                    print(\"Print Infografis 1\")\n",
    "                    # Set extent sesuai geometry\n",
    "                    \n",
    "                    map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                    prov_layer_sh.visible = False\n",
    "                    kab_layer_sh.visible = False\n",
    "                    kec_layer_sh.visible = False\n",
    "\n",
    "\n",
    "\n",
    "                    elements_laporan1 = layout_laporan1_ash.listElements()\n",
    "\n",
    "                    for element in elements_laporan1:\n",
    "                        if element.name == \"JUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year} INDONESIA DAN PULAU BESAR')\n",
    "                        elif element.name == \"TEKS\":\n",
    "                            element.text = element.text.replace('[TEKS]', f'Pada bulan {month_name} {year}, umumnya wilayah Indonesia akan mengalami sifat hujan kategori <BOL>ATAS NORMAL {atas_normal}%</BOL>, <BOL>NORMAL {normal}%</BOL>, dan <BOL>BAWAH NORMAL {bawah_normal}%</BOL>. Wilayah yang dominan <BOL>ATAS NORMAL </BOL> yaitu {wilayah_atas_normal}. Wilayah yang dominan <BOL>NORMAL</BOL> yaitu {wilayah_normal}. Wilayah yang dominan <BOL>BAWAH NORMAL</BOL> yaitu {wilayah_bawah_normal}.')\n",
    "\n",
    "                    \n",
    "                    print(\"Print Laporan 2\")\n",
    "\n",
    "                    elements_laporan2 = layout_laporan2_ash.listElements()\n",
    "\n",
    "                    for element in elements_laporan2:\n",
    "                        if element.name == 'TABEL':\n",
    "                                element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'table', 'table_laporan.png'), \n",
    "                                                                                (os.path.join(folder_aset,'table', 'table_laporan.png')))\n",
    "                        elif element.name == 'CHART':\n",
    "                                element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'laporan', 'chart_laporan.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'laporan', 'chart_laporan.png')))\n",
    "                        elif element.name == \"JUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year} INDONESIA DAN PULAU BESAR')\n",
    "                        elif element.name == \"JUDUL-TABEL\":\n",
    "                            element.text = element.text.replace('[WILAYAH]]', 'Indonesia dan Pulau Besar')\n",
    "                        elif element.name == \"JUDUL-CHART\":\n",
    "                            element.text = element.text.replace('[WILAYAH]', 'Indonesia dan Pulau Besar')\n",
    "\n",
    "                    temp_pdf1 = os.path.join(output_loc_report, 'infog1.pdf')\n",
    "                    temp_pdf2 = os.path.join(output_loc_report, 'infog2.pdf')\n",
    "                    layout_laporan1_ash.exportToPDF(temp_pdf1, resolution=300)\n",
    "                    layout_laporan2_ash.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                    pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_report, f'report_ash_bln_indo_ver_{year}{month}.pdf'))\n",
    "                    pdf_doc.appendPages(temp_pdf1)\n",
    "                    pdf_doc.appendPages(temp_pdf2)\n",
    "                    pdf_doc.saveAndClose()\n",
    "\n",
    "                    os.remove(temp_pdf1)\n",
    "                    os.remove(temp_pdf2)\n",
    "\n",
    "\n",
    "            else: # wilayah_ref == UPT\n",
    "                wilayah_upt = nama_prov_union_shp[wilayah_ref]\n",
    "        \n",
    "                print(wilayah_ref)\n",
    "                if tipe_informasi == 'ANALISA CURAH HUJAN':\n",
    "                    \n",
    "                    initial_state_laporan1 = self.store_initial_state(layout_laporan_ach_upt)\n",
    "                    \n",
    "\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_report = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                            output_tipe_periode='ANALISA-BULANAN', tipe='REPORT', \n",
    "                                                                            nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                    \n",
    "\n",
    "                    prov_df_complete, kab_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_upt(dataframe, tipe_informasi, nama_prov_union_shp[wilayah_ref])\n",
    "\n",
    "                    wilayah_sgt_tinggi = top_by_kategori['Sangat Tinggi']\n",
    "                    wilayah_tinggi = top_by_kategori['Tinggi']\n",
    "                    wilayah_menengah = top_by_kategori['Menengah']\n",
    "                    wilayah_rendah = top_by_kategori['Rendah']\n",
    "\n",
    "                    \n",
    "                    chart_laporan_ch(prov_df_complete)\n",
    "\n",
    "                    print(\"Print Laporan 1\")\n",
    "                    map_frame_ch_upt.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                    \n",
    "\n",
    "                    # if kab_layer_ch.isFeatureLayer:\n",
    "                    #     for lbl_class in kab_layer_ch.listLabelClasses():\n",
    "                    #         lbl_class.showClassLabels = True\n",
    "                    #         lbl_class.symbol.fontSize = 10\n",
    "                    #     kab_layer_ch.showLabels = True\n",
    "\n",
    "\n",
    "\n",
    "                    for layer in layers_to_hide:\n",
    "                            if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            for layer in layers_to_show:\n",
    "                                if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            \n",
    "\n",
    "                    elements_laporan1 = layout_laporan_ach_upt.listElements()\n",
    "\n",
    "                    for element in elements_laporan1:\n",
    "                        if element.name == \"JUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year} {nama_prov[wilayah_ref]}')\n",
    "                        elif element.name == \"TEKS\":\n",
    "                            element.text = element.text.replace('[TEKS]', f'Pada bulan {month_name} {year}, umumnya wilayah {nama_prov[wilayah_ref].title()} akan mengalami curah hujan kategori <BOL>SANGAT TINGGI {sgt_tinggi}%</BOL>, <BOL>TINGGI {tinggi}%</BOL>, <BOL>MENENGAH {menengah}%</BOL>, dan <BOL>RENDAH {rendah}%</BOL>. Wilayah yang dominan <BOL>SANGAT TINGGI </BOL> yaitu {wilayah_sgt_tinggi}. Wilayah yang dominan <BOL>TINGGI</BOL> yaitu {wilayah_tinggi}. Wilayah yang dominan <BOL>MENENGAH</BOL> yaitu {wilayah_menengah}. Wilayah yang dominan <BOL>RENDAH</BOL> yaitu {wilayah_rendah}.')\n",
    "                        elif element.name == 'CHART':\n",
    "                                element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png')))\n",
    "\n",
    "                    layout_laporan_ach_upt.exportToPNG(os.path.join(output_loc_report, f'report_ach_bln_{wilayah_ref.lower()}_ver_{year}{month}.png'), resolution=300, clip_to_elements=True)\n",
    "\n",
    "                    \n",
    "                    self.reset_elements(layout_laporan_ach_upt, initial_state_laporan1)\n",
    "                    \n",
    "\n",
    "                else: # tipe_informasi == 'ANALISA SIFAT HUJAN'\n",
    "                    \n",
    "                    initial_state_laporan1 = self.store_initial_state(layout_laporan_ash_upt)\n",
    "                    \n",
    "\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_report = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                            output_tipe_periode='ANALISA-BULANAN', tipe='REPORT', \n",
    "                                                                            nama_prov=nama_prov, pulau_kecil=wilayah_ref)\n",
    "                    \n",
    "\n",
    "                    prov_df_complete, kab_df_complete_clean, top_by_kategori, atas_normal, normal, bawah_normal = dataframe_upt(dataframe, tipe_informasi, nama_prov_union_shp[wilayah_ref])\n",
    "\n",
    "                    wilayah_atas_normal = top_by_kategori['Atas Normal']\n",
    "                    wilayah_normal = top_by_kategori['Normal']\n",
    "                    wilayah_bawah_normal = top_by_kategori['Bawah Normal']\n",
    "\n",
    "                    \n",
    "                    chart_laporan_sh(prov_df_complete_clean)\n",
    "\n",
    "                    print(\"Print Laporan 1\")\n",
    "                    map_frame_sh_upt.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "\n",
    "                    # if kab_layer_sh.isFeatureLayer:\n",
    "                    #     for lbl_class in kab_layer_sh.listLabelClasses():\n",
    "                    #         lbl_class.showClassLabels = True\n",
    "                    #         lbl_class.symbol.fontSize = 10\n",
    "                    #     kab_layer_sh.showLabels = True\n",
    "\n",
    "\n",
    "                    for layer in layers_to_hide:\n",
    "                            if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            for layer in layers_to_show:\n",
    "                                if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    elements_laporan1 = layout_laporan_ash_upt.listElements()\n",
    "\n",
    "                    for element in elements_laporan1:\n",
    "                        if element.name == \"JUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year} {nama_prov[wilayah_ref]}')\n",
    "                        elif element.name == \"TEKS\":\n",
    "                            element.text = element.text.replace('[TEKS]', f'Pada bulan {month_name} {year}, umumnya wilayah {nama_prov[wilayah_ref].title()} akan mengalami sifat hujan kategori <BOL>ATAS NORMAL {atas_normal}%</BOL>, <BOL>NORMAL {normal}%</BOL>, dan <BOL>BAWAH NORMAL {bawah_normal}%</BOL>. Wilayah yang dominan <BOL>ATAS NORMAL </BOL> yaitu {wilayah_atas_normal}. Wilayah yang dominan <BOL>NORMAL</BOL> yaitu {wilayah_normal}. Wilayah yang dominan <BOL>BAWAH NORMAL</BOL> yaitu {wilayah_bawah_normal}.')\n",
    "                        elif element.name == 'CHART':\n",
    "                                element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png')))\n",
    "\n",
    "                    layout_laporan_ash_upt.exportToPNG(os.path.join(output_loc_report, f'report_ash_bln_{wilayah_ref.lower()}_ver_{year}{month}.png'), resolution=300, clip_to_elements=True)\n",
    "\n",
    "                    \n",
    "                    self.reset_elements(layout_laporan_ash_upt, initial_state_laporan1)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error di pengolahan Pulau/Provinsi {wilayah_ref}: {e}\")\n",
    "            continue  # Skip to the next island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "#import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import locale\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_preprocess import Preprocessing\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "from utils.proses1_data_process import interpolasi_bln, interpolasi_das\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "## Get time\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "# Get geodatabase\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "output_table_name = \"output_1_proses1_table\"\n",
    "output_feature_name = \"output_2_proses1_feature_point\"\n",
    "\n",
    "\n",
    "## Input folder structure\n",
    "main_folder = os.getenv(\"MAIN_FOLDER\")\n",
    "folder_bulanan = r'BULANAN'\n",
    "folder_dasarian = r'DASARIAN'\n",
    "file_name_bulanan = f'BlendGSMAP_POS.{year}{month}.xls'\n",
    "file_name_dasarian = f'BlendGSMAP_POS.{year}{month}dec0{current_dasarian}.xls'\n",
    "\n",
    "# Output folder structure\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "output_level_ind = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA_BULANAN'\n",
    "output_tipe_das = 'ANALISA_DASARIAN'\n",
    "\n",
    "# Get full folder path\n",
    "file_path_bulanan = os.path.join(main_folder, folder_bulanan)\n",
    "file_path_dasarian = os.path.join(main_folder, folder_dasarian)\n",
    "\n",
    "# File input\n",
    "file_input_bulanan = os.path.join(file_path_bulanan, file_name_bulanan)\n",
    "file_input_dasarian = os.path.join(file_path_dasarian, file_name_dasarian)\n",
    "\n",
    "\n",
    "# map project\n",
    "map_project = os.getenv(\"APRX_PROJECT\")\n",
    "\n",
    "\n",
    "print(\"Proses Ekstraksi Table Excel dimulai ... \")\n",
    "start_time = datetime.datetime.now()\n",
    "# Memulai ekstraksi excel ke feature point\n",
    "preprocessing_bln = Preprocessing(fgdb_temp, file_input_bulanan)\n",
    "\n",
    "# # Panggil metode Get_Excel untuk mengonversi file Excel ke tabel\n",
    "point_bln = preprocessing_bln.Excel_to_Feature(output_table_name = output_table_name+'_bln', output_feature_name = output_feature_name+'_bln')\n",
    "end_time = datetime.datetime.now()\n",
    "duration = end_time - start_time\n",
    "print(f\"Proses Ekstraksi Table Excel Selesai selama: {duration.seconds} detik\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Analisa Data Bulanan dimulai\")\n",
    "\n",
    "poly_indo_ach, poly_indo_ash = interpolasi_bln(input_data= point_bln)\n",
    "end_time = datetime.datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Analisa Data Bulanan selesai selama: {(duration.total_seconds() % 3600) // 60} menit\")\n",
    "print(\"\\n\")\n",
    "\n",
    "pelaporan = PembuatanPetaLaporan(map_project=map_project)\n",
    "\n",
    "\n",
    "# peta1_bulanan = pelaporan.peta_1(periode_informasi='ANALISA_BULANAN')\n",
    "# print(\"Peta 1 berhasil\")\n",
    "\n",
    "# peta2_bulanan = pelaporan.peta_2(periode_informasi='ANALISA_BULANAN')\n",
    "# print(\"Peta 2 berhasil\")\n",
    "\n",
    "# print(\"Infografis Bulanan CH berhasil\")\n",
    "# infografis_ch = pelaporan.infografis_bln(feature = poly_indo_ach, tipe_informasi='ANALISA_CURAH_HUJAN')\n",
    "\n",
    "# infografis_sh = pelaporan.infografis_bln(feature = poly_indo_ash, tipe_informasi='ANALISA_SIFAT_HUJAN')\n",
    "# print(\"Infografis Bulanan SH berhasil\")\n",
    "\n",
    "# laporan_ch = pelaporan.laporan_bln2(feature = poly_indo_ach, tipe_informasi='ANALISA_CURAH_HUJAN')\n",
    "# print(\"Laporan Bulanan CH berhasil\")\n",
    "\n",
    "# laporan_sh = pelaporan.laporan_bln2(feature = poly_indo_ash, tipe_informasi='ANALISA_SIFAT_HUJAN')\n",
    "\n",
    "# print(\"Laporan Bulanan SH berhasil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_ch = r'F:\\ASSET\\spatial\\BMKG_PinterIklim\\proses1_data_layout.gdb\\polygon_ach'\n",
    "dataframe_sh = r'F:\\ASSET\\spatial\\BMKG_PinterIklim\\proses1_data_layout.gdb\\polygon_ash'\n",
    "\n",
    "\n",
    "\n",
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "#import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import locale\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_preprocess import Preprocessing\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "from utils.proses1_data_process import interpolasi_bln, interpolasi_das\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "## Get time\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "map_project = os.getenv(\"APRX_PROJECT\")\n",
    "pelaporan = PembuatanPetaLaporan(map_project=map_project)\n",
    "\n",
    "\n",
    "\n",
    "infografis_ch = pelaporan.infografis_das(feature = dataframe_ch, tipe_informasi='ANALISA_CURAH_HUJAN')\n",
    "print(\"Infografis Bulanan CH berhasil\")\n",
    "\n",
    "infografis_sh = pelaporan.infografis_das(feature = dataframe_sh, tipe_informasi='ANALISA_SIFAT_HUJAN')\n",
    "print(\"Infografis Bulanan SH berhasil\")\n",
    "\n",
    "laporan_ch = pelaporan.laporan_das2(feature = dataframe_ch, tipe_informasi='ANALISA_CURAH_HUJAN')\n",
    "print(\"Laporan Bulanan CH berhasil\")\n",
    "\n",
    "laporan_sh = pelaporan.laporan_das2(feature = dataframe_sh, tipe_informasi='ANALISA_SIFAT_HUJAN')\n",
    "\n",
    "print(\"Laporan Bulanan SH berhasil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "from config import nama_stasiun, nama_prov, nama_prov_union_shp, nama_prov_folder\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_chart import cut_image\n",
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "from utils.proses1_chart import chart_infografis_ch, chart_infografis_sh, laporan_tabel, chart_laporan_ch, chart_laporan_sh\n",
    "\n",
    "\n",
    "def infografis_das( feature, tipe_informasi):\n",
    "        \n",
    "    aprx = arcpy.mp.ArcGISProject(map_project)\n",
    "    \n",
    "    layout_infog1_ach = aprx.listLayouts(\"Infografis_ach_pusat_1\")[0]\n",
    "    layout_infog2_ach = aprx.listLayouts(\"Infografis_ach_pusat_2\")[0]\n",
    "    layout_infog1_ash = aprx.listLayouts(\"Infografis_ash_pusat_1\")[0]\n",
    "    layout_infog2_ash = aprx.listLayouts(\"Infografis_ash_pusat_2\")[0]\n",
    "\n",
    "    map_frame_ch = layout_infog1_ach.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame CH')[0]\n",
    "    map_obj_ch = map_frame_ch.map\n",
    "    prov_layer_ch = map_obj_ch.listLayers(\"admin_prov\")[0]\n",
    "    kab_layer_ch = map_obj_ch.listLayers(\"admin_kab\")[0]\n",
    "    kec_layer_ch = map_obj_ch.listLayers(\"idkec\")[0]\n",
    "\n",
    "    map_frame_sh = layout_infog1_ash.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame SH')[0]\n",
    "    map_obj_sh = map_frame_sh.map\n",
    "    prov_layer_sh = map_obj_sh.listLayers(\"admin_prov\")[0]\n",
    "    kab_layer_sh = map_obj_sh.listLayers(\"admin_kab\")[0]\n",
    "    kec_layer_sh = map_obj_sh.listLayers(\"idkec\")[0]\n",
    "    \n",
    "\n",
    "    layers_to_hide = [prov_layer_ch, prov_layer_sh]\n",
    "    layers_to_show = [kab_layer_ch, kab_layer_sh]\n",
    "\n",
    "\n",
    "    dataframe = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "\n",
    "\n",
    "    print(\"Proses Pembuatan Infografis dimulai . . .\")\n",
    "\n",
    "    prov_referensi = os.getenv(\"POLY_PROV\")\n",
    "    output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "    folder_aset = os.getenv(\"ASSET\")\n",
    "    \n",
    "    with arcpy.da.SearchCursor(prov_referensi, [\"WADMPR\", \"SHAPE@\"]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "        for r in cursors:\n",
    "            \n",
    "            wilayah_ref = r[0]\n",
    "            prov_geometry = r[1]\n",
    "            if wilayah_ref == 'Indonesia':\n",
    "                print(wilayah_ref)\n",
    "                \n",
    "                # initial_state_infog1 = self.store_initial_state(layout_infog1_ach)\n",
    "                # initial_state_infog2 = self.store_initial_state(layout_infog2_ach)\n",
    "\n",
    "                if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_infog = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                    output_tipe_periode='ANALISA_DASARIAN', tipe='INFOGRAFIS')\n",
    "\n",
    "\n",
    "                    indo_df_complete, prov_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_indo(dataframe, tipe_informasi)\n",
    "\n",
    "                    wilayah_sgt_tinggi = top_by_kategori['Sangat Tinggi']\n",
    "                    wilayah_tinggi = top_by_kategori['Tinggi']\n",
    "                    wilayah_menengah = top_by_kategori['Menengah']\n",
    "                    wilayah_rendah = top_by_kategori['Rendah']\n",
    "\n",
    "\n",
    "                    chart_infografis_ch(indo_df_complete)\n",
    "\n",
    "                    print(\"Print Infografis 1\")\n",
    "                    # Set extent sesuai geometry\n",
    "                    \n",
    "                    map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                    prov_layer_ch.visible = False\n",
    "                    kab_layer_ch.visible = False\n",
    "                    kec_layer_ch.visible = False\n",
    "\n",
    "                    # output_file = os.path.join(folder_aset, 'maps', f\"peta_infografis.png\")\n",
    "                    # output_ach = os.path.join(folder_aset, 'maps', f\"peta_infografis_ach.png\")\n",
    "                    # output_ash = os.path.join(folder_aset, 'maps', f\"peta_infografis_ash.png\")\n",
    "\n",
    "                    # layout_peta.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                    # cut_image(output_file, output_ach, output_ash)\n",
    "\n",
    "\n",
    "                    elements_infog1 = layout_infog1_ach.listElements()\n",
    "\n",
    "                    for element in elements_infog1:\n",
    "                        if element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian_txt} {month_name.upper()} {year}')\n",
    "\n",
    "                    \n",
    "                    print(\"Print Infografis 2\")\n",
    "\n",
    "                    elements_infog2 = layout_infog2_ach.listElements()\n",
    "\n",
    "                    for element in elements_infog2:\n",
    "                        if element.name == 'CHART':\n",
    "                                element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png')))\n",
    "                        elif element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian_txt} {month_name.upper()} {year}')\n",
    "                        elif element.name == \"SUBJUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian_txt} {month_name.upper()} {year}')\n",
    "                        elif element.name == 'TEXT1':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Curah Hujan</BOL>, umumnya wilayah Indonesia akan mengalami curah hujan <BOL>SANGAT TINGGI sebesar {sgt_tinggi}%</BOL>, <BOL>TINGGI sebesar {tinggi}%</BOL>, <BOL>MENENGAH sebesar {menengah}%</BOL>, dan <BOL>RENDAH sebesar {rendah}%</BOL>.''')\n",
    "                        elif element.name == 'TEXT2':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>SANGAT TINGGI</BOL> meliputi: {wilayah_sgt_tinggi}. Wilayah dominan <BOL>TINGGI</BOL> meliputi: {wilayah_tinggi}. Wilayah dominan <BOL>MENENGAH</BOL> meliputi: {wilayah_menengah}. Wilayah dominan <BOL>RENDAH</BOL> meliputi: {wilayah_rendah}.''')\n",
    "\n",
    "\n",
    "                    temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                    temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                    layout_infog1_ach.exportToPDF(temp_pdf1, resolution=300)\n",
    "                    layout_infog2_ach.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                    pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ach_das_indo_ver_{year}{month}das0{current_dasarian}.pdf'))\n",
    "                    pdf_doc.appendPages(temp_pdf1)\n",
    "                    pdf_doc.appendPages(temp_pdf2)\n",
    "                    pdf_doc.saveAndClose()\n",
    "\n",
    "                    os.remove(temp_pdf1)\n",
    "                    os.remove(temp_pdf2)\n",
    "\n",
    "                else: # tipe_informasi == 'ANALISA SIFAT HUJAN'\n",
    "                    \n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_infog = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                    output_tipe_periode='ANALISA_DASARIAN', tipe='INFOGRAFIS')\n",
    "\n",
    "\n",
    "                    indo_df_complete, prov_df_complete_clean, top_by_kategori,  atas_normal, normal, bawah_normal= dataframe_indo(dataframe, tipe_informasi)\n",
    "\n",
    "                    wilayah_atas_normal = top_by_kategori['Atas Normal']\n",
    "                    wilayah_normal = top_by_kategori['Normal']\n",
    "                    wilayah_bawah_normal = top_by_kategori['Bawah Normal']\n",
    "\n",
    "\n",
    "                    chart_infografis_sh(indo_df_complete)\n",
    "\n",
    "                    print(\"Print Infografis 1\")\n",
    "                    # Set extent sesuai geometry\n",
    "                    \n",
    "                    map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                    prov_layer_sh.visible = False\n",
    "                    kab_layer_sh.visible = False\n",
    "                    kec_layer_sh.visible = False\n",
    "\n",
    "\n",
    "\n",
    "                    elements_infog1 = layout_infog1_ash.listElements()\n",
    "\n",
    "                    for element in elements_infog1:\n",
    "                        if element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian_txt} {month_name.upper()} {year}')\n",
    "\n",
    "                    \n",
    "\n",
    "                    print(\"Print Infografis 2\")\n",
    "\n",
    "                    elements_infog2 = layout_infog2_ash.listElements()\n",
    "\n",
    "                    for element in elements_infog2:\n",
    "                        if element.name == 'CHART':\n",
    "                                element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png')))\n",
    "                        elif element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian_txt} {month_name.upper()} {year}')\n",
    "                        elif element.name == \"SUBJUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian_txt} {month_name.upper()} {year}')\n",
    "                        elif element.name == 'TEXT1':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Sifat Hujan</BOL>, umumnya wilayah Indonesia akan mengalami sifat hujan <BOL>ATAS NORMAL sebesar {atas_normal}%</BOL>, <BOL>NORMAL sebesar {normal}%</BOL>, <BOL>BAWAH NORMAL sebesar {bawah_normal}%</BOL>.''')\n",
    "                        elif element.name == 'TEXT2':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>ATAS NORMAL</BOL> meliputi: {wilayah_atas_normal}. Wilayah dominan <BOL>NORMAL</BOL> meliputi: {wilayah_normal}. Wilayah dominan <BOL>BAWAH NORMAL</BOL> meliputi: {wilayah_bawah_normal}.''')\n",
    "\n",
    "\n",
    "                    temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                    temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                    layout_infog1_ash.exportToPDF(temp_pdf1, resolution=300)\n",
    "                    layout_infog2_ash.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                    pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ash_das_indo_ver_{year}{month}das0{current_dasarian}.pdf'))\n",
    "                    pdf_doc.appendPages(temp_pdf1)\n",
    "                    pdf_doc.appendPages(temp_pdf2)\n",
    "                    pdf_doc.saveAndClose()\n",
    "\n",
    "                    os.remove(temp_pdf1)\n",
    "                    os.remove(temp_pdf2)\n",
    "\n",
    "\n",
    "            else: # wilayah_ref == UPT\n",
    "                # print(wilayah_ref)\n",
    "                wilayah_upt = nama_prov_union_shp[wilayah_ref]\n",
    "        \n",
    "                print(wilayah_ref)\n",
    "                if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "                    \n",
    "                    initial_state_infog1 = store_initial_state(layout_infog1_ach)\n",
    "                    initial_state_infog2 = store_initial_state(layout_infog2_ach)\n",
    "\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_infog = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                            output_tipe_periode='ANALISA-DASARIAN', tipe='INFOGRAFIS', \n",
    "                                                                            nama_prov=nama_prov_folder, pulau_kecil=wilayah_ref)\n",
    "                    \n",
    "\n",
    "                    prov_df_complete, kab_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_upt(dataframe, tipe_informasi, nama_prov_union_shp[wilayah_ref])\n",
    "\n",
    "                    wilayah_sgt_tinggi = top_by_kategori['Sangat Tinggi']\n",
    "                    wilayah_tinggi = top_by_kategori['Tinggi']\n",
    "                    wilayah_menengah = top_by_kategori['Menengah']\n",
    "                    wilayah_rendah = top_by_kategori['Rendah']\n",
    "\n",
    "                    chart_infografis_ch(prov_df_complete)\n",
    "\n",
    "                    print(\"Print Infografis 1\")\n",
    "                    map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                    \n",
    "\n",
    "                    # if kab_layer_ch.isFeatureLayer:\n",
    "                    #     for lbl_class in kab_layer_ch.listLabelClasses():\n",
    "                    #         lbl_class.showClassLabels = True\n",
    "                    #         lbl_class.symbol.fontSize = 10\n",
    "                    #     kab_layer_ch.showLabels = True\n",
    "\n",
    "\n",
    "\n",
    "                    for layer in layers_to_hide:\n",
    "                            if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            for layer in layers_to_show:\n",
    "                                if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            \n",
    "\n",
    "                    elements_infog1 = layout_infog1_ach.listElements()\n",
    "\n",
    "                    for element in elements_infog1:\n",
    "                        if element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "\n",
    "\n",
    "                    \n",
    "                    print(\"Print Infografis 2\")\n",
    "\n",
    "                    elements_infog2 = layout_infog2_ach.listElements()\n",
    "\n",
    "                    for element in elements_infog2:\n",
    "                        if element.name == 'CHART':\n",
    "                            element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png')))\n",
    "                        elif element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian_txt} {month_name.upper()} {year}')\n",
    "                        elif element.name == \"SUBJUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian_txt} {month_name.upper()} {year}')\n",
    "                        elif element.name == 'TEXT1':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Curah Hujan</BOL>, umumnya wilayah {nama_prov[wilayah_ref].title()} akan mengalami curah hujan <BOL>SANGAT TINGGI sebesar {sgt_tinggi}%</BOL>, <BOL>TINGGI sebesar {tinggi}%</BOL>, <BOL>MENENGAH sebesar {menengah}%</BOL>, dan <BOL>RENDAH sebesar {rendah}%</BOL>.''')\n",
    "                        elif element.name == 'TEXT2':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>SANGAT TINGGI</BOL> meliputi: {wilayah_sgt_tinggi}. Wilayah dominan <BOL>TINGGI</BOL> meliputi: {wilayah_tinggi}. Wilayah dominan <BOL>MENENGAH</BOL> meliputi: {wilayah_menengah}. Wilayah dominan <BOL>RENDAH</BOL> meliputi: {wilayah_rendah}.''')\n",
    "\n",
    "\n",
    "                    temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                    temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                    layout_infog1_ach.exportToPDF(temp_pdf1, resolution=300)\n",
    "                    layout_infog2_ach.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                    pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ach_das_{wilayah_ref.lower()}_ver_{year}{month}das0{current_dasarian}.pdf'))\n",
    "                    pdf_doc.appendPages(temp_pdf1)\n",
    "                    pdf_doc.appendPages(temp_pdf2)\n",
    "                    pdf_doc.saveAndClose()\n",
    "\n",
    "                    os.remove(temp_pdf1)\n",
    "                    os.remove(temp_pdf2)\n",
    "\n",
    "                    reset_elements(layout_infog1_ach, initial_state_infog1)\n",
    "                    reset_elements(layout_infog2_ach, initial_state_infog2)\n",
    "\n",
    "                else: # tipe_informasi == 'ANALISA_SIFAT_HUJAN'\n",
    "                    \n",
    "                    initial_state_infog1 = store_initial_state(layout_infog1_ash)\n",
    "                    initial_state_infog2 = store_initial_state(layout_infog2_ash)\n",
    "\n",
    "                    pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                    output_loc_infog = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                            output_tipe_periode='ANALISA_DASARIAN', tipe='INFOGRAFIS', \n",
    "                                                                            nama_prov=nama_prov_folder, pulau_kecil=wilayah_ref)\n",
    "                    \n",
    "\n",
    "                    prov_df_complete, kab_df_complete_clean, top_by_kategori, atas_normal, normal, bawah_normal = dataframe_upt(dataframe, tipe_informasi, nama_prov_union_shp[wilayah_ref])\n",
    "\n",
    "                    wilayah_atas_normal = top_by_kategori['Atas Normal']\n",
    "                    wilayah_normal = top_by_kategori['Normal']\n",
    "                    wilayah_bawah_normal = top_by_kategori['Bawah Normal']\n",
    "\n",
    "                    chart_infografis_sh(prov_df_complete)\n",
    "\n",
    "                    print(\"Print Infografis 1\")\n",
    "                    map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "\n",
    "                    # if kab_layer_sh.isFeatureLayer:\n",
    "                    #     for lbl_class in kab_layer_sh.listLabelClasses():\n",
    "                    #         lbl_class.showClassLabels = True\n",
    "                    #         lbl_class.symbol.fontSize = 10\n",
    "                    #     kab_layer_sh.showLabels = True\n",
    "\n",
    "\n",
    "                    for layer in layers_to_hide:\n",
    "                            if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            for layer in layers_to_show:\n",
    "                                if layer: \n",
    "                                    try:\n",
    "                                        layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                            \n",
    "\n",
    "                    elements_infog1 = layout_infog1_ash.listElements()\n",
    "\n",
    "                    for element in elements_infog1:\n",
    "                        if element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "\n",
    "\n",
    "                    \n",
    "                    print(\"Print Infografis 2\")\n",
    "\n",
    "                    elements_infog2 = layout_infog2_ash.listElements()\n",
    "\n",
    "                    for element in elements_infog2:\n",
    "                        if element.name == 'CHART':\n",
    "                            element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png'), \n",
    "                                                                                (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png')))\n",
    "                        elif element.name == \"PROVINSI\":\n",
    "                            element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                        elif element.name == \"WAKTU\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian_txt} {month_name.upper()} {year}')\n",
    "                        elif element.name == \"SUBJUDUL\":\n",
    "                            element.text = element.text.replace('[WAKTU]', f'DASARIAN {current_dasarian_txt} {month_name.upper()} {year}')\n",
    "                        elif element.name == 'TEXT1':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Sifat Hujan</BOL>, umumnya wilayah {nama_prov[wilayah_ref].title()} akan mengalami sifat hujan <BOL>ATAS NORMAL sebesar {atas_normal}%</BOL>, <BOL>NORMAL sebesar {normal}%</BOL>, <BOL>BAWAH NORMAL sebesar {bawah_normal}%</BOL>.''')\n",
    "                        elif element.name == 'TEXT2':\n",
    "                            element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>ATAS NORMAL</BOL> meliputi: {wilayah_atas_normal}. Wilayah dominan <BOL>NORMAL</BOL> meliputi: {wilayah_normal}. Wilayah dominan <BOL>BAWAH NORMAL</BOL> meliputi: {wilayah_bawah_normal}.''')\n",
    "\n",
    "\n",
    "                    temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                    temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                    layout_infog1_ash.exportToPDF(temp_pdf1, resolution=300)\n",
    "                    layout_infog2_ash.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                    pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ash_bln_{wilayah_ref.lower()}_ver_{year}{month}das0{current_dasarian}.pdf'))\n",
    "                    pdf_doc.appendPages(temp_pdf1)\n",
    "                    pdf_doc.appendPages(temp_pdf2)\n",
    "                    pdf_doc.saveAndClose()\n",
    "\n",
    "                    os.remove(temp_pdf1)\n",
    "                    os.remove(temp_pdf2)\n",
    "\n",
    "                    reset_elements(layout_infog1_ash, initial_state_infog1)\n",
    "                    reset_elements(layout_infog2_ash, initial_state_infog2)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_ach = r'F:\\ASSET\\spatial\\BMKG_PinterIklim\\proses1_data_layout.gdb\\polygon_ach'\n",
    "poly_ash = r'F:\\ASSET\\spatial\\BMKG_PinterIklim\\proses1_data_layout.gdb\\polygon_ash'\n",
    "tipe_informasi = 'ANALISA_CURAH_HUJAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infografis_das(feature = poly_ach, tipe_informasi=tipe_informasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "from config import nama_stasiun, nama_prov, nama_prov_union_shp, nama_prov_folder\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_chart import cut_image\n",
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "from utils.proses1_chart import chart_infografis_ch, chart_infografis_sh, laporan_tabel, chart_laporan_ch, chart_laporan_sh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dataframe_indo_test(dataframe, tipe_informasi):\n",
    "    data = dataframe[['Kategori', 'PROPINSI', 'Pulau_B', 'Area_H']]\n",
    "\n",
    "    # Agregasi Indonesia\n",
    "    sum_area = data['Area_H'].sum()\n",
    "    cat_df = data.groupby('Kategori')['Area_H'].sum()\n",
    "    indo_df = round(cat_df / sum_area, 4)\n",
    "    indo_df = indo_df.reset_index()\n",
    "    indo_df = indo_df.rename({'Area_H' : 'Persentase',}, axis='columns')\n",
    "    indo_df['Persentase'] = round(indo_df['Persentase']*100,2)\n",
    "    indo_df['Persentase%'] = round(indo_df['Persentase'],2).astype(str) + '%'\n",
    "    indo_df.drop(indo_df.index[0], inplace=True)\n",
    "    indo_df[\"Wilayah\"] = 'Indonesia'\n",
    "\n",
    "   \n",
    "\n",
    "    categories_ch = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "    categories_sh = ['Bawah Normal', 'Normal', 'Atas Normal']\n",
    "\n",
    "    if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "        all_combinations = pd.MultiIndex.from_product([indo_df['Wilayah'].unique(), categories_ch], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "        indo_df_complete = all_combinations.merge(indo_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "        indo_df_complete['Persentase'] = indo_df_complete['Persentase'].fillna(0)\n",
    "        indo_df_complete['Persentase%'] = indo_df_complete['Persentase%'].fillna('0%')\n",
    "        non_zero_df = indo_df_complete[indo_df_complete['Persentase'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Persentase'].sum()\n",
    "        non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "        indo_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "        if 'Persentase%' in indo_df_complete.columns:\n",
    "            indo_df_complete['Persentase%'] = indo_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "        indo_df_pivot = pd.pivot(indo_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "        indo_df_pivot = indo_df_pivot.reset_index()\n",
    "        indo_df_pivot.columns.name = None\n",
    "\n",
    "        # Proses statistik wilayah wilayah Provinsi\n",
    "        prov_area_sum = data.groupby('PROPINSI')['Area_H'].sum()\n",
    "        prov_cat_area_sum = data.groupby(['Kategori','PROPINSI'])['Area_H'].sum()\n",
    "        prov_df = round(prov_cat_area_sum / prov_area_sum, 2)\n",
    "        prov_df = prov_df.reset_index()\n",
    "        prov_df = prov_df[(prov_df['Kategori'] != \" \") & (prov_df['PROPINSI'] != \" \")]\n",
    "        prov_df['Area_H'] = round(prov_df['Area_H']*100, 2)\n",
    "        all_combinations_prov = pd.MultiIndex.from_product([prov_df['PROPINSI'].unique(), categories_ch], names=['PROPINSI', 'Kategori']).to_frame(index=False)\n",
    "        prov_df_complete = all_combinations_prov.merge(prov_df, on=['PROPINSI', 'Kategori'], how='left')\n",
    "        prov_df_complete['Area_H'] = prov_df_complete['Area_H'].fillna(0)\n",
    "        prov_df_complete_clean = pd.DataFrame()\n",
    "        for name, group in prov_df_complete.groupby('PROPINSI'):\n",
    "            non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "            total_non_zero = non_zero_df['Area_H'].sum()\n",
    "            \n",
    "            if total_non_zero > 0:\n",
    "                non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "            \n",
    "            group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "            prov_df_complete_clean = pd.concat([prov_df_complete_clean, group])\n",
    "\n",
    "        prov_df_complete_clean = prov_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "        top_13_areas = prov_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(13, 'Area_H')).reset_index(drop=True)\n",
    "        top_by_kategori = top_13_areas.groupby('Kategori')['PROPINSI'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "\n",
    "        prov_df_complete_clean = pd.pivot(prov_df_complete_clean, index='PROPINSI', columns='Kategori', values='Area_H')\n",
    "        prov_df_complete_clean = prov_df_complete_clean.reset_index()\n",
    "        prov_df_complete_clean.columns.name = None\n",
    "        prov_df_complete_clean.drop(prov_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "        # Concat Agregasi Indo to Propinsi\n",
    "        prov_df_complete_clean = prov_df_complete_clean.rename(columns={'PROPINSI': 'Wilayah'})\n",
    "        prov_df_complete_clean = pd.concat([indo_df_pivot, prov_df_complete_clean], ignore_index=True)\n",
    "\n",
    "        # Get kategori value for agregasi propinsi\n",
    "        sgt_tinggi = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "        tinggi = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "        rendah = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Rendah', 'Persentase'].values[0]\n",
    "        menengah =  indo_df_complete.loc[indo_df_complete['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah Pulau Besar\n",
    "        pulau_area_sum = data.groupby('Pulau_B')['Area_H'].sum()\n",
    "        pulau_cat_df3 = data.groupby(['Kategori','Pulau_B'])['Area_H'].sum()\n",
    "        pulau_df = round(pulau_cat_df3 / pulau_area_sum, 2)\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df = pulau_df[(pulau_df['Kategori'] != \" \") & (pulau_df['Pulau_B'] != \" \")]\n",
    "\n",
    "        pulau_df['Area_H'] = round(pulau_df['Area_H']*100, 2)\n",
    "        all_combinations_pulau = pd.MultiIndex.from_product([pulau_df['Pulau_B'].unique(), categories_ch], names=['Pulau_B', 'Kategori']).to_frame(index=False)\n",
    "        pulau_df_complete = all_combinations_pulau.merge(pulau_df, on=['Pulau_B', 'Kategori'], how='left')\n",
    "        pulau_df_complete['Area_H'] = pulau_df_complete['Area_H'].fillna(0)\n",
    "        pulau_df_complete_clean = pd.DataFrame()\n",
    "        for name, group in pulau_df_complete.groupby('Pulau_B'):\n",
    "            non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "            total_non_zero = non_zero_df['Area_H'].sum()\n",
    "            \n",
    "            if total_non_zero > 0:\n",
    "                non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "            \n",
    "            group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "            pulau_df_complete_clean = pd.concat([pulau_df_complete_clean, group])\n",
    "\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "        pulau_df_complete_clean = pd.pivot(pulau_df_complete_clean, index='Pulau_B', columns='Kategori', values='Area_H')\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.reset_index()\n",
    "        pulau_df_complete_clean.columns.name = None\n",
    "        # pulau_df_complete_clean.drop(pulau_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "        # Concat Agregasi Indo to Pulau_B\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Pulau_B': 'Wilayah'})\n",
    "        pulau_df_complete_clean = pd.concat([indo_df_pivot, pulau_df_complete_clean], ignore_index=True)\n",
    "\n",
    "\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Rendah': 'Rendah (%)', 'Menengah': 'Menengah (%)','Tinggi': 'Tinggi (%)', 'Sangat Tinggi': 'Sangat Tinggi (%)'})\n",
    "        new_order = ['Wilayah', 'Rendah (%)', 'Menengah (%)', 'Tinggi (%)', 'Sangat Tinggi (%)']\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean[new_order]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        return indo_df_complete, prov_df_complete_clean,pulau_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    else:    # tipe_informasi == 'ANALISA_SIFAT_HUJAN'\n",
    "\n",
    "        all_combinations = pd.MultiIndex.from_product([indo_df['Wilayah'].unique(), categories_sh], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "        indo_df_complete = all_combinations.merge(indo_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "        indo_df_complete['Persentase'] = indo_df_complete['Persentase'].fillna(0)\n",
    "        indo_df_complete['Persentase%'] = indo_df_complete['Persentase%'].fillna('0%')\n",
    "        non_zero_df = indo_df_complete[indo_df_complete['Persentase'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Persentase'].sum()\n",
    "        non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "        indo_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "        if 'Persentase%' in indo_df_complete.columns:\n",
    "            indo_df_complete['Persentase%'] = indo_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "        indo_df_pivot = pd.pivot(indo_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "        indo_df_pivot = indo_df_pivot.reset_index()\n",
    "        indo_df_pivot.columns.name = None\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah wilayah Provinsi\n",
    "        prov_area_sum = data.groupby('PROPINSI')['Area_H'].sum()\n",
    "        prov_cat_area_sum = data.groupby(['Kategori','PROPINSI'])['Area_H'].sum()\n",
    "        prov_df = round(prov_cat_area_sum / prov_area_sum, 2)\n",
    "        prov_df = prov_df.reset_index()\n",
    "        prov_df = prov_df[(prov_df['Kategori'] != \" \") & (prov_df['PROPINSI'] != \" \")]\n",
    "        prov_df['Area_H'] = round(prov_df['Area_H']*100, 2)\n",
    "        all_combinations_prov = pd.MultiIndex.from_product([prov_df['PROPINSI'].unique(), categories_sh], names=['PROPINSI', 'Kategori']).to_frame(index=False)\n",
    "        prov_df_complete = all_combinations_prov.merge(prov_df, on=['PROPINSI', 'Kategori'], how='left')\n",
    "        prov_df_complete['Area_H'] = prov_df_complete['Area_H'].fillna(0)\n",
    "        prov_df_complete_clean = pd.DataFrame()\n",
    "        for name, group in prov_df_complete.groupby('PROPINSI'):\n",
    "            non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "            total_non_zero = non_zero_df['Area_H'].sum()\n",
    "            \n",
    "            if total_non_zero > 0:\n",
    "                non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "            \n",
    "            group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "            prov_df_complete_clean = pd.concat([prov_df_complete_clean, group])\n",
    "\n",
    "        prov_df_complete_clean = prov_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "        top_13_areas = prov_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(13, 'Area_H')).reset_index(drop=True)\n",
    "        top_by_kategori = top_13_areas.groupby('Kategori')['PROPINSI'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "\n",
    "        prov_df_complete_clean = pd.pivot(prov_df_complete_clean, index='PROPINSI', columns='Kategori', values='Area_H')\n",
    "        prov_df_complete_clean = prov_df_complete_clean.reset_index()\n",
    "        prov_df_complete_clean.columns.name = None\n",
    "        prov_df_complete_clean.drop(prov_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "        # Concat Agregasi Indo to Propinsi\n",
    "        prov_df_complete_clean = prov_df_complete_clean.rename(columns={'PROPINSI': 'Wilayah'})\n",
    "        prov_df_complete_clean = pd.concat([indo_df_pivot, prov_df_complete_clean], ignore_index=True)\n",
    "\n",
    "        # Get kategori value for agregasi propinsi\n",
    "        atas_normal = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Atas Normal', 'Persentase'].values[0]\n",
    "        normal = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Normal', 'Persentase'].values[0]\n",
    "        bawah_normal = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Bawah Normal', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "        # Proses statistik wilayah Pulau Besar\n",
    "        pulau_area_sum = data.groupby('Pulau_B')['Area_H'].sum()\n",
    "        pulau_cat_df3 = data.groupby(['Kategori','Pulau_B'])['Area_H'].sum()\n",
    "        pulau_df = round(pulau_cat_df3 / pulau_area_sum, 2)\n",
    "        pulau_df = pulau_df.reset_index()\n",
    "        pulau_df = pulau_df[(pulau_df['Kategori'] != \" \") & (pulau_df['Pulau_B'] != \" \")]\n",
    "\n",
    "        pulau_df['Area_H'] = round(pulau_df['Area_H']*100, 2)\n",
    "        all_combinations_pulau = pd.MultiIndex.from_product([pulau_df['Pulau_B'].unique(), categories_sh], names=['Pulau_B', 'Kategori']).to_frame(index=False)\n",
    "        pulau_df_complete = all_combinations_pulau.merge(pulau_df, on=['Pulau_B', 'Kategori'], how='left')\n",
    "        pulau_df_complete['Area_H'] = pulau_df_complete['Area_H'].fillna(0)\n",
    "        pulau_df_complete_clean = pd.DataFrame()\n",
    "        for name, group in pulau_df_complete.groupby('Pulau_B'):\n",
    "            non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "            total_non_zero = non_zero_df['Area_H'].sum()\n",
    "            \n",
    "            if total_non_zero > 0:\n",
    "                non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "            \n",
    "            group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "            pulau_df_complete_clean = pd.concat([pulau_df_complete_clean, group])\n",
    "\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "        pulau_df_complete_clean = pd.pivot(pulau_df_complete_clean, index='Pulau_B', columns='Kategori', values='Area_H')\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.reset_index()\n",
    "        pulau_df_complete_clean.columns.name = None\n",
    "        # pulau_df_complete_clean.drop(pulau_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "        # Concat Agregasi Indo to Pulau_B\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Pulau_B': 'Wilayah'})\n",
    "        pulau_df_complete_clean = pd.concat([indo_df_pivot, pulau_df_complete_clean], ignore_index=True)\n",
    "\n",
    "\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Bawah Normal': 'Bawah Normal (%)', 'Normal': 'Normal (%)','Atas Normal': 'Atas Normal (%)'})\n",
    "        new_order = ['Wilayah', 'Bawah Normal (%)', 'Normal (%)', 'Atas Normal (%)']\n",
    "        pulau_df_complete_clean = pulau_df_complete_clean[new_order]\n",
    "        \n",
    "        \n",
    "        return indo_df_complete, pulau_df_complete_clean, pulau_df_complete_clean, top_by_kategori, atas_normal, normal, bawah_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_ach = r'F:\\ASSET\\spatial\\BMKG_PinterIklim\\proses1_data_layout.gdb\\polygon_ach'\n",
    "poly_ash = r'F:\\ASSET\\spatial\\BMKG_PinterIklim\\proses1_data_layout.gdb\\polygon_ash'\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame.spatial.from_featureclass(poly_ach)\n",
    "tipe_informasi = 'ANALISA_CURAH_HUJAN'\n",
    "\n",
    "\n",
    "indo_df_complete, prov_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_indo_test(dataframe, tipe_informasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame.spatial.from_featureclass(poly_ach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataframe[['Kategori', 'PROPINSI', 'Pulau_B', 'Area_H']]\n",
    "\n",
    "# Agregasi Indonesia\n",
    "sum_area = data['Area_H'].sum()\n",
    "cat_df = data.groupby('Kategori')['Area_H'].sum()\n",
    "indo_df = round(cat_df / sum_area, 4)\n",
    "indo_df = indo_df.reset_index()\n",
    "indo_df = indo_df.rename({'Area_H' : 'Persentase',}, axis='columns')\n",
    "indo_df['Persentase'] = round(indo_df['Persentase']*100,2)\n",
    "indo_df['Persentase%'] = round(indo_df['Persentase'],2).astype(str) + '%'\n",
    "indo_df.drop(indo_df.index[0], inplace=True)\n",
    "indo_df[\"Wilayah\"] = 'Indonesia'\n",
    "\n",
    "\n",
    "\n",
    "categories_ch = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "categories_sh = ['Bawah Normal', 'Normal', 'Atas Normal']\n",
    "\n",
    "if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "    all_combinations = pd.MultiIndex.from_product([indo_df['Wilayah'].unique(), categories_ch], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "    indo_df_complete = all_combinations.merge(indo_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "    indo_df_complete['Persentase'] = indo_df_complete['Persentase'].fillna(0)\n",
    "    indo_df_complete['Persentase%'] = indo_df_complete['Persentase%'].fillna('0%')\n",
    "    non_zero_df = indo_df_complete[indo_df_complete['Persentase'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Persentase'].sum()\n",
    "    non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "    indo_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "    if 'Persentase%' in indo_df_complete.columns:\n",
    "        indo_df_complete['Persentase%'] = indo_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "    indo_df_pivot = pd.pivot(indo_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "    indo_df_pivot = indo_df_pivot.reset_index()\n",
    "    indo_df_pivot.columns.name = None\n",
    "\n",
    "    # Proses statistik wilayah wilayah Provinsi\n",
    "    prov_area_sum = data.groupby('PROPINSI')['Area_H'].sum()\n",
    "    prov_cat_area_sum = data.groupby(['Kategori','PROPINSI'])['Area_H'].sum()\n",
    "    prov_df = round(prov_cat_area_sum / prov_area_sum, 2)\n",
    "    prov_df = prov_df.reset_index()\n",
    "    prov_df = prov_df[(prov_df['Kategori'] != \" \") & (prov_df['PROPINSI'] != \" \")]\n",
    "    prov_df['Area_H'] = round(prov_df['Area_H']*100, 2)\n",
    "    all_combinations_prov = pd.MultiIndex.from_product([prov_df['PROPINSI'].unique(), categories_ch], names=['PROPINSI', 'Kategori']).to_frame(index=False)\n",
    "    prov_df_complete = all_combinations_prov.merge(prov_df, on=['PROPINSI', 'Kategori'], how='left')\n",
    "    prov_df_complete['Area_H'] = prov_df_complete['Area_H'].fillna(0)\n",
    "    prov_df_complete_clean = pd.DataFrame()\n",
    "    for name, group in prov_df_complete.groupby('PROPINSI'):\n",
    "        non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Area_H'].sum()\n",
    "        \n",
    "        if total_non_zero > 0:\n",
    "            non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "        \n",
    "        group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "        prov_df_complete_clean = pd.concat([prov_df_complete_clean, group])\n",
    "\n",
    "    prov_df_complete_clean = prov_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "    top_13_areas = prov_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(13, 'Area_H')).reset_index(drop=True)\n",
    "    top_by_kategori = top_13_areas.groupby('Kategori')['PROPINSI'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "\n",
    "    prov_df_complete_clean = pd.pivot(prov_df_complete_clean, index='PROPINSI', columns='Kategori', values='Area_H')\n",
    "    prov_df_complete_clean = prov_df_complete_clean.reset_index()\n",
    "    prov_df_complete_clean.columns.name = None\n",
    "    prov_df_complete_clean.drop(prov_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "    # Concat Agregasi Indo to Propinsi\n",
    "    prov_df_complete_clean = prov_df_complete_clean.rename(columns={'PROPINSI': 'Wilayah'})\n",
    "    prov_df_complete_clean = pd.concat([indo_df_pivot, prov_df_complete_clean], ignore_index=True)\n",
    "\n",
    "    # Get kategori value for agregasi propinsi\n",
    "    sgt_tinggi = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "    tinggi = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "    rendah = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Rendah', 'Persentase'].values[0]\n",
    "    menengah =  indo_df_complete.loc[indo_df_complete['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "    # Proses statistik wilayah Pulau Besar\n",
    "    pulau_area_sum = data.groupby('Pulau_B')['Area_H'].sum()\n",
    "    pulau_cat_df3 = data.groupby(['Kategori','Pulau_B'])['Area_H'].sum()\n",
    "    pulau_df = round(pulau_cat_df3 / pulau_area_sum, 2)\n",
    "    pulau_df = pulau_df.reset_index()\n",
    "    pulau_df = pulau_df[(pulau_df['Kategori'] != \" \") & (pulau_df['Pulau_B'] != \" \")]\n",
    "\n",
    "    pulau_df['Area_H'] = round(pulau_df['Area_H']*100, 2)\n",
    "    all_combinations_pulau = pd.MultiIndex.from_product([pulau_df['Pulau_B'].unique(), categories_ch], names=['Pulau_B', 'Kategori']).to_frame(index=False)\n",
    "    pulau_df_complete = all_combinations_pulau.merge(pulau_df, on=['Pulau_B', 'Kategori'], how='left')\n",
    "    pulau_df_complete['Area_H'] = pulau_df_complete['Area_H'].fillna(0)\n",
    "    pulau_df_complete_clean = pd.DataFrame()\n",
    "    for name, group in pulau_df_complete.groupby('Pulau_B'):\n",
    "        non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Area_H'].sum()\n",
    "        \n",
    "        if total_non_zero > 0:\n",
    "            non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "        \n",
    "        group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "        pulau_df_complete_clean = pd.concat([pulau_df_complete_clean, group])\n",
    "\n",
    "    pulau_df_complete_clean = pulau_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "    pulau_df_complete_clean = pd.pivot(pulau_df_complete_clean, index='Pulau_B', columns='Kategori', values='Area_H')\n",
    "    pulau_df_complete_clean = pulau_df_complete_clean.reset_index()\n",
    "    pulau_df_complete_clean.columns.name = None\n",
    "    # pulau_df_complete_clean.drop(pulau_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "    # Concat Agregasi Indo to Pulau_B\n",
    "    pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Pulau_B': 'Wilayah'})\n",
    "    pulau_df_complete_clean = pd.concat([indo_df_pivot, pulau_df_complete_clean], ignore_index=True)\n",
    "\n",
    "\n",
    "    pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Rendah': 'Rendah (%)', 'Menengah': 'Menengah (%)','Tinggi': 'Tinggi (%)', 'Sangat Tinggi': 'Sangat Tinggi (%)'})\n",
    "    new_order = ['Wilayah', 'Rendah (%)', 'Menengah (%)', 'Tinggi (%)', 'Sangat Tinggi (%)']\n",
    "    pulau_df_complete_clean = pulau_df_complete_clean[new_order]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "else:    # tipe_informasi == 'ANALISA_SIFAT_HUJAN'\n",
    "\n",
    "    all_combinations = pd.MultiIndex.from_product([indo_df['Wilayah'].unique(), categories_sh], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "    indo_df_complete = all_combinations.merge(indo_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "    indo_df_complete['Persentase'] = indo_df_complete['Persentase'].fillna(0)\n",
    "    indo_df_complete['Persentase%'] = indo_df_complete['Persentase%'].fillna('0%')\n",
    "    non_zero_df = indo_df_complete[indo_df_complete['Persentase'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Persentase'].sum()\n",
    "    non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "    indo_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "    if 'Persentase%' in indo_df_complete.columns:\n",
    "        indo_df_complete['Persentase%'] = indo_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "    indo_df_pivot = pd.pivot(indo_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "    indo_df_pivot = indo_df_pivot.reset_index()\n",
    "    indo_df_pivot.columns.name = None\n",
    "\n",
    "\n",
    "    # Proses statistik wilayah wilayah Provinsi\n",
    "    prov_area_sum = data.groupby('PROPINSI')['Area_H'].sum()\n",
    "    prov_cat_area_sum = data.groupby(['Kategori','PROPINSI'])['Area_H'].sum()\n",
    "    prov_df = round(prov_cat_area_sum / prov_area_sum, 2)\n",
    "    prov_df = prov_df.reset_index()\n",
    "    prov_df = prov_df[(prov_df['Kategori'] != \" \") & (prov_df['PROPINSI'] != \" \")]\n",
    "    prov_df['Area_H'] = round(prov_df['Area_H']*100, 2)\n",
    "    all_combinations_prov = pd.MultiIndex.from_product([prov_df['PROPINSI'].unique(), categories_sh], names=['PROPINSI', 'Kategori']).to_frame(index=False)\n",
    "    prov_df_complete = all_combinations_prov.merge(prov_df, on=['PROPINSI', 'Kategori'], how='left')\n",
    "    prov_df_complete['Area_H'] = prov_df_complete['Area_H'].fillna(0)\n",
    "    prov_df_complete_clean = pd.DataFrame()\n",
    "    for name, group in prov_df_complete.groupby('PROPINSI'):\n",
    "        non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Area_H'].sum()\n",
    "        \n",
    "        if total_non_zero > 0:\n",
    "            non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "        \n",
    "        group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "        prov_df_complete_clean = pd.concat([prov_df_complete_clean, group])\n",
    "\n",
    "    prov_df_complete_clean = prov_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "    top_13_areas = prov_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(13, 'Area_H')).reset_index(drop=True)\n",
    "    top_by_kategori = top_13_areas.groupby('Kategori')['PROPINSI'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "\n",
    "    prov_df_complete_clean = pd.pivot(prov_df_complete_clean, index='PROPINSI', columns='Kategori', values='Area_H')\n",
    "    prov_df_complete_clean = prov_df_complete_clean.reset_index()\n",
    "    prov_df_complete_clean.columns.name = None\n",
    "    prov_df_complete_clean.drop(prov_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "    # Concat Agregasi Indo to Propinsi\n",
    "    prov_df_complete_clean = prov_df_complete_clean.rename(columns={'PROPINSI': 'Wilayah'})\n",
    "    prov_df_complete_clean = pd.concat([indo_df_pivot, prov_df_complete_clean], ignore_index=True)\n",
    "\n",
    "    # Get kategori value for agregasi propinsi\n",
    "    atas_normal = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Atas Normal', 'Persentase'].values[0]\n",
    "    normal = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Normal', 'Persentase'].values[0]\n",
    "    bawah_normal = indo_df_complete.loc[indo_df_complete['Kategori'] == 'Bawah Normal', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "    # Proses statistik wilayah Pulau Besar\n",
    "    pulau_area_sum = data.groupby('Pulau_B')['Area_H'].sum()\n",
    "    pulau_cat_df3 = data.groupby(['Kategori','Pulau_B'])['Area_H'].sum()\n",
    "    pulau_df = round(pulau_cat_df3 / pulau_area_sum, 2)\n",
    "    pulau_df = pulau_df.reset_index()\n",
    "    pulau_df = pulau_df[(pulau_df['Kategori'] != \" \") & (pulau_df['Pulau_B'] != \" \")]\n",
    "\n",
    "    pulau_df['Area_H'] = round(pulau_df['Area_H']*100, 2)\n",
    "    all_combinations_pulau = pd.MultiIndex.from_product([pulau_df['Pulau_B'].unique(), categories_sh], names=['Pulau_B', 'Kategori']).to_frame(index=False)\n",
    "    pulau_df_complete = all_combinations_pulau.merge(pulau_df, on=['Pulau_B', 'Kategori'], how='left')\n",
    "    pulau_df_complete['Area_H'] = pulau_df_complete['Area_H'].fillna(0)\n",
    "    pulau_df_complete_clean = pd.DataFrame()\n",
    "    for name, group in pulau_df_complete.groupby('Pulau_B'):\n",
    "        non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Area_H'].sum()\n",
    "        \n",
    "        if total_non_zero > 0:\n",
    "            non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "        \n",
    "        group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "        pulau_df_complete_clean = pd.concat([pulau_df_complete_clean, group])\n",
    "\n",
    "    pulau_df_complete_clean = pulau_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "    pulau_df_complete_clean = pd.pivot(pulau_df_complete_clean, index='Pulau_B', columns='Kategori', values='Area_H')\n",
    "    pulau_df_complete_clean = pulau_df_complete_clean.reset_index()\n",
    "    pulau_df_complete_clean.columns.name = None\n",
    "    # pulau_df_complete_clean.drop(pulau_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "    # Concat Agregasi Indo to Pulau_B\n",
    "    pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Pulau_B': 'Wilayah'})\n",
    "    pulau_df_complete_clean = pd.concat([indo_df_pivot, pulau_df_complete_clean], ignore_index=True)\n",
    "\n",
    "\n",
    "    pulau_df_complete_clean = pulau_df_complete_clean.rename(columns={'Bawah Normal': 'Bawah Normal (%)', 'Normal': 'Normal (%)','Atas Normal': 'Atas Normal (%)'})\n",
    "    new_order = ['Wilayah', 'Bawah Normal (%)', 'Normal (%)', 'Atas Normal (%)']\n",
    "    pulau_df_complete_clean = pulau_df_complete_clean[new_order]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indo_df_complete, prov_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_initial_state( original_layout):\n",
    "        initial_state = {}\n",
    "        elements = original_layout.listElements()\n",
    "        for element in elements:\n",
    "            if hasattr(element, 'text'):\n",
    "                initial_state[element.name] = element.text\n",
    "        return initial_state\n",
    "\n",
    "    # Function to reset elements to their initial state\n",
    "def reset_elements( modified_layout, initial_state):\n",
    "    elements = modified_layout.listElements()\n",
    "    for element in elements:\n",
    "        if element.name in initial_state:\n",
    "            try:\n",
    "                element.text = initial_state[element.name]\n",
    "            except Exception as e:\n",
    "                print(f\"Error resetting element '{element.name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import nama_stasiun, nama_prov, nama_prov_union_shp, nama_prov_folder\n",
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "from config import nama_stasiun, nama_prov, nama_prov_union_shp, nama_prov_folder\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_chart import cut_image\n",
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "from utils.proses1_chart import chart_infografis_ch, chart_infografis_sh, laporan_tabel, chart_laporan_ch, chart_laporan_sh\n",
    "\n",
    "\n",
    "# Set waktu\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tipe_informasi = 'ANALISA_CURAH_HUJAN'\n",
    "\n",
    "aprx = arcpy.mp.ArcGISProject(map_project)\n",
    "\n",
    "layout_infog1_ach = aprx.listLayouts(\"Infografis_ach_pusat_1\")[0]\n",
    "layout_infog2_ach = aprx.listLayouts(\"Infografis_ach_pusat_2\")[0]\n",
    "layout_infog1_ash = aprx.listLayouts(\"Infografis_ash_pusat_1\")[0]\n",
    "layout_infog2_ash = aprx.listLayouts(\"Infografis_ash_pusat_2\")[0]\n",
    "\n",
    "map_frame_ch = layout_infog1_ach.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame CH')[0]\n",
    "map_obj_ch = map_frame_ch.map\n",
    "prov_layer_ch = map_obj_ch.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_ch = map_obj_ch.listLayers(\"admin_kab\")[0]\n",
    "kec_layer_ch = map_obj_ch.listLayers(\"idkec\")[0]\n",
    "\n",
    "map_frame_sh = layout_infog1_ash.listElements(\"MAPFRAME_ELEMENT\", 'Map Frame SH')[0]\n",
    "map_obj_sh = map_frame_sh.map\n",
    "prov_layer_sh = map_obj_sh.listLayers(\"admin_prov\")[0]\n",
    "kab_layer_sh = map_obj_sh.listLayers(\"admin_kab\")[0]\n",
    "kec_layer_sh = map_obj_sh.listLayers(\"idkec\")[0]\n",
    "\n",
    "\n",
    "layers_to_hide = [prov_layer_ch, prov_layer_sh]\n",
    "layers_to_show = [kab_layer_ch, kab_layer_sh]\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame.spatial.from_featureclass(poly_indo_ach)\n",
    "\n",
    "\n",
    "print(\"Proses Pembuatan Infografis dimulai . . .\")\n",
    "\n",
    "prov_referensi = os.getenv(\"POLY_PROV\")\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "folder_aset = os.getenv(\"ASSET\")\n",
    "\n",
    "with arcpy.da.SearchCursor(prov_referensi, [\"WADMPR\", \"SHAPE@\"]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "        \n",
    "        wilayah_ref = r[0]\n",
    "        prov_geometry = r[1]\n",
    "        if wilayah_ref == 'Indonesia':\n",
    "            print(wilayah_ref)\n",
    "            \n",
    "            # initial_state_infog1 = self.store_initial_state(layout_infog1_ach)\n",
    "            # initial_state_infog2 = self.store_initial_state(layout_infog2_ach)\n",
    "\n",
    "            if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_infog = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                output_tipe_periode='ANALISA_BULANAN', tipe='INFOGRAFIS')\n",
    "\n",
    "\n",
    "                indo_df_complete, prov_df_complete_clean, pulau_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_indo(dataframe, tipe_informasi)\n",
    "\n",
    "                wilayah_sgt_tinggi = top_by_kategori['Sangat Tinggi']\n",
    "                wilayah_tinggi = top_by_kategori['Tinggi']\n",
    "                wilayah_menengah = top_by_kategori['Menengah']\n",
    "                wilayah_rendah = top_by_kategori['Rendah']\n",
    "\n",
    "\n",
    "                chart_infografis_ch(indo_df_complete)\n",
    "\n",
    "                print(\"Print Infografis 1\")\n",
    "                # Set extent sesuai geometry\n",
    "                \n",
    "                map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                prov_layer_ch.visible = False\n",
    "                kab_layer_ch.visible = False\n",
    "                kec_layer_ch.visible = False\n",
    "\n",
    "                # output_file = os.path.join(folder_aset, 'maps', f\"peta_infografis.png\")\n",
    "                # output_ach = os.path.join(folder_aset, 'maps', f\"peta_infografis_ach.png\")\n",
    "                # output_ash = os.path.join(folder_aset, 'maps', f\"peta_infografis_ash.png\")\n",
    "\n",
    "                # layout_peta.exportToPNG(output_file, resolution=300, clip_to_elements=True)\n",
    "                # cut_image(output_file, output_ach, output_ash)\n",
    "\n",
    "\n",
    "                elements_infog1 = layout_infog1_ach.listElements()\n",
    "\n",
    "                for element in elements_infog1:\n",
    "                    if element.name == \"PROVINSI\":\n",
    "                        element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                    elif element.name == \"WAKTU\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "\n",
    "                \n",
    "                print(\"Print Infografis 2\")\n",
    "\n",
    "                elements_infog2 = layout_infog2_ach.listElements()\n",
    "\n",
    "                for element in elements_infog2:\n",
    "                    if element.name == 'CHART':\n",
    "                            element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png'), \n",
    "                                                                            (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png')))\n",
    "                    elif element.name == \"PROVINSI\":\n",
    "                        element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                    elif element.name == \"WAKTU\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                    elif element.name == \"SUBJUDUL\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                    elif element.name == 'TEXT1':\n",
    "                        element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Curah Hujan</BOL>, umumnya wilayah Indonesia akan mengalami curah hujan <BOL>SANGAT TINGGI sebesar {sgt_tinggi}%</BOL>, <BOL>TINGGI sebesar {tinggi}%</BOL>, <BOL>MENENGAH sebesar {menengah}%</BOL>, dan <BOL>RENDAH sebesar {rendah}%</BOL>.''')\n",
    "                    elif element.name == 'TEXT2':\n",
    "                        element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>SANGAT TINGGI</BOL> meliputi: {wilayah_sgt_tinggi}. Wilayah dominan <BOL>TINGGI</BOL> meliputi: {wilayah_tinggi}. Wilayah dominan <BOL>MENENGAH</BOL> meliputi: {wilayah_menengah}. Wilayah dominan <BOL>RENDAH</BOL> meliputi: {wilayah_rendah}.''')\n",
    "\n",
    "\n",
    "                temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                layout_infog1_ach.exportToPDF(temp_pdf1, resolution=300)\n",
    "                layout_infog2_ach.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ach_bln_indo_ver_{year}{month}.pdf'))\n",
    "                pdf_doc.appendPages(temp_pdf1)\n",
    "                pdf_doc.appendPages(temp_pdf2)\n",
    "                pdf_doc.saveAndClose()\n",
    "\n",
    "                os.remove(temp_pdf1)\n",
    "                os.remove(temp_pdf2)\n",
    "\n",
    "            else: # tipe_informasi == 'ANALISA SIFAT HUJAN'\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_infog = pembuatan_archive.archive_indo(output_level_indo='INDONESIA', \n",
    "                                                                output_tipe_periode='ANALISA_BULANAN', tipe='INFOGRAFIS')\n",
    "\n",
    "\n",
    "                indo_df_complete, prov_df_complete_clean, pulau_df_complete_clean, top_by_kategori,  atas_normal, normal, bawah_normal= dataframe_indo(dataframe, tipe_informasi)\n",
    "\n",
    "                wilayah_atas_normal = top_by_kategori['Atas Normal']\n",
    "                wilayah_normal = top_by_kategori['Normal']\n",
    "                wilayah_bawah_normal = top_by_kategori['Bawah Normal']\n",
    "\n",
    "\n",
    "                chart_infografis_sh(indo_df_complete)\n",
    "\n",
    "                print(\"Print Infografis 1\")\n",
    "                # Set extent sesuai geometry\n",
    "                \n",
    "                map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                prov_layer_sh.visible = False\n",
    "                kab_layer_sh.visible = False\n",
    "                kec_layer_sh.visible = False\n",
    "\n",
    "\n",
    "\n",
    "                elements_infog1 = layout_infog1_ash.listElements()\n",
    "\n",
    "                for element in elements_infog1:\n",
    "                    if element.name == \"PROVINSI\":\n",
    "                        element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                    elif element.name == \"WAKTU\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "\n",
    "                \n",
    "\n",
    "                print(\"Print Infografis 2\")\n",
    "\n",
    "                elements_infog2 = layout_infog2_ash.listElements()\n",
    "\n",
    "                for element in elements_infog2:\n",
    "                    if element.name == 'CHART':\n",
    "                            element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png'), \n",
    "                                                                            (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png')))\n",
    "                    elif element.name == \"PROVINSI\":\n",
    "                        element.text = element.text.replace('[PROVINSI]', 'INDONESIA')\n",
    "                    elif element.name == \"WAKTU\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                    elif element.name == \"SUBJUDUL\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                    elif element.name == 'TEXT1':\n",
    "                        element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Sifat Hujan</BOL>, umumnya wilayah Indonesia akan mengalami sifat hujan <BOL>ATAS NORMAL sebesar {atas_normal}%</BOL>, <BOL>NORMAL sebesar {normal}%</BOL>, <BOL>BAWAH NORMAL sebesar {bawah_normal}%</BOL>.''')\n",
    "                    elif element.name == 'TEXT2':\n",
    "                        element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>ATAS NORMAL</BOL> meliputi: {wilayah_atas_normal}. Wilayah dominan <BOL>NORMAL</BOL> meliputi: {wilayah_normal}. Wilayah dominan <BOL>BAWAH NORMAL</BOL> meliputi: {wilayah_bawah_normal}.''')\n",
    "\n",
    "\n",
    "                temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                layout_infog1_ash.exportToPDF(temp_pdf1, resolution=300)\n",
    "                layout_infog2_ash.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ash_bln_indo_ver_{year}{month}.pdf'))\n",
    "                pdf_doc.appendPages(temp_pdf1)\n",
    "                pdf_doc.appendPages(temp_pdf2)\n",
    "                pdf_doc.saveAndClose()\n",
    "\n",
    "                os.remove(temp_pdf1)\n",
    "                os.remove(temp_pdf2)\n",
    "\n",
    "\n",
    "        else: # wilayah_ref == UPT\n",
    "            print(wilayah_ref)\n",
    "            wilayah_upt = nama_prov_union_shp[wilayah_ref]\n",
    "    \n",
    "            print(wilayah_ref)\n",
    "            if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "                \n",
    "                initial_state_infog1 = store_initial_state(layout_infog1_ach)\n",
    "                initial_state_infog2 = store_initial_state(layout_infog2_ach)\n",
    "\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_infog = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                        output_tipe_periode='ANALISA_BULANAN', tipe='INFOGRAFIS', \n",
    "                                                                        nama_prov=nama_prov_folder, pulau_kecil=wilayah_ref)\n",
    "                \n",
    "\n",
    "                prov_df_complete, kab_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_upt(dataframe, tipe_informasi, nama_prov_union_shp[wilayah_ref])\n",
    "\n",
    "                wilayah_sgt_tinggi = top_by_kategori['Sangat Tinggi']\n",
    "                wilayah_tinggi = top_by_kategori['Tinggi']\n",
    "                wilayah_menengah = top_by_kategori['Menengah']\n",
    "                wilayah_rendah = top_by_kategori['Rendah']\n",
    "\n",
    "                chart_infografis_ch(prov_df_complete)\n",
    "\n",
    "                print(\"Print Infografis 1\")\n",
    "                map_frame_ch.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "                \n",
    "\n",
    "                # if kab_layer_ch.isFeatureLayer:\n",
    "                #     for lbl_class in kab_layer_ch.listLabelClasses():\n",
    "                #         lbl_class.showClassLabels = True\n",
    "                #         lbl_class.symbol.fontSize = 10\n",
    "                #     kab_layer_ch.showLabels = True\n",
    "\n",
    "\n",
    "\n",
    "                for layer in layers_to_hide:\n",
    "                        if layer: \n",
    "                                try:\n",
    "                                    layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                        for layer in layers_to_show:\n",
    "                            if layer: \n",
    "                                try:\n",
    "                                    layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                        \n",
    "\n",
    "                elements_infog1 = layout_infog1_ach.listElements()\n",
    "\n",
    "                for element in elements_infog1:\n",
    "                    if element.name == \"PROVINSI\":\n",
    "                        element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                    elif element.name == \"WAKTU\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "\n",
    "\n",
    "                \n",
    "                print(\"Print Infografis 2\")\n",
    "\n",
    "                elements_infog2 = layout_infog2_ach.listElements()\n",
    "\n",
    "                for element in elements_infog2:\n",
    "                    if element.name == 'CHART':\n",
    "                        element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png'), \n",
    "                                                                            (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_ch.png')))\n",
    "                    elif element.name == \"PROVINSI\":\n",
    "                        element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                    elif element.name == \"WAKTU\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                    elif element.name == \"SUBJUDUL\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                    elif element.name == 'TEXT1':\n",
    "                        element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Curah Hujan</BOL>, umumnya wilayah {nama_prov[wilayah_ref].title()} akan mengalami curah hujan <BOL>SANGAT TINGGI sebesar {sgt_tinggi}%</BOL>, <BOL>TINGGI sebesar {tinggi}%</BOL>, <BOL>MENENGAH sebesar {menengah}%</BOL>, dan <BOL>RENDAH sebesar {rendah}%</BOL>.''')\n",
    "                    elif element.name == 'TEXT2':\n",
    "                        element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>SANGAT TINGGI</BOL> meliputi: {wilayah_sgt_tinggi}. Wilayah dominan <BOL>TINGGI</BOL> meliputi: {wilayah_tinggi}. Wilayah dominan <BOL>MENENGAH</BOL> meliputi: {wilayah_menengah}. Wilayah dominan <BOL>RENDAH</BOL> meliputi: {wilayah_rendah}.''')\n",
    "\n",
    "\n",
    "                temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                layout_infog1_ach.exportToPDF(temp_pdf1, resolution=300)\n",
    "                layout_infog2_ach.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ach_bln_{wilayah_ref.lower()}_ver_{year}{month}.pdf'))\n",
    "                pdf_doc.appendPages(temp_pdf1)\n",
    "                pdf_doc.appendPages(temp_pdf2)\n",
    "                pdf_doc.saveAndClose()\n",
    "\n",
    "                os.remove(temp_pdf1)\n",
    "                os.remove(temp_pdf2)\n",
    "\n",
    "                reset_elements(layout_infog1_ach, initial_state_infog1)\n",
    "                reset_elements(layout_infog2_ach, initial_state_infog2)\n",
    "\n",
    "            else: # tipe_informasi == 'ANALISA SIFAT HUJAN'\n",
    "                \n",
    "                initial_state_infog1 = store_initial_state(layout_infog1_ash)\n",
    "                initial_state_infog2 = store_initial_state(layout_infog2_ash)\n",
    "\n",
    "                pembuatan_archive = ArchivingFolder(output_folder)\n",
    "                output_loc_infog = pembuatan_archive.archive_prov(output_level_prov='PROVINSI', \n",
    "                                                                        output_tipe_periode='ANALISA_BULANAN', tipe='INFOGRAFIS', \n",
    "                                                                        nama_prov=nama_prov_folder, pulau_kecil=wilayah_ref)\n",
    "                \n",
    "\n",
    "                prov_df_complete, kab_df_complete_clean, top_by_kategori, atas_normal, normal, bawah_normal = dataframe_upt(dataframe, tipe_informasi, nama_prov_union_shp[wilayah_ref])\n",
    "\n",
    "                wilayah_atas_normal = top_by_kategori['Atas Normal']\n",
    "                wilayah_normal = top_by_kategori['Normal']\n",
    "                wilayah_bawah_normal = top_by_kategori['Bawah Normal']\n",
    "\n",
    "                chart_infografis_sh(prov_df_complete)\n",
    "\n",
    "                print(\"Print Infografis 1\")\n",
    "                map_frame_sh.camera.setExtent(prov_geometry.extent)\n",
    "\n",
    "\n",
    "                # if kab_layer_sh.isFeatureLayer:\n",
    "                #     for lbl_class in kab_layer_sh.listLabelClasses():\n",
    "                #         lbl_class.showClassLabels = True\n",
    "                #         lbl_class.symbol.fontSize = 10\n",
    "                #     kab_layer_sh.showLabels = True\n",
    "\n",
    "\n",
    "                for layer in layers_to_hide:\n",
    "                        if layer: \n",
    "                                try:\n",
    "                                    layer.definitionQuery = f\"WADMPR <> '{wilayah_ref}'\"\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                        for layer in layers_to_show:\n",
    "                            if layer: \n",
    "                                try:\n",
    "                                    layer.definitionQuery = f\"WADMPR = '{wilayah_ref}'\"\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Error setting definition query for {layer.name}: {e}\")\n",
    "                        \n",
    "\n",
    "                elements_infog1 = layout_infog1_ash.listElements()\n",
    "\n",
    "                for element in elements_infog1:\n",
    "                    if element.name == \"PROVINSI\":\n",
    "                        element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                    elif element.name == \"WAKTU\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "\n",
    "\n",
    "                \n",
    "                print(\"Print Infografis 2\")\n",
    "\n",
    "                elements_infog2 = layout_infog2_ash.listElements()\n",
    "\n",
    "                for element in elements_infog2:\n",
    "                    if element.name == 'CHART':\n",
    "                        element.sourceImage = element.sourceImage.replace(os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png'), \n",
    "                                                                            (os.path.join(folder_aset,'chart', 'infografis', 'chart_infografis_sh.png')))\n",
    "                    elif element.name == \"PROVINSI\":\n",
    "                        element.text = element.text.replace('[PROVINSI]', f'{nama_prov[wilayah_ref]}')\n",
    "                    elif element.name == \"WAKTU\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                    elif element.name == \"SUBJUDUL\":\n",
    "                        element.text = element.text.replace('[WAKTU]', f'{month_name.upper()} {year}')\n",
    "                    elif element.name == 'TEXT1':\n",
    "                        element.text = element.text.replace('[TEXT]', f'''Berdasarkan analisis <BOL>Sifat Hujan</BOL>, umumnya wilayah {nama_prov[wilayah_ref].title()} akan mengalami sifat hujan <BOL>ATAS NORMAL sebesar {atas_normal}%</BOL>, <BOL>NORMAL sebesar {normal}%</BOL>, <BOL>BAWAH NORMAL sebesar {bawah_normal}%</BOL>.''')\n",
    "                    elif element.name == 'TEXT2':\n",
    "                        element.text = element.text.replace('[TEXT]', f'''Wilayah dominan <BOL>ATAS NORMAL</BOL> meliputi: {wilayah_atas_normal}. Wilayah dominan <BOL>NORMAL</BOL> meliputi: {wilayah_normal}. Wilayah dominan <BOL>BAWAH NORMAL</BOL> meliputi: {wilayah_bawah_normal}.''')\n",
    "\n",
    "\n",
    "                temp_pdf1 = os.path.join(output_loc_infog, 'infog1.pdf')\n",
    "                temp_pdf2 = os.path.join(output_loc_infog, 'infog2.pdf')\n",
    "                layout_infog1_ash.exportToPDF(temp_pdf1, resolution=300)\n",
    "                layout_infog2_ash.exportToPDF(temp_pdf2, resolution=300)\n",
    "\n",
    "                pdf_doc = arcpy.mp.PDFDocumentCreate(os.path.join(output_loc_infog, f'ig_ash_bln_{wilayah_ref.lower()}_ver_{year}{month}.pdf'))\n",
    "                pdf_doc.appendPages(temp_pdf1)\n",
    "                pdf_doc.appendPages(temp_pdf2)\n",
    "                pdf_doc.saveAndClose()\n",
    "\n",
    "                os.remove(temp_pdf1)\n",
    "                os.remove(temp_pdf2)\n",
    "\n",
    "                reset_elements(layout_infog1_ash, initial_state_infog1)\n",
    "                reset_elements(layout_infog2_ash, initial_state_infog2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import nama_stasiun, nama_prov, nama_prov_union_shp, nama_prov_folder\n",
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "from config import nama_stasiun, nama_prov, nama_prov_union_shp, nama_prov_folder\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_chart import cut_image\n",
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "from utils.proses1_chart import chart_infografis_ch, chart_infografis_sh, laporan_tabel, chart_laporan_ch, chart_laporan_sh\n",
    "\n",
    "\n",
    "# Set waktu\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "poly_ach = r'F:\\ASSET\\spatial\\BMKG_PinterIklim\\proses1_data_layout.gdb\\polygon_ach'\n",
    "poly_ash = r'F:\\ASSET\\spatial\\BMKG_PinterIklim\\proses1_data_layout.gdb\\polygon_ash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame.spatial.from_featureclass(poly_ach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_upt(dataframe, tipe_informasi, wilayah_upt):\n",
    "    data = dataframe[['Kategori', 'PROPINSI', 'KABUPATEN', 'Area_H']]\n",
    "\n",
    "    data = data[data['PROPINSI'] == wilayah_upt]\n",
    "\n",
    "    # Agregasi Propinsi\n",
    "    sum_area = data['Area_H'].sum()\n",
    "    cat_df = data.groupby('Kategori')['Area_H'].sum()\n",
    "    prov_df = round(cat_df / sum_area, 4)\n",
    "    prov_df = prov_df.reset_index()\n",
    "    prov_df = prov_df.rename({'Area_H' : 'Persentase',}, axis='columns')\n",
    "    prov_df['Persentase'] = round(prov_df['Persentase']*100,2)\n",
    "    prov_df['Persentase%'] = round(prov_df['Persentase'],2).astype(str) + '%'\n",
    "    prov_df.drop(prov_df.index[0], inplace=True)\n",
    "    prov_df[\"Wilayah\"] = f'PROVINSI {wilayah_upt}'\n",
    "\n",
    "    categories_ch = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "    categories_sh = ['Bawah Normal', 'Normal', 'Atas Normal']\n",
    "\n",
    "    if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "        all_combinations = pd.MultiIndex.from_product([prov_df['Wilayah'].unique(), categories_ch], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "        prov_df_complete = all_combinations.merge(prov_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "        prov_df_complete['Persentase'] = prov_df_complete['Persentase'].fillna(0)\n",
    "        prov_df_complete['Persentase%'] = prov_df_complete['Persentase%'].fillna('0%')\n",
    "        non_zero_df = prov_df_complete[prov_df_complete['Persentase'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Persentase'].sum()\n",
    "        non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "        prov_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "        if 'Persentase%' in prov_df_complete.columns:\n",
    "            prov_df_complete['Persentase%'] = prov_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "        prov_df_pivot = pd.pivot(prov_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "        prov_df_pivot = prov_df_pivot.reset_index()\n",
    "        prov_df_pivot.columns.name = None\n",
    "\n",
    "        # Agregasi Kabupaten\n",
    "        kab_area_sum = data.groupby('KABUPATEN')['Area_H'].sum()\n",
    "        kab_cat_area_sum = data.groupby(['Kategori','KABUPATEN'])['Area_H'].sum()\n",
    "        kab_df = round(kab_cat_area_sum / kab_area_sum, 4)\n",
    "        kab_df = kab_df.reset_index()\n",
    "        kab_df = kab_df[(kab_df['Kategori'] != \" \") & (kab_df['KABUPATEN'] != \" \")]\n",
    "        kab_df['Area_H'] = round(kab_df['Area_H']*100, 2)\n",
    "        all_combinations_kab = pd.MultiIndex.from_product([kab_df['KABUPATEN'].unique(), categories_ch], names=['KABUPATEN', 'Kategori']).to_frame(index=False)\n",
    "        kab_df_complete = all_combinations_kab.merge(kab_df, on=['KABUPATEN', 'Kategori'], how='left')\n",
    "        kab_df_complete['Area_H'] = kab_df_complete['Area_H'].fillna(0)\n",
    "        kab_df_complete_clean = pd.DataFrame()\n",
    "        for name, group in kab_df_complete.groupby('KABUPATEN'):\n",
    "            non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "            total_non_zero = non_zero_df['Area_H'].sum()\n",
    "            \n",
    "            if total_non_zero > 0:\n",
    "                non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "            \n",
    "            group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "            kab_df_complete_clean = pd.concat([kab_df_complete_clean, group])\n",
    "\n",
    "        kab_df_complete_clean = kab_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        top_5_areas = kab_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(5, 'Area_H')).reset_index(drop=True)\n",
    "        top_by_kategori = top_5_areas.groupby('Kategori')['KABUPATEN'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "        kab_df_complete_clean = pd.pivot(kab_df_complete_clean, index='KABUPATEN', columns='Kategori', values='Area_H')\n",
    "        kab_df_complete_clean = kab_df_complete_clean.reset_index()\n",
    "        kab_df_complete_clean.columns.name = None\n",
    "        kab_df_complete_clean.drop(kab_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "\n",
    "        # # Concat Propinsi to kabupaten\n",
    "        kab_df_complete_clean = kab_df_complete_clean.rename(columns={'KABUPATEN': 'Wilayah'})\n",
    "        kab_df_complete_clean = pd.concat([prov_df_pivot, kab_df_complete_clean], ignore_index=True)\n",
    "\n",
    "        # Get kategori value for agregasi propinsi\n",
    "        sgt_tinggi = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "        tinggi = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "        rendah = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Rendah', 'Persentase'].values[0]\n",
    "        menengah =  prov_df_complete.loc[prov_df_complete['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "        \n",
    "\n",
    "        kab_df_complete_clean = kab_df_complete_clean.rename(columns={'Rendah': 'Rendah (%)', 'Menengah': 'Menengah (%)','Tinggi': 'Tinggi (%)', 'Sangat Tinggi': 'Sangat Tinggi (%)'})\n",
    "        new_order = ['Wilayah', 'Rendah (%)', 'Menengah (%)', 'Tinggi (%)', 'Sangat Tinggi (%)']\n",
    "        kab_df_complete_clean = kab_df_complete_clean[new_order]\n",
    "        \n",
    "        return prov_df_complete, kab_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    elif tipe_informasi == 'ANALISA_SIFAT_HUJAN':\n",
    "        all_combinations = pd.MultiIndex.from_product([prov_df['Wilayah'].unique(), categories_sh], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "        prov_df_complete = all_combinations.merge(prov_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "        prov_df_complete['Persentase'] = prov_df_complete['Persentase'].fillna(0)\n",
    "        prov_df_complete['Persentase%'] = prov_df_complete['Persentase%'].fillna('0%')\n",
    "        non_zero_df = prov_df_complete[prov_df_complete['Persentase'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Persentase'].sum()\n",
    "        non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "        prov_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "\n",
    "        # Update the 'Persentase%' column if it exists\n",
    "        if 'Persentase%' in prov_df_complete.columns:\n",
    "            prov_df_complete['Persentase%'] = prov_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "        prov_df_pivot = pd.pivot(prov_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "        prov_df_pivot = prov_df_pivot.reset_index()\n",
    "        prov_df_pivot.columns.name = None\n",
    "\n",
    "        # Agregasi Kabupaten\n",
    "        kab_area_sum = data.groupby('KABUPATEN')['Area_H'].sum()\n",
    "        kab_cat_area_sum = data.groupby(['Kategori','KABUPATEN'])['Area_H'].sum()\n",
    "        kab_df = round(kab_cat_area_sum / kab_area_sum, 4)\n",
    "        kab_df = kab_df.reset_index()\n",
    "        kab_df = kab_df[(kab_df['Kategori'] != \" \") & (kab_df['KABUPATEN'] != \" \")]\n",
    "        kab_df['Area_H'] = round(kab_df['Area_H']*100, 2)\n",
    "        all_combinations_kab = pd.MultiIndex.from_product([kab_df['KABUPATEN'].unique(), categories_sh], names=['KABUPATEN', 'Kategori']).to_frame(index=False)\n",
    "        kab_df_complete = all_combinations_kab.merge(kab_df, on=['KABUPATEN', 'Kategori'], how='left')\n",
    "        kab_df_complete['Area_H'] = kab_df_complete['Area_H'].fillna(0)\n",
    "        kab_df_complete_clean = pd.DataFrame()\n",
    "        for name, group in kab_df_complete.groupby('KABUPATEN'):\n",
    "            non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "            total_non_zero = non_zero_df['Area_H'].sum()\n",
    "            \n",
    "            if total_non_zero > 0:\n",
    "                non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "            \n",
    "            group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "            kab_df_complete_clean = pd.concat([kab_df_complete_clean, group])\n",
    "\n",
    "        kab_df_complete_clean = kab_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        top_5_areas = kab_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(5, 'Area_H')).reset_index(drop=True)\n",
    "        top_by_kategori = top_5_areas.groupby('Kategori')['KABUPATEN'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "        kab_df_complete_clean = pd.pivot(kab_df_complete_clean, index='KABUPATEN', columns='Kategori', values='Area_H')\n",
    "        kab_df_complete_clean = kab_df_complete_clean.reset_index()\n",
    "        kab_df_complete_clean.columns.name = None\n",
    "        kab_df_complete_clean.drop(kab_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "\n",
    "        # # Concat Propinsi to kabupaten\n",
    "        kab_df_complete_clean = kab_df_complete_clean.rename(columns={'KABUPATEN': 'Wilayah'})\n",
    "        kab_df_complete_clean = pd.concat([prov_df_pivot, kab_df_complete_clean], ignore_index=True)\n",
    "\n",
    "        # Get kategori value for agregasi propinsi\n",
    "        atas_normal = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Atas Normal', 'Persentase'].values[0]\n",
    "        normal = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Normal', 'Persentase'].values[0]\n",
    "        bawah_normal = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Bawah Normal', 'Persentase'].values[0]\n",
    "        \n",
    "\n",
    "        kab_df_complete_clean = kab_df_complete_clean.rename(columns={'Bawah Normal': 'Bawah Normal (%)', 'Normal': 'Normal (%)','Atas Normal': 'Atas Normal (%)'})\n",
    "        new_order = ['Wilayah', 'Bawah Normal (%)', 'Normal (%)', 'Atas Normal (%)']\n",
    "        kab_df_complete_clean = kab_df_complete_clean[new_order]\n",
    "        \n",
    "        \n",
    "        return prov_df_complete, kab_df_complete_clean, top_by_kategori, atas_normal, normal, bawah_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipe_informasi = 'ANALISA_CURAH_HUJAN'\n",
    "wilayah_ref = 'NAD'\n",
    "prov_df_complete, kab_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_upt(dataframe, tipe_informasi, nama_prov_union_shp[wilayah_ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[dataframe['PROPINSI'] == 'PAPUA BARAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcgis.features import GeoAccessor\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import locale\n",
    "from config import nama_stasiun, nama_prov, nama_prov_union_shp, nama_prov_folder\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_chart import cut_image\n",
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "from utils.proses1_chart import chart_infografis_ch, chart_infografis_sh, laporan_tabel, chart_laporan_ch, chart_laporan_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature = r'F:\\ASSET\\spatial\\BMKG_PinterIklim\\proses1_data_layout.gdb\\polygon_ach'\n",
    "dataframe = pd.DataFrame.spatial.from_featureclass(feature)\n",
    "tipe_informasi = 'ANALISA_CURAH_HUJAN'\n",
    "periode = 'BULANAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with arcpy.da.SearchCursor(prov_referensi, [\"WADMPR\", \"SHAPE@\"]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "            for r in cursors:\n",
    "            \n",
    "                wilayah_ref = r[0]\n",
    "                prov_geometry = r[1]\n",
    "                if wilayah_ref == 'Indonesia':\n",
    "                    print(wilayah_ref)\n",
    "                    sde_table_path = prov_sde[wilayah_ref]\n",
    "                    indo_df_complete, prov_df_complete_clean, pulau_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_indo(dataframe, tipe_informasi=\"ANALISA_CURAH_HUJAN\")\n",
    "                    df = prov_df_complete_clean\n",
    "\n",
    "\n",
    "                    if periode == 'BULANAN':\n",
    "                        if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "                            df = df.rename(columns={'Wilayah' : 'wilayah', 'Rendah (%)': 'rendah', 'Menengah (%)': 'menengah', 'Tinggi (%)' : 'tinggi', 'Sangat Tinggi (%)': 'sangat_tinggi'})\n",
    "                            df['periode_informasi'] = 'Bulanan'\n",
    "                            df['jenis_informasi'] = 'CH'\n",
    "                            df['tipe_informasi'] = 'Analisis'\n",
    "                            df['date'] = current_date_str\n",
    "                            df['date_datetime'] = current_date_datetime\n",
    "\n",
    "                            # Use ArcPy to create a search cursor and read the data\n",
    "                            fields = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "                            data = []\n",
    "                            with arcpy.da.SearchCursor(sde_table_path, fields) as cursor:\n",
    "                                for row in cursor:\n",
    "                                    data.append(row)\n",
    "                            # Convert the data to a pandas DataFrame\n",
    "                            df_sde = pd.DataFrame(data, columns=fields)\n",
    "                            df_sde['date_datetime'] = pd.to_datetime(df_sde['date_datetime'], errors='coerce')\n",
    "\n",
    "                            two_months_ago = datetime.now() - timedelta(days=60)\n",
    "                            df_filtered = df_sde[~((df_sde['tipe_informasi'] == 'Analisis') & \n",
    "                                                (df_sde['date_datetime'] < two_months_ago))]\n",
    "\n",
    "                            df_combined = pd.concat([df_filtered, df], ignore_index=True)\n",
    "                            sde_table_columns = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "\n",
    "                            for col in sde_table_columns:\n",
    "                                if col not in df_combined.columns:\n",
    "                                    df_combined[col] = None\n",
    "\n",
    "                            df_combined = df_combined[sde_table_columns]\n",
    "                            data_to_insert = df_combined.to_dict(orient='records')\n",
    "\n",
    "                            # Truncate the SDE table\n",
    "                            arcpy.management.TruncateTable(sde_table_path)\n",
    "\n",
    "                            # Insert the filtered data back into the SDE table\n",
    "                            with arcpy.da.InsertCursor(sde_table_path, sde_table_columns) as cursor:\n",
    "                                for row in data_to_insert:\n",
    "                                    cursor.insertRow([row[col] for col in sde_table_columns])\n",
    "\n",
    "                            del cursor\n",
    "\n",
    "\n",
    "\n",
    "                        else: #tipe_informasi == 'ANALISA_SIFAT HUJAN'\n",
    "                            df = df.rename(columns={'Wilayah' : 'wilayah', 'Bawah Normal (%)': 'bawah_normal', 'Normal (%)': 'normal', 'Atas Normal (%)' : 'atas_normal'})\n",
    "                            df['periode_informasi'] = 'Bulanan'\n",
    "                            df['jenis_informasi'] = 'SH'\n",
    "                            df['tipe_informasi'] = 'Analisis'\n",
    "                            df['date'] = current_date_str\n",
    "                            df['date_datetime'] = current_date_datetime\n",
    "\n",
    "                            # Use ArcPy to create a search cursor and read the data\n",
    "                            fields = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "                            data = []\n",
    "                            with arcpy.da.SearchCursor(sde_table_path, fields) as cursor:\n",
    "                                for row in cursor:\n",
    "                                    data.append(row)\n",
    "                            # Convert the data to a pandas DataFrame\n",
    "                            df_sde = pd.DataFrame(data, columns=fields)\n",
    "                            df_sde['date_datetime'] = pd.to_datetime(df_sde['date_datetime'], errors='coerce')\n",
    "\n",
    "                            two_months_ago = datetime.now() - timedelta(days=60)\n",
    "                            df_filtered = df_sde[~((df_sde['tipe_informasi'] == 'Analisis') & \n",
    "                                                (df_sde['date_datetime'] < two_months_ago))]\n",
    "\n",
    "                            df_combined = pd.concat([df_filtered, df], ignore_index=True)\n",
    "                            sde_table_columns = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "\n",
    "                            for col in sde_table_columns:\n",
    "                                if col not in df_combined.columns:\n",
    "                                    df_combined[col] = None\n",
    "\n",
    "                            df_combined = df_combined[sde_table_columns]\n",
    "                            data_to_insert = df_combined.to_dict(orient='records')\n",
    "\n",
    "                            # Truncate the SDE table\n",
    "                            arcpy.management.TruncateTable(sde_table_path)\n",
    "\n",
    "                            # Insert the filtered data back into the SDE table\n",
    "                            with arcpy.da.InsertCursor(sde_table_path, sde_table_columns) as cursor:\n",
    "                                for row in data_to_insert:\n",
    "                                    cursor.insertRow([row[col] for col in sde_table_columns])\n",
    "\n",
    "                            del cursor\n",
    "\n",
    "                            \n",
    "\n",
    "                    else: #periode == 'DASARIAN \\\n",
    "                        if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "                            df = df.rename(columns={'Wilayah' : 'wilayah', 'Rendah (%)': 'rendah', 'Menengah (%)': 'menengah', 'Tinggi (%)' : 'tinggi', 'Sangat Tinggi (%)': 'sangat_tinggi'})\n",
    "                            df['periode_informasi'] = 'Dasarian'\n",
    "                            df['jenis_informasi'] = 'CH'\n",
    "                            df['tipe_informasi'] = 'Analisis'\n",
    "                            df['date'] = current_date_str\n",
    "                            df['date_datetime'] = current_date_datetime\n",
    "\n",
    "\n",
    "                            # Use ArcPy to create a search cursor and read the data\n",
    "                            fields = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "                            data = []\n",
    "                            with arcpy.da.SearchCursor(sde_table_path, fields) as cursor:\n",
    "                                for row in cursor:\n",
    "                                    data.append(row)\n",
    "                            # Convert the data to a pandas DataFrame\n",
    "                            df_sde = pd.DataFrame(data, columns=fields)\n",
    "                            df_sde['date_datetime'] = pd.to_datetime(df_sde['date_datetime'], errors='coerce')\n",
    "\n",
    "                            two_months_ago = datetime.now() - timedelta(days=60)\n",
    "                            df_filtered = df_sde[~((df_sde['tipe_informasi'] == 'Analisis') & \n",
    "                                                (df_sde['date_datetime'] < two_months_ago))]\n",
    "\n",
    "                            df_combined = pd.concat([df_filtered, df], ignore_index=True)\n",
    "                            sde_table_columns = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "\n",
    "                            for col in sde_table_columns:\n",
    "                                if col not in df_combined.columns:\n",
    "                                    df_combined[col] = None\n",
    "\n",
    "                            df_combined = df_combined[sde_table_columns]\n",
    "                            data_to_insert = df_combined.to_dict(orient='records')\n",
    "\n",
    "                            # Truncate the SDE table\n",
    "                            arcpy.management.TruncateTable(sde_table_path)\n",
    "\n",
    "                            # Insert the filtered data back into the SDE table\n",
    "                            with arcpy.da.InsertCursor(sde_table_path, sde_table_columns) as cursor:\n",
    "                                for row in data_to_insert:\n",
    "                                    cursor.insertRow([row[col] for col in sde_table_columns])\n",
    "\n",
    "                            del cursor\n",
    "\n",
    "                            \n",
    "\n",
    "                        else: #tipe_informasi == 'ANALISA_SIFAT HUJAN'\n",
    "                            df = df.rename(columns={'Wilayah' : 'wilayah', 'Bawah Normal (%)': 'bawah_normal', 'Normal (%)': 'normal', 'Atas Normal (%)' : 'atas_normal'})\n",
    "                            df['periode_informasi'] = 'Dasarian'\n",
    "                            df['jenis_informasi'] = 'SH'\n",
    "                            df['tipe_informasi'] = 'Analisis'\n",
    "                            df['date'] = current_date_str\n",
    "                            df['date_datetime'] = current_date_datetime\n",
    "\n",
    "\n",
    "                            # Use ArcPy to create a search cursor and read the data\n",
    "                            fields = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "                            data = []\n",
    "                            with arcpy.da.SearchCursor(sde_table_path, fields) as cursor:\n",
    "                                for row in cursor:\n",
    "                                    data.append(row)\n",
    "                            # Convert the data to a pandas DataFrame\n",
    "                            df_sde = pd.DataFrame(data, columns=fields)\n",
    "                            df_sde['date_datetime'] = pd.to_datetime(df_sde['date_datetime'], errors='coerce')\n",
    "\n",
    "                            two_months_ago = datetime.now() - timedelta(days=60)\n",
    "                            df_filtered = df_sde[~((df_sde['tipe_informasi'] == 'Analisis') & \n",
    "                                                (df_sde['date_datetime'] < two_months_ago))]\n",
    "\n",
    "                            df_combined = pd.concat([df_filtered, df], ignore_index=True)\n",
    "                            sde_table_columns = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "\n",
    "                            for col in sde_table_columns:\n",
    "                                if col not in df_combined.columns:\n",
    "                                    df_combined[col] = None\n",
    "\n",
    "                            df_combined = df_combined[sde_table_columns]\n",
    "                            data_to_insert = df_combined.to_dict(orient='records')\n",
    "\n",
    "                            # Truncate the SDE table\n",
    "                            arcpy.management.TruncateTable(sde_table_path)\n",
    "\n",
    "                            # Insert the filtered data back into the SDE table\n",
    "                            with arcpy.da.InsertCursor(sde_table_path, sde_table_columns) as cursor:\n",
    "                                for row in data_to_insert:\n",
    "                                    cursor.insertRow([row[col] for col in sde_table_columns])\n",
    "\n",
    "                            del cursor\n",
    "\n",
    "\n",
    "\n",
    "                else: # wilayah_ref == UPT\n",
    "                    \n",
    "                    print(wilayah_ref)\n",
    "                    sde_table_path = prov_sde[wilayah_ref]\n",
    "                    prov_df_complete, kab_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_upt(dataframe, tipe_informasi, nama_prov_union_shp[wilayah_ref])\n",
    "                    df = kab_df_complete_clean\n",
    "\n",
    "                    if periode == 'BULANAN':\n",
    "                        if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "                            df = df.rename(columns={'Wilayah' : 'wilayah', 'Rendah (%)': 'rendah', 'Menengah (%)': 'menengah', 'Tinggi (%)' : 'tinggi', 'Sangat Tinggi (%)': 'sangat_tinggi'})\n",
    "                            df['periode_informasi'] = 'Bulanan'\n",
    "                            df['jenis_informasi'] = 'CH'\n",
    "                            df['tipe_informasi'] = 'Analisis'\n",
    "                            df['date'] = current_date_str\n",
    "                            df['date_datetime'] = current_date_datetime\n",
    "\n",
    "                            # Use ArcPy to create a search cursor and read the data\n",
    "                            fields = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "                            data = []\n",
    "                            with arcpy.da.SearchCursor(sde_table_path, fields) as cursor:\n",
    "                                for row in cursor:\n",
    "                                    data.append(row)\n",
    "                            # Convert the data to a pandas DataFrame\n",
    "                            df_sde = pd.DataFrame(data, columns=fields)\n",
    "                            df_sde['date_datetime'] = pd.to_datetime(df_sde['date_datetime'], errors='coerce')\n",
    "\n",
    "                            two_months_ago = datetime.now() - timedelta(days=60)\n",
    "                            df_filtered = df_sde[~((df_sde['tipe_informasi'] == 'Analisis') & \n",
    "                                                (df_sde['date_datetime'] < two_months_ago))]\n",
    "\n",
    "                            df_combined = pd.concat([df_filtered, df], ignore_index=True)\n",
    "                            sde_table_columns = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "\n",
    "                            for col in sde_table_columns:\n",
    "                                if col not in df_combined.columns:\n",
    "                                    df_combined[col] = None\n",
    "\n",
    "                            df_combined = df_combined[sde_table_columns]\n",
    "                            data_to_insert = df_combined.to_dict(orient='records')\n",
    "\n",
    "                            # Truncate the SDE table\n",
    "                            arcpy.management.TruncateTable(sde_table_path)\n",
    "\n",
    "                            # Insert the filtered data back into the SDE table\n",
    "                            with arcpy.da.InsertCursor(sde_table_path, sde_table_columns) as cursor:\n",
    "                                for row in data_to_insert:\n",
    "                                    cursor.insertRow([row[col] for col in sde_table_columns])\n",
    "\n",
    "                            del cursor\n",
    "\n",
    "\n",
    "\n",
    "                        else: #tipe_informasi == 'ANALISA_SIFAT HUJAN'\n",
    "                            df = df.rename(columns={'Wilayah' : 'wilayah', 'Bawah Normal (%)': 'bawah_normal', 'Normal (%)': 'normal', 'Atas Normal (%)' : 'atas_normal'})\n",
    "                            df['periode_informasi'] = 'Bulanan'\n",
    "                            df['jenis_informasi'] = 'SH'\n",
    "                            df['tipe_informasi'] = 'Analisis'\n",
    "                            df['date'] = current_date_str\n",
    "                            df['date_datetime'] = current_date_datetime\n",
    "\n",
    "                            # Use ArcPy to create a search cursor and read the data\n",
    "                            fields = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "                            data = []\n",
    "                            with arcpy.da.SearchCursor(sde_table_path, fields) as cursor:\n",
    "                                for row in cursor:\n",
    "                                    data.append(row)\n",
    "                            # Convert the data to a pandas DataFrame\n",
    "                            df_sde = pd.DataFrame(data, columns=fields)\n",
    "                            df_sde['date_datetime'] = pd.to_datetime(df_sde['date_datetime'], errors='coerce')\n",
    "\n",
    "                            two_months_ago = datetime.now() - timedelta(days=60)\n",
    "                            df_filtered = df_sde[~((df_sde['tipe_informasi'] == 'Analisis') & \n",
    "                                                (df_sde['date_datetime'] < two_months_ago))]\n",
    "\n",
    "                            df_combined = pd.concat([df_filtered, df], ignore_index=True)\n",
    "                            sde_table_columns = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "\n",
    "                            for col in sde_table_columns:\n",
    "                                if col not in df_combined.columns:\n",
    "                                    df_combined[col] = None\n",
    "\n",
    "                            df_combined = df_combined[sde_table_columns]\n",
    "                            data_to_insert = df_combined.to_dict(orient='records')\n",
    "\n",
    "                            # Truncate the SDE table\n",
    "                            arcpy.management.TruncateTable(sde_table_path)\n",
    "\n",
    "                            # Insert the filtered data back into the SDE table\n",
    "                            with arcpy.da.InsertCursor(sde_table_path, sde_table_columns) as cursor:\n",
    "                                for row in data_to_insert:\n",
    "                                    cursor.insertRow([row[col] for col in sde_table_columns])\n",
    "\n",
    "                            del cursor\n",
    "\n",
    "                        \n",
    "\n",
    "                    else:\n",
    "                        if tipe_informasi == 'ANALISA_CURAH_HUJAN':\n",
    "                            df = df.rename(columns={'Wilayah' : 'wilayah', 'Rendah (%)': 'rendah', 'Menengah (%)': 'menengah', 'Tinggi (%)' : 'tinggi', 'Sangat Tinggi (%)': 'sangat_tinggi'})\n",
    "                            df['periode_informasi'] = 'Dasarian'\n",
    "                            df['jenis_informasi'] = 'CH'\n",
    "                            df['tipe_informasi'] = 'Analisis'\n",
    "                            df['date'] = current_date_str\n",
    "                            df['date_datetime'] = current_date_datetime\n",
    "\n",
    "\n",
    "                            # Use ArcPy to create a search cursor and read the data\n",
    "                            fields = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "                            data = []\n",
    "                            with arcpy.da.SearchCursor(sde_table_path, fields) as cursor:\n",
    "                                for row in cursor:\n",
    "                                    data.append(row)\n",
    "                            # Convert the data to a pandas DataFrame\n",
    "                            df_sde = pd.DataFrame(data, columns=fields)\n",
    "                            df_sde['date_datetime'] = pd.to_datetime(df_sde['date_datetime'], errors='coerce')\n",
    "\n",
    "                            two_months_ago = datetime.now() - timedelta(days=60)\n",
    "                            df_filtered = df_sde[~((df_sde['tipe_informasi'] == 'Analisis') & \n",
    "                                                (df_sde['date_datetime'] < two_months_ago))]\n",
    "\n",
    "                            df_combined = pd.concat([df_filtered, df], ignore_index=True)\n",
    "                            sde_table_columns = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "\n",
    "                            for col in sde_table_columns:\n",
    "                                if col not in df_combined.columns:\n",
    "                                    df_combined[col] = None\n",
    "\n",
    "                            df_combined = df_combined[sde_table_columns]\n",
    "                            data_to_insert = df_combined.to_dict(orient='records')\n",
    "\n",
    "                            # Truncate the SDE table\n",
    "                            arcpy.management.TruncateTable(sde_table_path)\n",
    "\n",
    "                            # Insert the filtered data back into the SDE table\n",
    "                            with arcpy.da.InsertCursor(sde_table_path, sde_table_columns) as cursor:\n",
    "                                for row in data_to_insert:\n",
    "                                    cursor.insertRow([row[col] for col in sde_table_columns])\n",
    "\n",
    "                            del cursor\n",
    "\n",
    "                            \n",
    "\n",
    "                        else: #tipe_informasi == 'ANALISA_SIFAT HUJAN'\n",
    "                            df = df.rename(columns={'Wilayah' : 'wilayah', 'Bawah Normal (%)': 'bawah_normal', 'Normal (%)': 'normal', 'Atas Normal (%)' : 'atas_normal'})\n",
    "                            df['periode_informasi'] = 'Dasarian'\n",
    "                            df['jenis_informasi'] = 'SH'\n",
    "                            df['tipe_informasi'] = 'Analisis'\n",
    "                            df['date'] = current_date_str\n",
    "                            df['date_datetime'] = current_date_datetime\n",
    "\n",
    "\n",
    "                            # Use ArcPy to create a search cursor and read the data\n",
    "                            fields = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "                            data = []\n",
    "                            with arcpy.da.SearchCursor(sde_table_path, fields) as cursor:\n",
    "                                for row in cursor:\n",
    "                                    data.append(row)\n",
    "                            # Convert the data to a pandas DataFrame\n",
    "                            df_sde = pd.DataFrame(data, columns=fields)\n",
    "                            df_sde['date_datetime'] = pd.to_datetime(df_sde['date_datetime'], errors='coerce')\n",
    "\n",
    "                            two_months_ago = datetime.now() - timedelta(days=60)\n",
    "                            df_filtered = df_sde[~((df_sde['tipe_informasi'] == 'Analisis') & \n",
    "                                                (df_sde['date_datetime'] < two_months_ago))]\n",
    "\n",
    "                            df_combined = pd.concat([df_filtered, df], ignore_index=True)\n",
    "                            sde_table_columns = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "\n",
    "                            for col in sde_table_columns:\n",
    "                                if col not in df_combined.columns:\n",
    "                                    df_combined[col] = None\n",
    "\n",
    "                            df_combined = df_combined[sde_table_columns]\n",
    "                            data_to_insert = df_combined.to_dict(orient='records')\n",
    "\n",
    "                            # Truncate the SDE table\n",
    "                            arcpy.management.TruncateTable(sde_table_path)\n",
    "\n",
    "                            # Insert the filtered data back into the SDE table\n",
    "                            with arcpy.da.InsertCursor(sde_table_path, sde_table_columns) as cursor:\n",
    "                                for row in data_to_insert:\n",
    "                                    cursor.insertRow([row[col] for col in sde_table_columns])\n",
    "\n",
    "                            del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "from config import extent_pulau, pulau_feature, titik_grid, nama_prov, poly_kecamatan, nama_prov_folder\n",
    "from utils.proses1_raster_mosaic import copy_raster, add_raster_and_update_fields, delete_old_rasters\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "import arcgis\n",
    "from arcgis.features import GeoAccessor\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import locale\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Set time for dataset\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "\n",
    "# Set parameter\n",
    "gridsize_pkecil = os.getenv(\"GRID_PKECIL\")\n",
    "gridsize_pbesar= os.getenv(\"GRID_PBESAR\")\n",
    "\n",
    "\n",
    "# Set folder structure\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "output_level_ind = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA_BULANAN'\n",
    "output_tipe_das = 'ANALISA_DASARIAN'\n",
    "\n",
    "\n",
    "\n",
    "# All output folder path Bulanan - Prov\n",
    "output_prov = os.path.join(output_folder, output_level_prov)\n",
    "\n",
    "\n",
    "# Set file to loop code\n",
    "pulau_reference = os.getenv(\"PULAU_REFERENCE\")\n",
    "pulau_besar_merge = os.getenv(\"PULAU_BESAR_MERGE\")\n",
    "\n",
    "\n",
    "# Set data for I/O\n",
    "raster_loc = os.getenv(\"RASTER_LOC\")\n",
    "fgdb_input = os.getenv(\"FGDB_TEMP\")\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "mosaic_bln_ch= os.getenv(\"MOSAIC_BLN_ACH\")\n",
    "mosaic_bln_sh= os.getenv(\"MOSAIC_BLN_ASH\")\n",
    "mosaic_das_ch= os.getenv(\"MOSAIC_DAS_ACH\")\n",
    "mosaic_das_sh= os.getenv(\"MOSAIC_DAS_ASH\")\n",
    "main_output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "input_data_bln = os.path.join(fgdb_temp, 'output_2_proses1_feature_point_bln')\n",
    "input_data_das = os.path.join(fgdb_temp, 'output_2_proses1_feature_point_das')\n",
    "\n",
    "\n",
    "raster_loc= os.getenv('RASTER_LOC')\n",
    "\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "\n",
    "input_data = os.path.join(fgdb_temp, 'output_2_proses1_feature_point_bln')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "raster_ACH_to_merge = []\n",
    "raster_ASH_to_merge = []\n",
    "ACH_to_merge = []\n",
    "ASH_to_merge = []\n",
    "CSV_to_merge = []\n",
    "\n",
    "poly_indo_ach = None\n",
    "poly_indo_ash = None\n",
    "\n",
    "with arcpy.da.SearchCursor(pulau_reference, [[\"Pulau_Singkat\", [\"Is_Besar\"]]]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "        \n",
    "            if r[1] == \"False\":  # val False = Pulau Kecil dan va True = Pulau Besar\n",
    "                pulau_kecil = r[0]\n",
    "                print(f\"Memulai Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "\n",
    "                ####### Proses untuk kategori pulau kecil\\\n",
    "                ####### Proses ACH untuk kategori pulau kecil\n",
    "                # Create new folder\n",
    "\n",
    "                pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                    output_tipe_periode=output_tipe_bln, tipe='TIFF', \n",
    "                                                                    nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "\n",
    "                # Start Process\n",
    "\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features= input_data,\n",
    "                        z_field=\"CH\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(output_loc_tiff, f\"ach_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\"),\n",
    "                        cell_size=gridsize_pkecil,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "                raster_ach_pk = arcpy.Raster(os.path.join(output_loc_tiff, f\"ach_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\"))\n",
    "                raster_ach_pk_copy = os.path.join(raster_loc, f\"ach_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\")\n",
    "\n",
    "                copy_raster(raster_ach_pk, raster_ach_pk_copy)\n",
    "\n",
    "                row_list = (raster_ach_pk_copy, f'{pulau_kecil}')\n",
    "\n",
    "                raster_ACH_to_merge.append(row_list)\n",
    "\n",
    "                print(f\"Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "                # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "                # arcpy.management.AddRastersToMosaicDataset(\n",
    "                #                 in_mosaic_dataset= mosaic_bln_ch,\n",
    "                #                 raster_type=\"Raster Dataset\",\n",
    "                #                 input_path= raster_ach_pk,\n",
    "                #                 update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                #                 update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                #                 update_overviews=\"NO_OVERVIEWS\",\n",
    "                #                 maximum_pyramid_levels=None,\n",
    "                #                 maximum_cell_size=0,\n",
    "                #                 minimum_dimension=1500,\n",
    "                #                 spatial_reference=None,\n",
    "                #                 filter=\"\",\n",
    "                #                 sub_folder=\"SUBFOLDERS\",\n",
    "                #                 duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                #                 build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                #                 calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                #                 build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                #                 operation_description=\"\",\n",
    "                #                 force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                #                 estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                #                 aux_inputs=None,\n",
    "                #                 enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                #                 cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "                # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai ...\")\n",
    "\n",
    "                pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                output_loc_csv = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                    output_tipe_periode=output_tipe_bln, tipe='CSV', \n",
    "                                                                    nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "\n",
    "\n",
    "                titik_grid_extract_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}\")\n",
    "                arcpy.management.CopyFeatures(in_features=titik_grid[pulau_kecil], out_feature_class=titik_grid_extract_pk)\n",
    "                point_extracted_pk = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pk, [[raster_ach_pk, \"CH\"]], \"NONE\")\n",
    "                # point_extracted_ch.save()\n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Reclassify ACH Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                out_raster_ach_pk = arcpy.sa.Reclassify(\n",
    "                    in_raster=raster_ach_pk,\n",
    "                    reclass_field=\"VALUE\",\n",
    "                    remap=\"0 20 1;20 50 2;50 100 3;100 150 4;150 200 5;200 300 6;300 400 7;400 500 8;500 10000 9\",\n",
    "                    missing_values=\"DATA\")\n",
    "\n",
    "                out_raster_ach_pk.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{pulau_kecil}_{year}{month}\"))\n",
    "                print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                # Pembuatan archive\n",
    "                output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                    output_tipe_periode=output_tipe_bln, tipe='SHP', \n",
    "                                                                    nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "                Output_polygon_features_ach = os.path.join(fgdb_temp, f\"ach_bln_{pulau_kecil.lower()}_ver_{year}{month}\")\n",
    "                arcpy.conversion.RasterToPolygon(in_raster=out_raster_ach_pk, out_polygon_features=Output_polygon_features_ach)\n",
    "                arcpy.management.AddFields(in_table=Output_polygon_features_ach, field_description= \"CH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                arcpy.management.CalculateField(\n",
    "                            in_table=Output_polygon_features_ach,\n",
    "                            field=\"CH\",\n",
    "                            expression=\"ch(!gridcode!)\",\n",
    "                            expression_type=\"PYTHON3\",\n",
    "                            code_block=\"\"\"def ch(x):\n",
    "                            if x == 1:\n",
    "                                return \"0-20\"\n",
    "                            elif x == 2:\n",
    "                                return \"21-50\"\n",
    "                            elif x == 3:\n",
    "                                return \"51-100\"\n",
    "                            elif x == 4:\n",
    "                                return \"101-150\"\n",
    "                            elif x == 5:\n",
    "                                return \"151-200\"\n",
    "                            elif x == 6:\n",
    "                                return \"201-300\"\n",
    "                            elif x == 7:\n",
    "                                return \"301-400\"\n",
    "                            elif x == 8:\n",
    "                                return \"401-500\"\n",
    "                            elif x ==9 :\n",
    "                                return \">500\"\n",
    "                            \"\"\",\n",
    "                            field_type=\"TEXT\",\n",
    "                            enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                arcpy.management.CalculateField(\n",
    "                            in_table=Output_polygon_features_ach,\n",
    "                            field=\"Kategori\",\n",
    "                            expression=\"cat(!gridcode!)\",\n",
    "                            expression_type=\"PYTHON3\",\n",
    "                            code_block=\"\"\"def cat(x):\n",
    "                            if x == 1:\n",
    "                                return \"Rendah\"\n",
    "                            elif x == 2:\n",
    "                                return \"Rendah\"\n",
    "                            elif x == 3:\n",
    "                                return \"Rendah\"\n",
    "                            elif x == 4:\n",
    "                                return \"Menengah\"\n",
    "                            elif x == 5:\n",
    "                                return \"Menengah\"\n",
    "                            elif x == 6:\n",
    "                                return \"Menengah\"\n",
    "                            elif x == 7:\n",
    "                                return \"Tinggi\"\n",
    "                            elif x == 8:\n",
    "                                return \"Sangat Tinggi\"\n",
    "                            elif x ==9 :\n",
    "                                return \"Sangat Tinggi\"\n",
    "                            \"\"\",\n",
    "                            field_type=\"TEXT\",\n",
    "                            enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ach,\n",
    "                                        field=\"Periode\",\n",
    "                                        expression=f'\"{month_name} {year}\"',\n",
    "                                        expression_type=\"PYTHON3\"\n",
    "                                    )\n",
    "                arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"Informasi\",\n",
    "                                    expression='\"Curah Hujan\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "\n",
    "                poly_kec = poly_kecamatan[pulau_kecil]\n",
    "\n",
    "\n",
    "                Output_polygon_features_ach_union = os.path.join(output_loc_shp, f\"ach_bln_{pulau_kecil.lower()}_ver_{year}{month}\")\n",
    "                arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ach], \n",
    "                                        out_feature_class=Output_polygon_features_ach_union)\n",
    "\n",
    "                arcpy.management.AddField(\n",
    "                            in_table=Output_polygon_features_ach_union,\n",
    "                            field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                arcpy.management.CalculateGeometryAttributes(\n",
    "                        in_features=Output_polygon_features_ach_union,\n",
    "                        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                        area_unit=\"HECTARES\")\n",
    "\n",
    "                # Menggabungkan polygon untuk di merge\n",
    "                ACH_to_merge.append(Output_polygon_features_ach)\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "                ####### Proses ASH untuk kategori pulau kecil\n",
    "                print(f\"Memulai Proses Interpolasi ASH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features=input_data,\n",
    "                        z_field=\"SH_\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(output_loc_tiff, f\"ash_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\"),\n",
    "                        cell_size=gridsize_pkecil,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "\n",
    "                raster_ash_pk = arcpy.Raster(os.path.join(output_loc_tiff, f\"ash_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\"))\n",
    "\n",
    "                raster_ach_pk_copy = os.path.join(raster_loc, f\"ash_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\")\n",
    "\n",
    "                copy_raster(raster_ach_pk, raster_ach_pk_copy)\n",
    "\n",
    "                row_list = (raster_ach_pk_copy, f'{pulau_kecil}')\n",
    "\n",
    "                raster_ASH_to_merge.append(row_list)\n",
    "\n",
    "\n",
    "                print(f\"Proses Interpolasi ASH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "                # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "                # arcpy.management.AddRastersToMosaicDataset(\n",
    "                #                 in_mosaic_dataset= mosaic_bln_sh,\n",
    "                #                 raster_type=\"Raster Dataset\",\n",
    "                #                 input_path= raster_ash_pk,\n",
    "                #                 update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                #                 update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                #                 update_overviews=\"NO_OVERVIEWS\",\n",
    "                #                 maximum_pyramid_levels=None,\n",
    "                #                 maximum_cell_size=0,\n",
    "                #                 minimum_dimension=1500,\n",
    "                #                 spatial_reference=None,\n",
    "                #                 filter=\"\",\n",
    "                #                 sub_folder=\"SUBFOLDERS\",\n",
    "                #                 duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                #                 build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                #                 calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                #                 build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                #                 operation_description=\"\",\n",
    "                #                 force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                #                 estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                #                 aux_inputs=None,\n",
    "                #                 enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                #                 cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_SH\")\n",
    "                # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai . . .\")\n",
    "                point_extracted_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}\")\n",
    "                arcpy.sa.ExtractMultiValuesToPoints(point_extracted_pk, [[raster_ash_pk, \"SH\"]], \"NONE\")\n",
    "                # point_extracted_sh.save()\n",
    "                arcpy.management.AddFields(in_table=point_extracted_pk, field_description=[[\"LAT\", \"DOUBLE\", \"Latitude\", \"\", \"\", \"\"], [\"LONG\", \"DOUBLE\", \"Longitude\", \"\", \"\", \"\"]])[0]\n",
    "                arcpy.management.CalculateGeometryAttributes(in_features=point_extracted_pk, geometry_property=[[\"LAT\", \"POINT_Y\"], [\"LONG\", \"POINT_X\"]], coordinate_system=\"PROJCS[\\\"WGS_1984_Web_Mercator_Auxiliary_Sphere\\\",GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Mercator_Auxiliary_Sphere\\\"],PARAMETER[\\\"False_Easting\\\",0.0],PARAMETER[\\\"False_Northing\\\",0.0],PARAMETER[\\\"Central_Meridian\\\",0.0],PARAMETER[\\\"Standard_Parallel_1\\\",0.0],PARAMETER[\\\"Auxiliary_Sphere_Type\\\",0.0],UNIT[\\\"Meter\\\",1.0]]\", \n",
    "                                                                        coordinate_format=\"DD\")[0]\n",
    "                print(f\"Proses Extract Point Provinsi: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Export to csv Provinsi: {pulau_kecil} dimulai . . .\")\n",
    "                out_csv_table_pk = os.path.join(output_loc_csv, f\"bln_{pulau_kecil.lower()}_ver_{year}0{month}.csv\")\n",
    "                arcpy.conversion.ExportTable(\n",
    "                                in_table= point_extracted_pk,\n",
    "                                out_table= out_csv_table_pk,\n",
    "                                where_clause=\"\",\n",
    "                                use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "                                field_mapping=None,\n",
    "                                sort_field=None)\n",
    "\n",
    "                # Menggabungkan csv untuk di merge\n",
    "                CSV_to_merge.append(out_csv_table_pk)\n",
    "                print(f\"Proses Export to csv Provinsi: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "                print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                out_raster_ash_pk = arcpy.sa.Reclassify(\n",
    "                    in_raster=raster_ash_pk,\n",
    "                    reclass_field=\"VALUE\",\n",
    "                    remap=\"0 30 1;30 50 2;50 84 3;84 115 4;115 150 5;150 200 6;200 10000 7\",\n",
    "                    missing_values=\"DATA\")\n",
    "\n",
    "                out_raster_ash_pk.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{pulau_kecil}_{year}{month}\"))\n",
    "                print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                Output_polygon_features_ash = os.path.join(fgdb_temp, f\"ash_bln_{pulau_kecil}_ver_{year}{month}\")\n",
    "                arcpy.conversion.RasterToPolygon(in_raster=out_raster_ash_pk, out_polygon_features=Output_polygon_features_ash)\n",
    "                arcpy.management.AddFields(in_table=Output_polygon_features_ash, field_description= \"SH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"SH\",\n",
    "                                        expression=\"sh(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def sh(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"0-30\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"31-50\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"51-84\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"85-115\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"116-150\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"151-200\"\n",
    "                                        elif x == 7:\n",
    "                                            return \">200\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"Kategori\",\n",
    "                                        expression=\"kategori(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def kategori(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"Normal\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "                arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"Periode\",\n",
    "                                        expression=f'\"{month_name} {year}\"',\n",
    "                                        expression_type=\"PYTHON3\"\n",
    "                                    )\n",
    "                arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Informasi\",\n",
    "                                    expression='\"Sifat Hujan\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "\n",
    "\n",
    "                poly_kec = poly_kecamatan[pulau_kecil]\n",
    "\n",
    "                Output_polygon_features_ash_union = os.path.join(output_loc_shp, f\"ash_bln_{pulau_kecil.lower()}_ver_{year}{month}\")\n",
    "                arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ash], \n",
    "                                        out_feature_class=Output_polygon_features_ash_union)\n",
    "\n",
    "                arcpy.management.AddField(\n",
    "                            in_table=Output_polygon_features_ash_union,\n",
    "                            field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                arcpy.management.CalculateGeometryAttributes(\n",
    "                        in_features=Output_polygon_features_ash_union,\n",
    "                        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                        area_unit=\"HECTARES\")\n",
    "\n",
    "                # menggabungkan polygon untuk di merge\n",
    "                ASH_to_merge.append(Output_polygon_features_ash)\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "            ####### Proses untuk kategori pulau besar\n",
    "            ####### Proses ACH Pulau Besar\n",
    "            else:\n",
    "                pulau_besar = r[0]\n",
    "                print(f\"Memulai Proses Interpolasi ACH Pulau Besar: {pulau_besar} . . .\")\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_besar], mask=pulau_feature[pulau_besar]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features=input_data,\n",
    "                        z_field=\"CH\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(fgdb_temp, f\"interpolasi_ACH_Pulau_{pulau_besar}_{year}{month}\"),\n",
    "                        cell_size=gridsize_pbesar,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "                raster_ach_pb = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ACH_Pulau_{pulau_besar}_{year}{month}\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Interpolasi ACH Pulau Besar: {pulau_besar} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "                ######### Proses Masking ACH\n",
    "                print(f\"Proses Masking ACH Pulau Besar: {pulau_besar} dimulai . . .\")\n",
    "                with arcpy.da.SearchCursor(pulau_besar_merge, [[\"Pulau\", [\"Provinsi_Singkat\"]]]) as masks:\n",
    "                    for r in masks:\n",
    "                        pulau_mask = r[0]\n",
    "                        provinsi = r[1]\n",
    "                        if pulau_mask == pulau_besar:\n",
    "                            print(f\"Memulai Mask Provinsi: {provinsi}  . . .\")\n",
    "\n",
    "                            # Membuat archive folder\n",
    "                            print(\"Membuat Archive\")\n",
    "                            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                            output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                    output_tipe_periode=output_tipe_bln, tipe='TIFF', \n",
    "                                                                    nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                            print(\"Selesai Archive\")\n",
    "\n",
    "\n",
    "                            Extract_rast_ch = os.path.join(output_loc_tiff, f\"ach_bln_{provinsi.lower()}_ver_{year}{month}.tif\")\n",
    "                            Extract_by_Mask = Extract_rast_ch\n",
    "                            Extract_rast_ch = arcpy.sa.ExtractByMask(raster_ach_pb, pulau_feature[provinsi], \"INSIDE\", extent_pulau[provinsi])\n",
    "                            Extract_rast_ch.save(Extract_by_Mask)\n",
    "\n",
    "                            Extract_rast_ch_copy = os.path.join(raster_loc, f\"ach_bln_{provinsi.lower()}_ver_{year}{month}.tif\")\n",
    "\n",
    "                            copy_raster(Extract_rast_ch, Extract_rast_ch_copy)\n",
    "\n",
    "                            row_list = (Extract_rast_ch_copy, f'{provinsi}')\n",
    "\n",
    "                            raster_ACH_to_merge.append(row_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Proses Mask Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} dimulai . . .. \")\n",
    "                            # arcpy.management.AddRastersToMosaicDataset(\n",
    "                            #     in_mosaic_dataset= mosaic_bln_ch,\n",
    "                            #     raster_type=\"Raster Dataset\",\n",
    "                            #     input_path= Extract_rast_ch,\n",
    "                            #     update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                            #     update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                            #     update_overviews=\"NO_OVERVIEWS\",\n",
    "                            #     maximum_pyramid_levels=None,\n",
    "                            #     maximum_cell_size=0,\n",
    "                            #     minimum_dimension=1500,\n",
    "                            #     spatial_reference=None,\n",
    "                            #     filter=\"\",\n",
    "                            #     sub_folder=\"SUBFOLDERS\",\n",
    "                            #     duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                            #     build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                            #     calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                            #     build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                            #     operation_description=\"\",\n",
    "                            #     force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                            #     estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                            #     aux_inputs=None,\n",
    "                            #     enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                            #     cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "                            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} selesai \")\n",
    "\n",
    "\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} dimulai ...\")\n",
    "                            titik_grid_extract_pb = os.path.join(fgdb_temp, f\"Titik_extract_{provinsi}_{year}{month}\")\n",
    "                            arcpy.management.CopyFeatures(in_features=titik_grid[provinsi], out_feature_class=titik_grid_extract_pb)\n",
    "                            point_extracted_pb = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pb, [[Extract_rast_ch, \"CH\"]], \"NONE\")\n",
    "                            # point_extracted_ch.save()\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Memulai Reclassify Provinsi: {provinsi}  . . .\")\n",
    "                            out_raster_ach_pb = arcpy.sa.Reclassify(in_raster=Extract_rast_ch,\n",
    "                                                            reclass_field=\"VALUE\",\n",
    "                                                            remap=\"0 20 1;20 50 2;50 100 3;100 150 4;150 200 5;200 300 6;300 400 7;400 500 8;500 10000 9\",\n",
    "                                                            missing_values=\"DATA\")\n",
    "\n",
    "                            out_raster_ach_pb.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{provinsi}_{year}{month}\"))\n",
    "                            print(f\"Proses Reclassify Provinsi: {provinsi} telah selesai\")\n",
    "\n",
    "\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} dimulai . . . . . . . . . . . .\")\n",
    "                            # Membuat archive folder\n",
    "                            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                            output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                    output_tipe_periode=output_tipe_bln, tipe='SHP', \n",
    "                                                                    nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                            Output_polygon_features_ach = os.path.join(fgdb_temp, f\"ach_bln_{provinsi}_ver_{year}{month}\")\n",
    "                            arcpy.conversion.RasterToPolygon(in_raster=out_raster_ach_pb, out_polygon_features=Output_polygon_features_ach)\n",
    "                            arcpy.management.AddFields(in_table=Output_polygon_features_ach, field_description= \"CH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ach,\n",
    "                                        field=\"CH\",\n",
    "                                        expression=\"ch(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def ch(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"0-20\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"21-50\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"51-100\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"101-150\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"151-200\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"201-300\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"301-400\"\n",
    "                                        elif x == 8:\n",
    "                                            return \"401-500\"\n",
    "                                        elif x ==9 :\n",
    "                                            return \">500\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ach,\n",
    "                                        field=\"Kategori\",\n",
    "                                        expression=\"cat(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def cat(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"Rendah\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"Rendah\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"Rendah\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"Menengah\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"Menengah\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"Menengah\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"Tinggi\"\n",
    "                                        elif x == 8:\n",
    "                                            return \"Sangat Tinggi\"\n",
    "                                        elif x ==9 :\n",
    "                                            return \"Sangat Tinggi\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ach,\n",
    "                                        field=\"Periode\",\n",
    "                                        expression=f'\"{month_name} {year}\"',\n",
    "                                        expression_type=\"PYTHON3\"\n",
    "                                    )\n",
    "                            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"Informasi\",\n",
    "                                    expression='\"Curah Hujan\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "\n",
    "\n",
    "                            poly_kec = poly_kecamatan[provinsi]\n",
    "\n",
    "                            Output_polygon_features_ach_union = os.path.join(output_loc_shp, f\"ach_bln_{provinsi.lower()}_ver_{year}{month}\")\n",
    "                            arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ach], \n",
    "                                        out_feature_class= Output_polygon_features_ach_union)\n",
    "\n",
    "\n",
    "                            arcpy.management.AddField(\n",
    "                            in_table=Output_polygon_features_ach_union,\n",
    "                            field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                            arcpy.management.CalculateGeometryAttributes(\n",
    "                                    in_features=Output_polygon_features_ach_union,\n",
    "                                    geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                                    area_unit=\"HECTARES\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            # Menggabungkan polygon untuk di merge\n",
    "                            ACH_to_merge.append(Output_polygon_features_ach)\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} telah selesai\")\n",
    "                            print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "                ####### Proses ASH Pulau Besar\n",
    "                ####### Proses Interpolasi ASH\n",
    "                print(f\"Memulai Proses Interpolasi ASH Pulau Besar: {pulau_besar}\")\n",
    "\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_besar], mask=pulau_feature[pulau_besar]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features=input_data,\n",
    "                        z_field=\"SH_\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(fgdb_temp, f\"interpolasi_ASH_Pulau_{pulau_besar}_{year}{month}\"),\n",
    "                        cell_size=gridsize_pbesar,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "\n",
    "                raster_ash = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ASH_Pulau_{pulau_besar}_{year}{month}\"))\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Interpolasi ASH Pulau Besar: {pulau_besar} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "                ######### Proses Masking ASH\n",
    "                print(f\"Proses Masking ASH Pulau Besar: {pulau_besar} dimulai . . .\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                with arcpy.da.SearchCursor(pulau_besar_merge, [[\"Pulau\", [\"Provinsi_Singkat\"]]]) as masks:\n",
    "                    for r in masks:\n",
    "                        pulau_mask = r[0]\n",
    "                        provinsi = r[1]\n",
    "                        if pulau_mask == pulau_besar:\n",
    "                            print(f\"Memulai Mask ASH Provinsi: {provinsi}  . . .\")\n",
    "\n",
    "\n",
    "                            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                            output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                        output_tipe_periode=output_tipe_bln, tipe='TIFF', \n",
    "                                                        nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "\n",
    "\n",
    "                            Extract_rast_sh = os.path.join(output_loc_tiff, f\"ash_bln_{provinsi.lower()}_ver_{year}{month}.tif\")\n",
    "                            Extract_by_Mask = Extract_rast_sh\n",
    "                            Extract_rast_sh = arcpy.sa.ExtractByMask(raster_ash, pulau_feature[provinsi], \"INSIDE\", extent_pulau[provinsi])\n",
    "                            Extract_rast_sh.save(Extract_by_Mask)\n",
    "\n",
    "\n",
    "                            Extract_rast_sh_copy = os.path.join(raster_loc, f\"ash_bln_{provinsi.lower()}_ver_{year}{month}.tif\")\n",
    "\n",
    "                            copy_raster(Extract_rast_sh, Extract_rast_sh_copy)\n",
    "\n",
    "                            row_list = (Extract_rast_sh_copy, f'{provinsi}')\n",
    "\n",
    "                            raster_ASH_to_merge.append(row_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Proses Mask Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} dimulai . . .\")\n",
    "                            point_extracted_pb = os.path.join(fgdb_temp, f\"Titik_extract_{provinsi}_{year}{month}\")\n",
    "                            arcpy.sa.ExtractMultiValuesToPoints(point_extracted_pb, [[Extract_rast_sh, \"SH\"]], \"NONE\")\n",
    "                            arcpy.management.AddFields(in_table=point_extracted_pb, field_description=[[\"LAT\", \"DOUBLE\", \"Latitude\", \"\", \"\", \"\"], [\"LONG\", \"DOUBLE\", \"Longitude\", \"\", \"\", \"\"]])[0]\n",
    "                            arcpy.management.CalculateGeometryAttributes(in_features=point_extracted_pb, geometry_property=[[\"LAT\", \"POINT_Y\"], [\"LONG\", \"POINT_X\"]],coordinate_system=\"PROJCS[\\\"WGS_1984_Web_Mercator_Auxiliary_Sphere\\\",GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Mercator_Auxiliary_Sphere\\\"],PARAMETER[\\\"False_Easting\\\",0.0],PARAMETER[\\\"False_Northing\\\",0.0],PARAMETER[\\\"Central_Meridian\\\",0.0],PARAMETER[\\\"Standard_Parallel_1\\\",0.0],PARAMETER[\\\"Auxiliary_Sphere_Type\\\",0.0],UNIT[\\\"Meter\\\",1.0]]\", \n",
    "                                                                        coordinate_format=\"DD\")[0]\n",
    "                            # point_extracted_sh.save()\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} selesai\")\n",
    "\n",
    "                            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} dimulai . . .. \")\n",
    "                            # arcpy.management.AddRastersToMosaicDataset(\n",
    "                            #     in_mosaic_dataset= mosaic_bln_sh,\n",
    "                            #     raster_type=\"Raster Dataset\",\n",
    "                            #     input_path= Extract_rast_sh,\n",
    "                            #     update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                            #     update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                            #     update_overviews=\"NO_OVERVIEWS\",\n",
    "                            #     maximum_pyramid_levels=None,\n",
    "                            #     maximum_cell_size=0,\n",
    "                            #     minimum_dimension=1500,\n",
    "                            #     spatial_reference=None,\n",
    "                            #     filter=\"\",\n",
    "                            #     sub_folder=\"SUBFOLDERS\",\n",
    "                            #     duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                            #     build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                            #     calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                            #     build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                            #     operation_description=\"\",\n",
    "                            #     force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                            #     estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                            #     aux_inputs=None,\n",
    "                            #     enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                            #     )\n",
    "                            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} selesai \")\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Proses Export to csv Provinsi: {provinsi} dimulai . . .\")\n",
    "\n",
    "                            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                            output_loc_csv = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                    output_tipe_periode=output_tipe_bln, tipe='CSV', \n",
    "                                                                    nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                            out_csv_table_pb = os.path.join(output_loc_csv, f\"bln_{provinsi.lower()}_ver_{year}0{month}.csv\")\n",
    "                            arcpy.conversion.ExportTable(\n",
    "                                in_table= point_extracted_pb,\n",
    "                                out_table= out_csv_table_pb,\n",
    "                                where_clause=\"\",\n",
    "                                use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "                                field_mapping=None,\n",
    "                                sort_field=None)\n",
    "\n",
    "                            # Menggabungkan ke dalam list csv untuk di merge\n",
    "                            CSV_to_merge.append(out_csv_table_pb)\n",
    "                            print(f\"Proses Export to csv Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Memulai Reclassify Provinsi: {provinsi}  . . .\")\n",
    "                            out_raster_ash_pb = arcpy.sa.Reclassify(in_raster=Extract_rast_sh,\n",
    "                                                            reclass_field=\"VALUE\",\n",
    "                                                            remap=\"0 30 1;30 50 2;50 84 3;84 115 4;115 150 5;150 200 6;200 10000 7\",\n",
    "                                                            missing_values=\"DATA\")\n",
    "\n",
    "                            out_raster_ash_pb.save(os.path.join(fgdb_temp, f\"Reclass_ASH_{provinsi}_{year}{month}\"))\n",
    "                            print(f\"Proses Reclassify Provinsi: {provinsi} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} dimulai . . . . . . . . . . . .\")\n",
    "\n",
    "                            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                            output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                    output_tipe_periode=output_tipe_bln, tipe='SHP', \n",
    "                                                                    nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "\n",
    "                            Output_polygon_features_ash = os.path.join(fgdb_temp, f\"ash_bln_{provinsi}_ver_{year}{month}\")\n",
    "                            arcpy.conversion.RasterToPolygon(in_raster=out_raster_ash_pb, out_polygon_features=Output_polygon_features_ash)\n",
    "                            arcpy.management.AddFields(in_table=Output_polygon_features_ash, field_description= \"SH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"SH\",\n",
    "                                        expression=\"sh(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def sh(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"0-30\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"31-50\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"51-84\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"85-115\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"116-150\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"151-200\"\n",
    "                                        elif x == 7:\n",
    "                                            return \">200\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"Kategori\",\n",
    "                                        expression=\"kategori(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def kategori(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"Normal\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"Periode\",\n",
    "                                        expression=f'\"{month_name} {year}\"',\n",
    "                                        expression_type=\"PYTHON3\"\n",
    "                                    )\n",
    "                            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Informasi\",\n",
    "                                    expression='\"Sifat Hujan\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "\n",
    "                            poly_kec = poly_kecamatan[provinsi]\n",
    "\n",
    "\n",
    "                            Output_polygon_features_ash_union = os.path.join(output_loc_shp, f\"ash_bln_{provinsi.lower()}_ver_{year}{month}\")\n",
    "                            arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ach], \n",
    "                                        out_feature_class= Output_polygon_features_ash_union)\n",
    "\n",
    "                            arcpy.management.AddField(\n",
    "                                        in_table=Output_polygon_features_ash_union,\n",
    "                                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                            arcpy.management.CalculateGeometryAttributes(\n",
    "                                    in_features=Output_polygon_features_ash_union,\n",
    "                                    geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                                    area_unit=\"HECTARES\")\n",
    "\n",
    "                            # Menggabungkan output polygon untuk di merge\n",
    "                            ASH_to_merge.append(Output_polygon_features_ash)\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} telah selesai\")\n",
    "                            print(\"\\n\")\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "# Proses se Indonesia \n",
    "#Mosaic CH\n",
    "\n",
    "print(\"Proses Update Mosaic Dataset ACH: Indonesia dimulai . . .\")\n",
    "\n",
    "mosaic_data_ch = os.getenv(\"MOSAIC_BLN_ACH\")\n",
    "\n",
    "for raster_path, area in raster_ACH_to_merge :\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_ch)\n",
    "\n",
    "delete_old_rasters(mosaic_data_ch)\n",
    "\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=mosaic_data_ch,\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\")\n",
    "print(\"Proses Update Mosaic Dataset ACH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Proses Update Mosaic Dataset ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "\n",
    "mosaic_data_sh = os.getenv(\"MOSAIC_BLN_ASH\")\n",
    "\n",
    "for raster_path, area in raster_ASH_to_merge :\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_sh)\n",
    "\n",
    "delete_old_rasters(mosaic_data_sh)\n",
    "\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=mosaic_data_sh,\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\")\n",
    "print(\"Proses Update Mosaic Dataset ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Proses Update Mosaic Dataset ACH: Indonesia dimulai . . .\")\n",
    "# # Re-Calculate Statistic Mosaic Dataset\n",
    "# arcpy.management.CalculateStatistics(\n",
    "#     in_raster_dataset=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_CH\",\n",
    "#     x_skip_factor=1,\n",
    "#     y_skip_factor=1,\n",
    "#     ignore_values=[],\n",
    "#     skip_existing=\"OVERWRITE\",\n",
    "#     area_of_interest=r\"in_memory\\feature_set1\")\n",
    "# print(\"Proses Update Mosaic Dataset ACH: Indonesia selesai\")\n",
    "# print(\"\\n\")\n",
    "\n",
    "\n",
    "# print(\"Proses Update Mosaic Dataset ASH: Indonesia dimulai . . .\")\n",
    "# arcpy.management.CalculateStatistics(\n",
    "#     in_raster_dataset=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_SH\",\n",
    "#     x_skip_factor=1,\n",
    "#     y_skip_factor=1,\n",
    "#     ignore_values=[],\n",
    "#     skip_existing=\"OVERWRITE\",\n",
    "#     area_of_interest=r\"in_memory\\feature_set1\")\n",
    "# print(\"Proses Update Mosaic Dataset ASH: Indonesia selesai\")\n",
    "# print(\"\\n\")\n",
    "\n",
    "print(\"Proses Merge Raster ACH dan ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "output_loc_tiff = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_bln, tipe='TIFF')\n",
    "\n",
    "\n",
    "arcpy.MosaicToNewRaster_management(\n",
    "    input_rasters=raster_ACH_to_merge,\n",
    "    output_location=output_loc_tiff,  # Direktori output\n",
    "    raster_dataset_name_with_extension=f\"ach_bln_indo_ver_{year}{month}.tif\",\n",
    "    coordinate_system_for_the_raster=None,  # Sistem koordinat, bisa None untuk menggunakan sistem koordinat raster input\n",
    "    pixel_type=\"32_BIT_FLOAT\",\n",
    "    cellsize=None,\n",
    "    number_of_bands=1,\n",
    "    mosaic_method=\"MEAN\" ,\n",
    "    mosaic_colormap_mode=\"FIRST\"  # Mode kolormap, bisa \"FIRST\", \"LAST\", \"MATCH\", dll.\n",
    "    )\n",
    "\n",
    "arcpy.MosaicToNewRaster_management(\n",
    "    input_rasters=raster_ASH_to_merge,\n",
    "    output_location=output_loc_tiff,  # Direktori output\n",
    "    raster_dataset_name_with_extension= f\"ash_bln_indo_ver_{year}{month}.tif\",\n",
    "    coordinate_system_for_the_raster=None,  # Sistem koordinat, bisa None untuk menggunakan sistem koordinat raster input\n",
    "    pixel_type=\"32_BIT_FLOAT\",\n",
    "    cellsize=None,\n",
    "    number_of_bands=1,\n",
    "    mosaic_method=\"MEAN\" ,\n",
    "    mosaic_colormap_mode=\"FIRST\"  # Mode kolormap, bisa \"FIRST\", \"LAST\", \"MATCH\", dll.\n",
    "    )\n",
    "\n",
    "print(\"Proses Merge Raster ACH dan ASH: Indonesia selesai\")\n",
    "\n",
    "\n",
    "print(\"Proses Merge Polygon ACH dan ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "#Membuat archiving\n",
    "pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "output_loc_shp = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_bln, tipe='SHP')\n",
    "\n",
    "\n",
    "# Merge polygon menjadi se Indonesia\n",
    "kec_indo = os.getenv(\"POLY_KEC\")\n",
    "arcpy.management.Merge(ACH_to_merge, os.path.join(fgdb_temp, f\"ach_bln_indo_ver_{year}{month}\"))\n",
    "poly_indo_ach = os.path.join(output_loc_shp, f\"ach_bln_indo_ver_{year}{month}\")\n",
    "arcpy.analysis.Union(in_features=[kec_indo, os.path.join(fgdb_temp, f\"ach_bln_indo_ver_{year}{month}\")], \n",
    "                                    out_feature_class=poly_indo_ach)\n",
    "\n",
    "arcpy.management.AddField(\n",
    "                        in_table=poly_indo_ach,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "            \n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "        in_features=poly_indo_ach,\n",
    "        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "        area_unit=\"HECTARES\")\n",
    "\n",
    "folder_layout = os.getenv(\"FOLDER_LAYOUT\")\n",
    "\n",
    "arcpy.CopyFeatures_management(poly_indo_ach, os.path.join(folder_layout, 'polygon_ach_bln'))\n",
    "\n",
    "\n",
    "arcpy.management.Merge(ASH_to_merge, os.path.join(fgdb_temp, f\"ash_bln_indo_ver_{year}{month}\"))\n",
    "poly_indo_ash = os.path.join(output_loc_shp, f\"ash_bln_indo_ver_{year}{month}\")\n",
    "arcpy.analysis.Union(in_features=[kec_indo, os.path.join(fgdb_temp, f\"ash_bln_indo_ver_{year}{month}\")], \n",
    "                                    out_feature_class= poly_indo_ash)\n",
    "arcpy.management.AddField(\n",
    "                        in_table=poly_indo_ash,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "            \n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "        in_features=poly_indo_ash,\n",
    "        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "        area_unit=\"HECTARES\")\n",
    "\n",
    "folder_layout = os.getenv(\"FOLDER_LAYOUT\")\n",
    "\n",
    "arcpy.CopyFeatures_management(poly_indo_ash, os.path.join(folder_layout, 'polygon_ash_bln'))\n",
    "\n",
    "print(\"Proses Merge Polygon ACH dan ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Proses Merge CSV ACH dan ASH: Indonesia dimulai . . .\")\n",
    "#Mmebuiat archive\n",
    "output_loc_csv = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_bln, tipe='CSV')\n",
    "\n",
    "# Merge csv se Indonesia\n",
    "combined_df = pd.DataFrame()\n",
    "for file in CSV_to_merge:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file, delimiter=';')\n",
    "    # Append the DataFrame to the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "combined_df.to_csv(os.path.join(output_loc_csv, f\"bln_indo_ver_{year}{month}.csv\"), index=False)\n",
    "print(\"Proses Merge CSV ACH dan ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"PROSES ANALISA BULANAN SELESAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "\n",
    "def add_raster_and_update_fields(raster_path, area, mosaic_data):\n",
    "    # Check if the area is 'Lampung' and stop the script if true\n",
    "\n",
    "    # Add the raster to the mosaic dataset\n",
    "    arcpy.management.AddRastersToMosaicDataset(\n",
    "        in_mosaic_dataset=mosaic_data,\n",
    "        raster_type=\"Raster Dataset\",\n",
    "        input_path=raster_path,\n",
    "        update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "        update_boundary=\"UPDATE_BOUNDARY\",\n",
    "        update_overviews=\"NO_OVERVIEWS\",\n",
    "        maximum_pyramid_levels=None,\n",
    "        maximum_cell_size=0,\n",
    "        minimum_dimension=1500,\n",
    "        spatial_reference=None,\n",
    "        filter=\"\",\n",
    "        sub_folder=\"SUBFOLDERS\",\n",
    "        duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "        build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "        calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "        build_thumbnails=\"NO_THUMBNAILS\",\n",
    "        operation_description=\"\",\n",
    "        force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "        estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "        aux_inputs=None,\n",
    "        enable_pixel_cache=\"NO_PIXEL_CACHE\"\n",
    "    )\n",
    "    \n",
    "    # Get the current date in the format YYYY-MM-DD\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "#     current_date = '25/10/2024'\n",
    "    \n",
    "    # Add a unique identifier using timestamp down to microseconds\n",
    "    unique_id = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "    \n",
    "    # Find the highest OBJECTID to identify the newly added raster\n",
    "    max_objectid = None\n",
    "    with arcpy.da.SearchCursor(mosaic_data, [\"objectid\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            if max_objectid is None or row[0] > max_objectid:\n",
    "                max_objectid = row[0]\n",
    "\n",
    "    # Update the fields for the newly added raster\n",
    "    with arcpy.da.UpdateCursor(mosaic_data, [\"objectid\", \"uniqueid\", \"area_upt\", \"date\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] == max_objectid:\n",
    "                row[1] = unique_id\n",
    "                row[2] = area\n",
    "                row[3] = current_date\n",
    "                cursor.updateRow(row)\n",
    "\n",
    "   \n",
    "\n",
    "    print(f\"Berhasil menambahkan {area}\")\n",
    "\n",
    "\n",
    "\n",
    "def delete_old_rasters(mosaic_data):\n",
    "    # Calculate the date two months ago from today\n",
    "    two_months_ago = datetime.now() - timedelta(days=60)\n",
    "    \n",
    "    # Use an UpdateCursor to delete rasters older than two months\n",
    "    with arcpy.da.UpdateCursor(mosaic_data, [\"OBJECTID\", \"date\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            # Check if row[1] is already a datetime object\n",
    "            if isinstance(row[1], datetime):\n",
    "                raster_date = row[1]\n",
    "            else:\n",
    "                raster_date = datetime.strptime(row[1], \"%Y-%m-%d\")\n",
    "            \n",
    "            if raster_date < two_months_ago:\n",
    "                cursor.deleteRow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, area in raster_ACH_to_merge:\n",
    "    print(path, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mosaic_data_ch = r'F:\\SIPINTAR-IKLIM-BMKG-PROSES2\\EGDB\\sde@geodb_bmkg.sde\\geodb_bmkg.sde.mosaic_pch_bulanan'\n",
    "\n",
    "for raster_path, area in raster_ACH_to_merge :\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_ch)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sde_connection = r\"F:\\SIPINTAR-IKLIM-BMKG-PROSES2\\EGDB\\sde@geodb_bmkg.sde\"\n",
    "mosaic_dataset = r'{}\\geodb_bmkg.sde.mosaic_ach_bulanan'.format(sde_connection)\n",
    "\n",
    "arcpy.env.workspace=sde_connection\n",
    "\n",
    "try:\n",
    "    # Ensure the mosaic dataset exists\n",
    "    if arcpy.Exists(mosaic_dataset):\n",
    "        print(f\"Mosaic dataset found: {mosaic_dataset}\")\n",
    "    else:\n",
    "        print(f\"Mosaic dataset not found: {mosaic_dataset}\")\n",
    "        \n",
    "except arcpy.ExecuteError as e:\n",
    "    print(f\"ArcPy Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"General Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F:\\ASSET\\spatial\\BMKG_PinterIklim\\PostgreSQL-gisdbiklim-geodb_bmkg(sde).sde\\geodb_bmkg.sde.mosaic_ach_bulanan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "from config import extent_pulau, pulau_feature, titik_grid, nama_prov, poly_kecamatan, nama_prov_folder\n",
    "from utils.proses1_raster_mosaic import copy_raster, add_raster_and_update_fields, delete_old_rasters\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "import arcgis\n",
    "from arcgis.features import GeoAccessor\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import locale\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set time for dataset\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "\n",
    "# Set parameter\n",
    "gridsize_pkecil = os.getenv(\"GRID_PKECIL\")\n",
    "gridsize_pbesar= os.getenv(\"GRID_PBESAR\")\n",
    "\n",
    "\n",
    "# Set folder structure\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "output_level_ind = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA_BULANAN'\n",
    "output_tipe_das = 'ANALISA_DASARIAN'\n",
    "\n",
    "\n",
    "\n",
    "# All output folder path Bulanan - Prov\n",
    "output_prov = os.path.join(output_folder, output_level_prov)\n",
    "\n",
    "\n",
    "# Set file to loop code\n",
    "pulau_reference = os.getenv(\"PULAU_REFERENCE\")\n",
    "pulau_besar_merge = os.getenv(\"PULAU_BESAR_MERGE\")\n",
    "\n",
    "\n",
    "# Set data for I/O\n",
    "raster_loc = os.getenv(\"RASTER_LOC\")\n",
    "fgdb_input = os.getenv(\"FGDB_TEMP\")\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "mosaic_bln_ch= os.getenv(\"MOSAIC_BLN_ACH\")\n",
    "mosaic_bln_sh= os.getenv(\"MOSAIC_BLN_ASH\")\n",
    "mosaic_das_ch= os.getenv(\"MOSAIC_DAS_ACH\")\n",
    "mosaic_das_sh= os.getenv(\"MOSAIC_DAS_ASH\")\n",
    "main_output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "input_data_bln = os.path.join(fgdb_temp, 'output_2_proses1_feature_point_bln')\n",
    "input_data = os.path.join(fgdb_temp, 'output_2_proses1_feature_point_das')\n",
    "\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"PROSES ANALISA DASARIAN DIMULAI . . .\")\n",
    "    \n",
    "raster_ACH_to_merge = []\n",
    "raster_ASH_to_merge = []\n",
    "raster_ACH_to_merge_tif = []\n",
    "raster_ASH_to_merge_tif = []\n",
    "ACH_to_merge = []\n",
    "ASH_to_merge = []\n",
    "CSV_to_merge = []\n",
    "\n",
    "poly_indo_ach = None\n",
    "poly_indo_ash = None\n",
    "\n",
    "\n",
    "with arcpy.da.SearchCursor(pulau_reference, [[\"Pulau_Singkat\", [\"Is_Besar\"]]]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "    \n",
    "        if r[1] == \"False\":  # val False = Pulau Kecil dan va True = Pulau Besar\n",
    "            pulau_kecil = r[0]\n",
    "            print(f\"Memulai Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "\n",
    "            ####### Proses untuk kategori pulau kecil\\\n",
    "            ####### Proses ACH untuk kategori pulau kecil\n",
    "            # Create new folder\n",
    "\n",
    "            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "            output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_das, tipe='TIFF', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "\n",
    "            # Start Process\n",
    "\n",
    "            with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                arcpy.ga.IDW(\n",
    "                    in_features= input_data,\n",
    "                    z_field=\"CH\",\n",
    "                    out_ga_layer=None,\n",
    "                    out_raster=os.path.join(output_loc_tiff, f\"ach_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\"),\n",
    "                    cell_size=gridsize_pkecil,\n",
    "                    power=2,\n",
    "                    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                    weight_field=None\n",
    "                )\n",
    "            raster_ach_pk = arcpy.Raster(os.path.join(output_loc_tiff, f\"ach_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\"))\n",
    "            raster_ach_pk_copy = os.path.join(raster_loc, f\"ach_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "\n",
    "            copy_raster(raster_ach_pk, raster_ach_pk_copy)\n",
    "\n",
    "            row_list = (raster_ach_pk_copy, f'{pulau_kecil}')\n",
    "\n",
    "            raster_ACH_to_merge.append(row_list)\n",
    "\n",
    "\n",
    "            raster_ACH_to_merge_tif.append(raster_ach_pk)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "            # arcpy.management.AddRastersToMosaicDataset(\n",
    "            #                 in_mosaic_dataset= mosaic_bln_ch,\n",
    "            #                 raster_type=\"Raster Dataset\",\n",
    "            #                 input_path= raster_ach_pk,\n",
    "            #                 update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "            #                 update_boundary=\"UPDATE_BOUNDARY\",\n",
    "            #                 update_overviews=\"NO_OVERVIEWS\",\n",
    "            #                 maximum_pyramid_levels=None,\n",
    "            #                 maximum_cell_size=0,\n",
    "            #                 minimum_dimension=1500,\n",
    "            #                 spatial_reference=None,\n",
    "            #                 filter=\"\",\n",
    "            #                 sub_folder=\"SUBFOLDERS\",\n",
    "            #                 duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "            #                 build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "            #                 calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "            #                 build_thumbnails=\"NO_THUMBNAILS\",\n",
    "            #                 operation_description=\"\",\n",
    "            #                 force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "            #                 estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "            #                 aux_inputs=None,\n",
    "            #                 enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "            #                 cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "            print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai ...\")\n",
    "\n",
    "            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "            output_loc_csv = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_das, tipe='CSV', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "\n",
    "\n",
    "            titik_grid_extract_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}das0{current_dasarian}\")\n",
    "            arcpy.management.CopyFeatures(in_features=titik_grid[pulau_kecil], out_feature_class=titik_grid_extract_pk)\n",
    "            point_extracted_pk = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pk, [[raster_ach_pk, \"CH\"]], \"NONE\")\n",
    "            # point_extracted_ch.save()\n",
    "            print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Reclassify ACH Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "            out_raster_ach_pk = arcpy.sa.Reclassify(\n",
    "                in_raster=raster_ach_pk,\n",
    "                reclass_field=\"VALUE\",\n",
    "                remap=\"0 10 1;10 20 2;20 50 3;50 75 4;75 100 5;100 150 6;150 200 7;200 300 8;300 10000 9\",\n",
    "                missing_values=\"DATA\")\n",
    "\n",
    "            out_raster_ach_pk.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{pulau_kecil}_{year}{month}das0{current_dasarian}\"))\n",
    "            print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "            # Pembuatan archive\n",
    "            output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_das, tipe='SHP', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "            Output_polygon_features_ach = os.path.join(fgdb_temp, f\"ach_das_{pulau_kecil}_ver_{year}{month}das0{current_dasarian}\")\n",
    "            arcpy.conversion.RasterToPolygon(in_raster=out_raster_ach_pk, out_polygon_features=Output_polygon_features_ach)\n",
    "            arcpy.management.AddFields(in_table=Output_polygon_features_ach, field_description= \"CH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "            arcpy.management.CalculateField(\n",
    "                        in_table=Output_polygon_features_ach,\n",
    "                        field=\"CH\",\n",
    "                        expression=\"ch(!gridcode!)\",\n",
    "                        expression_type=\"PYTHON3\",\n",
    "                        code_block=\"\"\"def ch(x):\n",
    "                        if x == 1:\n",
    "                            return \"0-10\"\n",
    "                        elif x == 2:\n",
    "                            return \"11-20\"\n",
    "                        elif x == 3:\n",
    "                            return \"21-50\"\n",
    "                        elif x == 4:\n",
    "                            return \"51-75\"\n",
    "                        elif x == 5:\n",
    "                            return \"76-100\"\n",
    "                        elif x == 6:\n",
    "                            return \"101-150\"\n",
    "                        elif x == 7:\n",
    "                            return \"151-200\"\n",
    "                        elif x == 8:\n",
    "                            return \"201-300\"\n",
    "                        elif x ==9 :\n",
    "                            return \">300\"\n",
    "                        \"\"\",\n",
    "                        field_type=\"TEXT\",\n",
    "                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "            arcpy.management.CalculateField(\n",
    "                        in_table=Output_polygon_features_ach,\n",
    "                        field=\"Kategori\",\n",
    "                        expression=\"cat(!gridcode!)\",\n",
    "                        expression_type=\"PYTHON3\",\n",
    "                        code_block=\"\"\"def cat(x):\n",
    "                        if x == 1:\n",
    "                            return \"Rendah\"\n",
    "                        elif x == 2:\n",
    "                            return \"Rendah\"\n",
    "                        elif x == 3:\n",
    "                            return \"Rendah\"\n",
    "                        elif x == 4:\n",
    "                            return \"Menengah\"\n",
    "                        elif x == 5:\n",
    "                            return \"Menengah\"\n",
    "                        elif x == 6:\n",
    "                            return \"Menengah\"\n",
    "                        elif x == 7:\n",
    "                            return \"Tinggi\"\n",
    "                        elif x == 8:\n",
    "                            return \"Sangat Tinggi\"\n",
    "                        elif x ==9 :\n",
    "                            return \"Sangat Tinggi\"\n",
    "                        \"\"\",\n",
    "                        field_type=\"TEXT\",\n",
    "                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"Periode\",\n",
    "                                    expression=f'\"Dasarian {current_dasarian} {month_name} {year}\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "            arcpy.management.CalculateField(\n",
    "                                in_table=Output_polygon_features_ach,\n",
    "                                field=\"Informasi\",\n",
    "                                expression='\"Curah Hujan\"',\n",
    "                                expression_type=\"PYTHON3\"\n",
    "                            )\n",
    "\n",
    "            poly_kec = poly_kecamatan[pulau_kecil]\n",
    "\n",
    "            Output_polygon_features_ach_union = os.path.join(output_loc_shp, f\"ach_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}\")\n",
    "            arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ach], \n",
    "                                 out_feature_class=Output_polygon_features_ach_union)\n",
    "\n",
    "\n",
    "            arcpy.management.AddField(\n",
    "                        in_table=Output_polygon_features_ach_union,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "            arcpy.management.CalculateGeometryAttributes(\n",
    "                    in_features=Output_polygon_features_ach_union,\n",
    "                    geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                    area_unit=\"HECTARES\")\n",
    "\n",
    "\n",
    "\n",
    "            # Menggabungkan polygon untuk di merge\n",
    "            ACH_to_merge.append(Output_polygon_features_ach)\n",
    "            print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            ####### Proses ASH untuk kategori pulau kecil\n",
    "            print(f\"Memulai Proses Interpolasi ASH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "            with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                arcpy.ga.IDW(\n",
    "                    in_features=input_data,\n",
    "                    z_field=\"SH_\",\n",
    "                    out_ga_layer=None,\n",
    "                    out_raster=os.path.join(output_loc_tiff, f\"ash_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\"),\n",
    "                    cell_size=gridsize_pkecil,\n",
    "                    power=2,\n",
    "                    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                    weight_field=None\n",
    "                )\n",
    "\n",
    "            raster_ash_pk = arcpy.Raster(os.path.join(output_loc_tiff, f\"ash_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\"))\n",
    "\n",
    "            raster_ash_pk_copy = os.path.join(raster_loc, f\"ash_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "\n",
    "            copy_raster(raster_ash_pk, raster_ash_pk_copy)\n",
    "\n",
    "            row_list = (raster_ash_pk_copy, f'{pulau_kecil}')\n",
    "\n",
    "            raster_ASH_to_merge.append(row_list)\n",
    "\n",
    "            raster_ASH_to_merge_tif.append(raster_ash_pk)\n",
    "\n",
    "\n",
    "            print(f\"Proses Interpolasi ASH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "            # arcpy.management.AddRastersToMosaicDataset(\n",
    "            #                 in_mosaic_dataset= mosaic_bln_sh,\n",
    "            #                 raster_type=\"Raster Dataset\",\n",
    "            #                 input_path= raster_ash_pk,\n",
    "            #                 update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "            #                 update_boundary=\"UPDATE_BOUNDARY\",\n",
    "            #                 update_overviews=\"NO_OVERVIEWS\",\n",
    "            #                 maximum_pyramid_levels=None,\n",
    "            #                 maximum_cell_size=0,\n",
    "            #                 minimum_dimension=1500,\n",
    "            #                 spatial_reference=None,\n",
    "            #                 filter=\"\",\n",
    "            #                 sub_folder=\"SUBFOLDERS\",\n",
    "            #                 duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "            #                 build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "            #                 calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "            #                 build_thumbnails=\"NO_THUMBNAILS\",\n",
    "            #                 operation_description=\"\",\n",
    "            #                 force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "            #                 estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "            #                 aux_inputs=None,\n",
    "            #                 enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "            #                 cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_SH\")\n",
    "            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai . . .\")\n",
    "            point_extracted_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}das0{current_dasarian}\")\n",
    "            arcpy.sa.ExtractMultiValuesToPoints(point_extracted_pk, [[raster_ash_pk, \"SH\"]], \"NONE\")\n",
    "            # point_extracted_sh.save()\n",
    "            arcpy.management.AddFields(in_table=point_extracted_pk, field_description=[[\"LAT\", \"DOUBLE\", \"Latitude\", \"\", \"\", \"\"], [\"LONG\", \"DOUBLE\", \"Longitude\", \"\", \"\", \"\"]])[0]\n",
    "            arcpy.management.CalculateGeometryAttributes(in_features=point_extracted_pk, geometry_property=[[\"LAT\", \"POINT_Y\"], [\"LONG\", \"POINT_X\"]], coordinate_system=\"PROJCS[\\\"WGS_1984_Web_Mercator_Auxiliary_Sphere\\\",GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Mercator_Auxiliary_Sphere\\\"],PARAMETER[\\\"False_Easting\\\",0.0],PARAMETER[\\\"False_Northing\\\",0.0],PARAMETER[\\\"Central_Meridian\\\",0.0],PARAMETER[\\\"Standard_Parallel_1\\\",0.0],PARAMETER[\\\"Auxiliary_Sphere_Type\\\",0.0],UNIT[\\\"Meter\\\",1.0]]\", \n",
    "                                                                    coordinate_format=\"DD\")[0]\n",
    "            print(f\"Proses Extract Point Provinsi: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Export to csv Provinsi: {pulau_kecil} dimulai . . .\")\n",
    "            out_csv_table_pk = os.path.join(output_loc_csv, f\"das_{pulau_kecil.lower()}_ver_{year}0{month}das0{current_dasarian}.csv\")\n",
    "            arcpy.conversion.ExportTable(\n",
    "                            in_table= point_extracted_pk,\n",
    "                            out_table= out_csv_table_pk,\n",
    "                            where_clause=\"\",\n",
    "                            use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "                            field_mapping=None,\n",
    "                            sort_field=None)\n",
    "\n",
    "            # Menggabungkan csv untuk di merge\n",
    "            CSV_to_merge.append(out_csv_table_pk)\n",
    "            print(f\"Proses Export to csv Provinsi: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "            print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "            out_raster_ash_pk = arcpy.sa.Reclassify(\n",
    "                in_raster=raster_ash_pk,\n",
    "                reclass_field=\"VALUE\",\n",
    "                remap=\"0 30 1;30 50 2;50 84 3;84 115 4;115 150 5;150 200 6;200 10000 7\",\n",
    "                missing_values=\"DATA\")\n",
    "\n",
    "            out_raster_ash_pk.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{pulau_kecil}_{year}{month}das0{current_dasarian}\"))\n",
    "            print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "            Output_polygon_features_ash = os.path.join(fgdb_temp, f\"ash_das_{pulau_kecil}_ver_{year}{month}das0{current_dasarian}\")\n",
    "            arcpy.conversion.RasterToPolygon(in_raster=out_raster_ash_pk, out_polygon_features=Output_polygon_features_ash)\n",
    "            arcpy.management.AddFields(in_table=Output_polygon_features_ash, field_description= \"SH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"SH\",\n",
    "                                    expression=\"sh(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def sh(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"0-30\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"31-50\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"51-84\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"85-115\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"116-150\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"151-200\"\n",
    "                                    elif x == 7:\n",
    "                                        return \">200\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Kategori\",\n",
    "                                    expression=\"kategori(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def kategori(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"Normal\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    elif x == 7:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Periode\",\n",
    "                                    expression=f'\"Dasarian {current_dasarian} {month_name} {year}\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "            arcpy.management.CalculateField(\n",
    "                                in_table=Output_polygon_features_ash,\n",
    "                                field=\"Informasi\",\n",
    "                                expression='\"Sifat Hujan\"',\n",
    "                                expression_type=\"PYTHON3\"\n",
    "                            )\n",
    "\n",
    "\n",
    "            poly_kec = poly_kecamatan[pulau_kecil]\n",
    "\n",
    "            Output_polygon_features_ash_union = os.path.join(output_loc_shp, f\"ash_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}\")\n",
    "            arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ash], \n",
    "                                 out_feature_class=Output_polygon_features_ash_union)\n",
    "\n",
    "            arcpy.management.AddField(\n",
    "                        in_table=Output_polygon_features_ash_union,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "            arcpy.management.CalculateGeometryAttributes(\n",
    "                    in_features=Output_polygon_features_ash_union,\n",
    "                    geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                    area_unit=\"HECTARES\")\n",
    "\n",
    "\n",
    "\n",
    "            # menggabungkan polygon untuk di merge\n",
    "            ASH_to_merge.append(Output_polygon_features_ash)\n",
    "            print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "        ####### Proses untuk kategori pulau besar\n",
    "        ####### Proses ACH Pulau Besar\n",
    "        else:\n",
    "            pulau_besar = r[0]\n",
    "            print(f\"Memulai Proses Interpolasi ACH Pulau Besar: {pulau_besar} . . .\")\n",
    "            with arcpy.EnvManager(extent=extent_pulau[pulau_besar], mask=pulau_feature[pulau_besar]):\n",
    "                arcpy.ga.IDW(\n",
    "                    in_features=input_data,\n",
    "                    z_field=\"CH\",\n",
    "                    out_ga_layer=None,\n",
    "                    out_raster=os.path.join(fgdb_temp, f\"interpolasi_ACH_Pulau_{pulau_besar}_{year}{month}das0{current_dasarian}\"),\n",
    "                    cell_size=gridsize_pbesar,\n",
    "                    power=2,\n",
    "                    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                    weight_field=None\n",
    "                )\n",
    "            raster_ach_pb = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ACH_Pulau_{pulau_besar}_{year}{month}das0{current_dasarian}\"))\n",
    "\n",
    "\n",
    "            raster_ACH_to_merge.append(raster_ach_pb)\n",
    "\n",
    "\n",
    "            print(f\"Proses Interpolasi ACH Pulau Besar: {pulau_besar} telah selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "            ######### Proses Masking ACH\n",
    "            print(f\"Proses Masking ACH Pulau Besar: {pulau_besar} dimulai . . .\")\n",
    "            with arcpy.da.SearchCursor(pulau_besar_merge, [[\"Pulau\", [\"Provinsi_Singkat\"]]]) as masks:\n",
    "                for r in masks:\n",
    "                    pulau_mask = r[0]\n",
    "                    provinsi = r[1]\n",
    "                    if pulau_mask == pulau_besar:\n",
    "                        print(f\"Memulai Mask Provinsi: {provinsi}  . . .\")\n",
    "\n",
    "                        # Membuat archive folder\n",
    "                        print(\"Membuat Archive\")\n",
    "                        pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                        output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_das, tipe='TIFF', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                        print(\"Selesai Archive\")\n",
    "\n",
    "\n",
    "                        Extract_rast_ch = os.path.join(output_loc_tiff, f\"ach_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "                        Extract_by_Mask = Extract_rast_ch\n",
    "                        Extract_rast_ch = arcpy.sa.ExtractByMask(raster_ach_pb, pulau_feature[provinsi], \"INSIDE\", extent_pulau[provinsi])\n",
    "                        Extract_rast_ch.save(Extract_by_Mask)\n",
    "\n",
    "                        Extract_rast_ch_copy = os.path.join(raster_loc, f\"ach_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "\n",
    "                        copy_raster(Extract_rast_ch, Extract_rast_ch_copy)\n",
    "\n",
    "                        row_list = (Extract_rast_ch_copy, f'{provinsi}')\n",
    "\n",
    "                        raster_ACH_to_merge.append(row_list)\n",
    "\n",
    "                        raster_ACH_to_merge_tif.append(Extract_rast_ch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Proses Mask Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                        # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} dimulai . . .. \")\n",
    "                        # arcpy.management.AddRastersToMosaicDataset(\n",
    "                        #     in_mosaic_dataset= mosaic_bln_ch,\n",
    "                        #     raster_type=\"Raster Dataset\",\n",
    "                        #     input_path= Extract_rast_ch,\n",
    "                        #     update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                        #     update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                        #     update_overviews=\"NO_OVERVIEWS\",\n",
    "                        #     maximum_pyramid_levels=None,\n",
    "                        #     maximum_cell_size=0,\n",
    "                        #     minimum_dimension=1500,\n",
    "                        #     spatial_reference=None,\n",
    "                        #     filter=\"\",\n",
    "                        #     sub_folder=\"SUBFOLDERS\",\n",
    "                        #     duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                        #     build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                        #     calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                        #     build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                        #     operation_description=\"\",\n",
    "                        #     force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                        #     estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                        #     aux_inputs=None,\n",
    "                        #     enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                        #     cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "                        # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} selesai \")\n",
    "\n",
    "\n",
    "                        print(f\"Proses Extract Point Provinsi: {provinsi} dimulai ...\")\n",
    "                        titik_grid_extract_pb = os.path.join(fgdb_temp, f\"Titik_extract_{provinsi}_{year}{month}das0{current_dasarian}\")\n",
    "                        arcpy.management.CopyFeatures(in_features=titik_grid[provinsi], out_feature_class=titik_grid_extract_pb)\n",
    "                        point_extracted_pb = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pb, [[Extract_rast_ch, \"CH\"]], \"NONE\")\n",
    "                        # point_extracted_ch.save()\n",
    "                        print(f\"Proses Extract Point Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Memulai Reclassify Provinsi: {provinsi}  . . .\")\n",
    "                        out_raster_ach_pb = arcpy.sa.Reclassify(in_raster=Extract_rast_ch,\n",
    "                                                        reclass_field=\"VALUE\",\n",
    "                                                        remap=\"0 10 1;10 20 2;20 50 3;50 75 4;75 100 5;100 150 6;150 200 7;200 300 8;300 10000 9\",\n",
    "                                                        missing_values=\"DATA\")\n",
    "\n",
    "                        out_raster_ach_pb.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{provinsi}_{year}{month}das0{current_dasarian}\"))\n",
    "                        print(f\"Proses Reclassify Provinsi: {provinsi} telah selesai\")\n",
    "\n",
    "\n",
    "                        print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} dimulai . . . . . . . . . . . .\")\n",
    "                        # Membuat archive folder\n",
    "                        pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                        output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_das, tipe='SHP', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                        Output_polygon_features_ach = os.path.join(fgdb_temp, f\"ach_das_{provinsi}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                        arcpy.conversion.RasterToPolygon(in_raster=out_raster_ach_pb, out_polygon_features=Output_polygon_features_ach)\n",
    "                        arcpy.management.AddFields(in_table=Output_polygon_features_ach, field_description= \"CH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"CH\",\n",
    "                                    expression=\"ch(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def ch(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"0-10\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"11-20\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"21-50\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"51-75\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"76-100\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"101-150\"\n",
    "                                    elif x == 7:\n",
    "                                        return \"151-200\"\n",
    "                                    elif x == 8:\n",
    "                                        return \"201-300\"\n",
    "                                    elif x ==9 :\n",
    "                                        return \">300\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"Kategori\",\n",
    "                                    expression=\"cat(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def cat(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"Rendah\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"Rendah\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"Rendah\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"Menengah\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"Menengah\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"Menengah\"\n",
    "                                    elif x == 7:\n",
    "                                        return \"Tinggi\"\n",
    "                                    elif x == 8:\n",
    "                                        return \"Sangat Tinggi\"\n",
    "                                    elif x ==9 :\n",
    "                                        return \"Sangat Tinggi\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"Periode\",\n",
    "                                    expression=f'\"Dasarian {current_dasarian} {month_name} {year}\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "                        arcpy.management.CalculateField(\n",
    "                                in_table=Output_polygon_features_ach,\n",
    "                                field=\"Informasi\",\n",
    "                                expression='\"Curah Hujan\"',\n",
    "                                expression_type=\"PYTHON3\"\n",
    "                            )\n",
    "\n",
    "                        poly_kec = poly_kecamatan[provinsi]\n",
    "\n",
    "                        Output_polygon_features_ach_union = os.path.join(output_loc_shp, f\"ach_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                        arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ach], \n",
    "                                 out_feature_class= Output_polygon_features_ach_union)\n",
    "\n",
    "\n",
    "                        arcpy.management.AddField(\n",
    "                                    in_table=Output_polygon_features_ach_union,\n",
    "                                    field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                        arcpy.management.CalculateGeometryAttributes(\n",
    "                                in_features=Output_polygon_features_ach_union,\n",
    "                                geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                                area_unit=\"HECTARES\")\n",
    "\n",
    "\n",
    "\n",
    "                        # Menggabungkan polygon untuk di merge\n",
    "                        ACH_to_merge.append(Output_polygon_features_ach)\n",
    "                        print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} telah selesai\")\n",
    "                        print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            ####### Proses ASH Pulau Besar\n",
    "            ####### Proses Interpolasi ASH\n",
    "            print(f\"Memulai Proses Interpolasi ASH Pulau Besar: {pulau_besar}\")\n",
    "\n",
    "            with arcpy.EnvManager(extent=extent_pulau[pulau_besar], mask=pulau_feature[pulau_besar]):\n",
    "                arcpy.ga.IDW(\n",
    "                    in_features=input_data,\n",
    "                    z_field=\"SH_\",\n",
    "                    out_ga_layer=None,\n",
    "                    out_raster=os.path.join(fgdb_temp, f\"interpolasi_ASH_Pulau_{pulau_besar}_{year}{month}das0{current_dasarian}\"),\n",
    "                    cell_size=gridsize_pbesar,\n",
    "                    power=2,\n",
    "                    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                    weight_field=None\n",
    "                )\n",
    "\n",
    "            raster_ash = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ASH_Pulau_{pulau_besar}_{year}{month}das0{current_dasarian}\"))\n",
    "\n",
    "            raster_ASH_to_merge.append(raster_ash)\n",
    "\n",
    "            print(f\"Proses Interpolasi ASH Pulau Besar: {pulau_besar} telah selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "            ######### Proses Masking ASH\n",
    "            print(f\"Proses Masking ASH Pulau Besar: {pulau_besar} dimulai . . .\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            with arcpy.da.SearchCursor(pulau_besar_merge, [[\"Pulau\", [\"Provinsi_Singkat\"]]]) as masks:\n",
    "                for r in masks:\n",
    "                    pulau_mask = r[0]\n",
    "                    provinsi = r[1]\n",
    "                    if pulau_mask == pulau_besar:\n",
    "                        print(f\"Memulai Mask ASH Provinsi: {provinsi}  . . .\")\n",
    "\n",
    "\n",
    "                        pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                        output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                    output_tipe_periode=output_tipe_das, tipe='TIFF', \n",
    "                                                    nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "\n",
    "\n",
    "                        Extract_rast_sh = os.path.join(output_loc_tiff, f\"ash_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "                        Extract_by_Mask = Extract_rast_sh\n",
    "                        Extract_rast_sh = arcpy.sa.ExtractByMask(raster_ash, pulau_feature[provinsi], \"INSIDE\", extent_pulau[provinsi])\n",
    "                        Extract_rast_sh.save(Extract_by_Mask)\n",
    "\n",
    "\n",
    "                        Extract_rast_sh_copy = os.path.join(raster_loc, f\"ash_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "\n",
    "                        copy_raster(Extract_rast_sh, Extract_rast_sh_copy)\n",
    "\n",
    "                        row_list = (Extract_rast_sh_copy, f'{provinsi}')\n",
    "\n",
    "                        raster_ASH_to_merge.append(row_list)\n",
    "\n",
    "                        raster_ASH_to_merge_tif.append(Extract_rast_sh)\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Proses Mask Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "                        print(f\"Proses Extract Point Provinsi: {provinsi} dimulai . . .\")\n",
    "                        point_extracted_pb = os.path.join(fgdb_temp, f\"Titik_extract_{provinsi}_{year}{month}das0{current_dasarian}\")\n",
    "                        arcpy.sa.ExtractMultiValuesToPoints(point_extracted_pb, [[Extract_rast_sh, \"SH\"]], \"NONE\")\n",
    "                        arcpy.management.AddFields(in_table=point_extracted_pb, field_description=[[\"LAT\", \"DOUBLE\", \"Latitude\", \"\", \"\", \"\"], [\"LONG\", \"DOUBLE\", \"Longitude\", \"\", \"\", \"\"]])[0]\n",
    "                        arcpy.management.CalculateGeometryAttributes(in_features=point_extracted_pb, geometry_property=[[\"LAT\", \"POINT_Y\"], [\"LONG\", \"POINT_X\"]],coordinate_system=\"PROJCS[\\\"WGS_1984_Web_Mercator_Auxiliary_Sphere\\\",GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Mercator_Auxiliary_Sphere\\\"],PARAMETER[\\\"False_Easting\\\",0.0],PARAMETER[\\\"False_Northing\\\",0.0],PARAMETER[\\\"Central_Meridian\\\",0.0],PARAMETER[\\\"Standard_Parallel_1\\\",0.0],PARAMETER[\\\"Auxiliary_Sphere_Type\\\",0.0],UNIT[\\\"Meter\\\",1.0]]\", \n",
    "                                                                    coordinate_format=\"DD\")[0]\n",
    "                        # point_extracted_sh.save()\n",
    "                        print(f\"Proses Extract Point Provinsi: {provinsi} selesai\")\n",
    "\n",
    "                        # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} dimulai . . .. \")\n",
    "                        # arcpy.management.AddRastersToMosaicDataset(\n",
    "                        #     in_mosaic_dataset= mosaic_bln_sh,\n",
    "                        #     raster_type=\"Raster Dataset\",\n",
    "                        #     input_path= Extract_rast_sh,\n",
    "                        #     update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                        #     update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                        #     update_overviews=\"NO_OVERVIEWS\",\n",
    "                        #     maximum_pyramid_levels=None,\n",
    "                        #     maximum_cell_size=0,\n",
    "                        #     minimum_dimension=1500,\n",
    "                        #     spatial_reference=None,\n",
    "                        #     filter=\"\",\n",
    "                        #     sub_folder=\"SUBFOLDERS\",\n",
    "                        #     duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                        #     build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                        #     calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                        #     build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                        #     operation_description=\"\",\n",
    "                        #     force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                        #     estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                        #     aux_inputs=None,\n",
    "                        #     enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                        #     cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_SH\")\n",
    "                        # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} selesai \")\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Proses Export to csv Provinsi: {provinsi} dimulai . . .\")\n",
    "\n",
    "                        pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                        output_loc_csv = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_das, tipe='CSV', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                        out_csv_table_pb = os.path.join(output_loc_csv, f\"das_{provinsi.lower()}_ver_{year}0{month}das0{current_dasarian}.csv\")\n",
    "                        arcpy.conversion.ExportTable(\n",
    "                            in_table= point_extracted_pb,\n",
    "                            out_table= out_csv_table_pb,\n",
    "                            where_clause=\"\",\n",
    "                            use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "                            field_mapping=None,\n",
    "                            sort_field=None)\n",
    "\n",
    "                        # Menggabungkan ke dalam list csv untuk di merge\n",
    "                        CSV_to_merge.append(out_csv_table_pb)\n",
    "                        print(f\"Proses Export to csv Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Memulai Reclassify Provinsi: {provinsi}  . . .\")\n",
    "                        out_raster_ash_pb = arcpy.sa.Reclassify(in_raster=Extract_rast_sh,\n",
    "                                                        reclass_field=\"VALUE\",\n",
    "                                                        remap=\"0 30 1;30 50 2;50 84 3;84 115 4;115 150 5;150 200 6;200 10000 7\",\n",
    "                                                        missing_values=\"DATA\")\n",
    "\n",
    "                        out_raster_ash_pb.save(os.path.join(fgdb_temp, f\"Reclass_ASH_{provinsi}_{year}{month}das0{current_dasarian}\"))\n",
    "                        print(f\"Proses Reclassify Provinsi: {provinsi} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} dimulai . . . . . . . . . . . .\")\n",
    "\n",
    "                        pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                        output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_das, tipe='SHP', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "\n",
    "                        Output_polygon_features_ash = os.path.join(fgdb_temp, f\"ash_das_{provinsi}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                        arcpy.conversion.RasterToPolygon(in_raster=out_raster_ash_pb, out_polygon_features=Output_polygon_features_ash)\n",
    "                        arcpy.management.AddFields(in_table=Output_polygon_features_ash, field_description= \"SH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"SH\",\n",
    "                                    expression=\"sh(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def sh(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"0-30\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"31-50\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"51-84\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"85-115\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"116-150\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"151-200\"\n",
    "                                    elif x == 7:\n",
    "                                        return \">200\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Kategori\",\n",
    "                                    expression=\"kategori(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def kategori(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"Normal\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    elif x == 7:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Periode\",\n",
    "                                    expression=f'\"Dasarian {current_dasarian} {month_name} {year}\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "                        arcpy.management.CalculateField(\n",
    "                                in_table=Output_polygon_features_ash,\n",
    "                                field=\"Informasi\",\n",
    "                                expression='\"Sifat Hujan\"',\n",
    "                                expression_type=\"PYTHON3\"\n",
    "                            )\n",
    "\n",
    "\n",
    "                        poly_kec = poly_kecamatan[provinsi]\n",
    "\n",
    "\n",
    "                        Output_polygon_features_ash_union = os.path.join(output_loc_shp, f\"ash_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                        arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ash], \n",
    "                                 out_feature_class= Output_polygon_features_ash_union)\n",
    "\n",
    "\n",
    "                        arcpy.management.AddField(\n",
    "                                    in_table=Output_polygon_features_ash_union,\n",
    "                                    field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                        arcpy.management.CalculateGeometryAttributes(\n",
    "                                in_features=Output_polygon_features_ash_union,\n",
    "                                geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                                area_unit=\"HECTARES\")\n",
    "\n",
    "\n",
    "\n",
    "                        # Menggabungkan output polygon untuk di merge\n",
    "                        ASH_to_merge.append(Output_polygon_features_ash)\n",
    "                        print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} telah selesai\")\n",
    "                        print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Proses se Indonesia\n",
    "\n",
    "print(\"Proses Update Mosaic Dataset ACH: Indonesia dimulai . . .\")\n",
    "\n",
    "mosaic_data_ch = os.getenv(\"MOSAIC_DAS_ACH\")\n",
    "\n",
    "for raster_path, area in raster_ACH_to_merge :\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_ch)\n",
    "\n",
    "delete_old_rasters(mosaic_data_ch)\n",
    "\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=mosaic_data_ch,\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\")\n",
    "print(\"Proses Update Mosaic Dataset ACH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Proses Update Mosaic Dataset ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "\n",
    "mosaic_data_sh = os.getenv(\"MOSAIC_DAS_ASH\")\n",
    "\n",
    "for raster_path, area in raster_ASH_to_merge :\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_sh)\n",
    "\n",
    "delete_old_rasters(mosaic_data_sh)\n",
    "\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=mosaic_data_sh,\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\")\n",
    "print(\"Proses Update Mosaic Dataset ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# print(\"Proses Update Mosaic Dataset ACH: Indonesia dimulai . . .\")\n",
    "# # Re-Calculate Statistic Mosaic Dataset\n",
    "# arcpy.management.CalculateStatistics(\n",
    "#     in_raster_dataset=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_CH\",\n",
    "#     x_skip_factor=1,\n",
    "#     y_skip_factor=1,\n",
    "#     ignore_values=[],\n",
    "#     skip_existing=\"OVERWRITE\",\n",
    "#     area_of_interest=r\"in_memory\\feature_set1\")\n",
    "# print(\"Proses Update Mosaic Dataset ACH: Indonesia selesai\")\n",
    "# print(\"\\n\")\n",
    "\n",
    "\n",
    "# print(\"Proses Update Mosaic Dataset ASH: Indonesia dimulai . . .\")\n",
    "# arcpy.management.CalculateStatistics(\n",
    "#     in_raster_dataset=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_SH\",\n",
    "#     x_skip_factor=1,\n",
    "#     y_skip_factor=1,\n",
    "#     ignore_values=[],\n",
    "#     skip_existing=\"OVERWRITE\",\n",
    "#     area_of_interest=r\"in_memory\\feature_set1\")\n",
    "# print(\"Proses Update Mosaic Dataset ASH: Indonesia selesai\")\n",
    "# print(\"\\n\")\n",
    "\n",
    "print(\"Proses Merge Raster ACH dan ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "output_loc_tiff = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_das, tipe='TIFF')\n",
    "\n",
    "\n",
    "arcpy.MosaicToNewRaster_management(\n",
    "    input_rasters=raster_ACH_to_merge_tif,\n",
    "    output_location=output_loc_tiff,  # Direktori output\n",
    "    raster_dataset_name_with_extension=f\"ach_das_indo_ver_{year}{month}das0{current_dasarian}.tif\",\n",
    "    coordinate_system_for_the_raster=None,  # Sistem koordinat, bisa None untuk menggunakan sistem koordinat raster input\n",
    "    pixel_type=\"32_BIT_FLOAT\",\n",
    "    cellsize=None,\n",
    "    number_of_bands=1,\n",
    "    mosaic_method=\"MEAN\" ,\n",
    "    mosaic_colormap_mode=\"FIRST\"  # Mode kolormap, bisa \"FIRST\", \"LAST\", \"MATCH\", dll.\n",
    "    )\n",
    "\n",
    "arcpy.MosaicToNewRaster_management(\n",
    "    input_rasters=raster_ASH_to_merge_tif,\n",
    "    output_location=output_loc_tiff,  # Direktori output\n",
    "    raster_dataset_name_with_extension= f\"ash_das_indo_ver_{year}{month}das0{current_dasarian}.tif\",\n",
    "    coordinate_system_for_the_raster=None,  # Sistem koordinat, bisa None untuk menggunakan sistem koordinat raster input\n",
    "    pixel_type=\"32_BIT_FLOAT\",\n",
    "    cellsize=None,\n",
    "    number_of_bands=1,\n",
    "    mosaic_method=\"MEAN\" ,\n",
    "    mosaic_colormap_mode=\"FIRST\"  # Mode kolormap, bisa \"FIRST\", \"LAST\", \"MATCH\", dll.\n",
    "    )\n",
    "\n",
    "print(\"Proses Merge Raster ACH dan ASH: Indonesia selesai\")\n",
    "\n",
    "\n",
    "print(\"Proses Merge Polygon ACH dan ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "#Membuat archiving\n",
    "pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "output_loc_shp = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_das, tipe='SHP')\n",
    "\n",
    "\n",
    "# Merge polygon menjadi se Indonesia\n",
    "kec_indo = os.getenv(\"POLY_KEC\")\n",
    "arcpy.management.Merge(ACH_to_merge, os.path.join(fgdb_temp, f\"ach_das_indo_ver_{year}{month}das0{current_dasarian}\"))\n",
    "poly_indo_ach = os.path.join(output_loc_shp, f\"ach_das_indo_ver_{year}{month}das0{current_dasarian}\")\n",
    "arcpy.analysis.Union(in_features=[kec_indo, os.path.join(fgdb_temp, f\"ach_das_indo_ver_{year}{month}das0{current_dasarian}\")], \n",
    "                                 out_feature_class=poly_indo_ach)\n",
    "arcpy.management.AddField(\n",
    "                        in_table=poly_indo_ach,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "        in_features=poly_indo_ach,\n",
    "        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "        area_unit=\"HECTARES\")\n",
    "\n",
    "folder_layout = os.getenv(\"FOLDER_LAYOUT\")\n",
    "\n",
    "arcpy.CopyFeatures_management(poly_indo_ach, os.path.join(folder_layout, 'polygon_ach_das'))\n",
    "\n",
    "\n",
    "\n",
    "arcpy.management.Merge(ASH_to_merge, os.path.join(fgdb_temp, f\"ash_das_indo_ver_{year}{month}das0{current_dasarian}\"))\n",
    "poly_indo_ash = os.path.join(output_loc_shp, f\"ash_das_indo_ver_{year}{month}das0{current_dasarian}\")\n",
    "arcpy.analysis.Union(in_features=[kec_indo, os.path.join(fgdb_temp, f\"ash_das_indo_ver_{year}{month}das0{current_dasarian}\")], \n",
    "                                 out_feature_class=poly_indo_ash)\n",
    "\n",
    "arcpy.management.AddField(\n",
    "                        in_table=poly_indo_ash,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "        in_features=poly_indo_ash,\n",
    "        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "        area_unit=\"HECTARES\")\n",
    "\n",
    "arcpy.CopyFeatures_management(poly_indo_ash, os.path.join(folder_layout, 'polygon_ash_das'))\n",
    "\n",
    "\n",
    "print(\"Proses Merge Polygon ACH dan ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Proses Merge CSV ACH dan ASH: Indonesia dimulai . . .\")\n",
    "#Mmebuiat archive\n",
    "output_loc_csv = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_das, tipe='CSV')\n",
    "\n",
    "# Merge csv se Indonesia\n",
    "combined_df = pd.DataFrame()\n",
    "for file in CSV_to_merge:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file, delimiter=';')\n",
    "    # Append the DataFrame to the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "combined_df.to_csv(os.path.join(output_loc_csv, f\"das_indo_ver_{year}0{month}das0{current_dasarian}.csv\"), index=False)\n",
    "print(\"Proses Merge CSV ACH dan ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "print(\"PROSES ANALISA DASARIAN SELESAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "from config import extent_pulau, pulau_feature, titik_grid, nama_prov, poly_kecamatan, nama_prov_folder\n",
    "from utils.proses1_raster_mosaic import copy_raster, add_raster_and_update_fields, delete_old_rasters\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "import arcgis\n",
    "from arcgis.features import GeoAccessor\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import locale\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set time for dataset\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "\n",
    "# Set parameter\n",
    "gridsize_pkecil = os.getenv(\"GRID_PKECIL\")\n",
    "gridsize_pbesar= os.getenv(\"GRID_PBESAR\")\n",
    "\n",
    "\n",
    "# Set folder structure\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "output_level_ind = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA_BULANAN'\n",
    "output_tipe_das = 'ANALISA_DASARIAN'\n",
    "\n",
    "\n",
    "\n",
    "# All output folder path Bulanan - Prov\n",
    "output_prov = os.path.join(output_folder, output_level_prov)\n",
    "\n",
    "\n",
    "# Set file to loop code\n",
    "pulau_reference = os.getenv(\"PULAU_REFERENCE\")\n",
    "pulau_besar_merge = os.getenv(\"PULAU_BESAR_MERGE\")\n",
    "\n",
    "\n",
    "# Set data for I/O\n",
    "raster_loc = os.getenv(\"RASTER_LOC\")\n",
    "fgdb_input = os.getenv(\"FGDB_TEMP\")\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "mosaic_bln_ch= os.getenv(\"MOSAIC_BLN_ACH\")\n",
    "mosaic_bln_sh= os.getenv(\"MOSAIC_BLN_ASH\")\n",
    "mosaic_das_ch= os.getenv(\"MOSAIC_DAS_ACH\")\n",
    "mosaic_das_sh= os.getenv(\"MOSAIC_DAS_ASH\")\n",
    "main_output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "input_data_bln = os.path.join(fgdb_temp, 'output_2_proses1_feature_point_bln')\n",
    "input_data_das = os.path.join(fgdb_temp, 'output_2_proses1_feature_point_das')\n",
    "\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"PROSES ANALISA BULANAN DIMULAI . . .\")\n",
    "    \n",
    "raster_ACH_to_merge = []\n",
    "raster_ASH_to_merge = []\n",
    "raster_ACH_to_merge_tif = []\n",
    "raster_ASH_to_merge_tif = []\n",
    "ACH_to_merge = []\n",
    "ASH_to_merge = []\n",
    "CSV_to_merge = []\n",
    "\n",
    "poly_indo_ach = None\n",
    "poly_indo_ash = None\n",
    "\n",
    "with arcpy.da.SearchCursor(pulau_reference, [[\"Pulau_Singkat\", [\"Is_Besar\"]]]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "        \n",
    "        if r[1] == \"False\":  # val False = Pulau Kecil dan va True = Pulau Besar\n",
    "            pulau_kecil = r[0]\n",
    "            print(f\"Memulai Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "\n",
    "            ####### Proses untuk kategori pulau kecil\\\n",
    "            ####### Proses ACH untuk kategori pulau kecil\n",
    "            # Create new folder\n",
    "\n",
    "            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "            output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_bln, tipe='TIFF', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "\n",
    "            # Start Process\n",
    "\n",
    "            with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                arcpy.ga.IDW(\n",
    "                    in_features= input_data,\n",
    "                    z_field=\"CH\",\n",
    "                    out_ga_layer=None,\n",
    "                    out_raster=os.path.join(output_loc_tiff, f\"ach_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\"),\n",
    "                    cell_size=gridsize_pkecil,\n",
    "                    power=2,\n",
    "                    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                    weight_field=None\n",
    "                )\n",
    "            raster_ach_pk = arcpy.Raster(os.path.join(output_loc_tiff, f\"ach_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\"))\n",
    "            raster_ach_pk_copy = os.path.join(raster_loc, f\"ach_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\")\n",
    "\n",
    "            copy_raster(raster_ach_pk, raster_ach_pk_copy)\n",
    "\n",
    "            row_list = (raster_ach_pk_copy, f'{pulau_kecil}')\n",
    "\n",
    "            raster_ACH_to_merge.append(row_list)\n",
    "\n",
    "            raster_ACH_to_merge_tif.append(raster_ach_pk)\n",
    "\n",
    "\n",
    "            print(f\"Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "            # arcpy.management.AddRastersToMosaicDataset(\n",
    "            #                 in_mosaic_dataset= mosaic_bln_ch,\n",
    "            #                 raster_type=\"Raster Dataset\",\n",
    "            #                 input_path= raster_ach_pk,\n",
    "            #                 update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "            #                 update_boundary=\"UPDATE_BOUNDARY\",\n",
    "            #                 update_overviews=\"NO_OVERVIEWS\",\n",
    "            #                 maximum_pyramid_levels=None,\n",
    "            #                 maximum_cell_size=0,\n",
    "            #                 minimum_dimension=1500,\n",
    "            #                 spatial_reference=None,\n",
    "            #                 filter=\"\",\n",
    "            #                 sub_folder=\"SUBFOLDERS\",\n",
    "            #                 duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "            #                 build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "            #                 calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "            #                 build_thumbnails=\"NO_THUMBNAILS\",\n",
    "            #                 operation_description=\"\",\n",
    "            #                 force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "            #                 estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "            #                 aux_inputs=None,\n",
    "            #                 enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "            #                 cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "            print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai ...\")\n",
    "\n",
    "            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "            output_loc_csv = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_bln, tipe='CSV', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "\n",
    "\n",
    "            titik_grid_extract_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}\")\n",
    "            arcpy.management.CopyFeatures(in_features=titik_grid[pulau_kecil], out_feature_class=titik_grid_extract_pk)\n",
    "            point_extracted_pk = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pk, [[raster_ach_pk, \"CH\"]], \"NONE\")\n",
    "            # point_extracted_ch.save()\n",
    "            print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Reclassify ACH Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "            out_raster_ach_pk = arcpy.sa.Reclassify(\n",
    "                in_raster=raster_ach_pk,\n",
    "                reclass_field=\"VALUE\",\n",
    "                remap=\"0 20 1;20 50 2;50 100 3;100 150 4;150 200 5;200 300 6;300 400 7;400 500 8;500 10000 9\",\n",
    "                missing_values=\"DATA\")\n",
    "\n",
    "            out_raster_ach_pk.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{pulau_kecil}_{year}{month}\"))\n",
    "            print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "            # Pembuatan archive\n",
    "            output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_bln, tipe='SHP', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "            Output_polygon_features_ach = os.path.join(fgdb_temp, f\"ach_bln_{pulau_kecil.lower()}_ver_{year}{month}\")\n",
    "            arcpy.conversion.RasterToPolygon(in_raster=out_raster_ach_pk, out_polygon_features=Output_polygon_features_ach)\n",
    "            arcpy.management.AddFields(in_table=Output_polygon_features_ach, field_description= \"CH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "            arcpy.management.CalculateField(\n",
    "                        in_table=Output_polygon_features_ach,\n",
    "                        field=\"CH\",\n",
    "                        expression=\"ch(!gridcode!)\",\n",
    "                        expression_type=\"PYTHON3\",\n",
    "                        code_block=\"\"\"def ch(x):\n",
    "                        if x == 1:\n",
    "                            return \"0-20\"\n",
    "                        elif x == 2:\n",
    "                            return \"21-50\"\n",
    "                        elif x == 3:\n",
    "                            return \"51-100\"\n",
    "                        elif x == 4:\n",
    "                            return \"101-150\"\n",
    "                        elif x == 5:\n",
    "                            return \"151-200\"\n",
    "                        elif x == 6:\n",
    "                            return \"201-300\"\n",
    "                        elif x == 7:\n",
    "                            return \"301-400\"\n",
    "                        elif x == 8:\n",
    "                            return \"401-500\"\n",
    "                        elif x ==9 :\n",
    "                            return \">500\"\n",
    "                        \"\"\",\n",
    "                        field_type=\"TEXT\",\n",
    "                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "            arcpy.management.CalculateField(\n",
    "                        in_table=Output_polygon_features_ach,\n",
    "                        field=\"Kategori\",\n",
    "                        expression=\"cat(!gridcode!)\",\n",
    "                        expression_type=\"PYTHON3\",\n",
    "                        code_block=\"\"\"def cat(x):\n",
    "                        if x == 1:\n",
    "                            return \"Rendah\"\n",
    "                        elif x == 2:\n",
    "                            return \"Rendah\"\n",
    "                        elif x == 3:\n",
    "                            return \"Rendah\"\n",
    "                        elif x == 4:\n",
    "                            return \"Menengah\"\n",
    "                        elif x == 5:\n",
    "                            return \"Menengah\"\n",
    "                        elif x == 6:\n",
    "                            return \"Menengah\"\n",
    "                        elif x == 7:\n",
    "                            return \"Tinggi\"\n",
    "                        elif x == 8:\n",
    "                            return \"Sangat Tinggi\"\n",
    "                        elif x ==9 :\n",
    "                            return \"Sangat Tinggi\"\n",
    "                        \"\"\",\n",
    "                        field_type=\"TEXT\",\n",
    "                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"Periode\",\n",
    "                                    expression=f'\"{month_name} {year}\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "            arcpy.management.CalculateField(\n",
    "                                in_table=Output_polygon_features_ach,\n",
    "                                field=\"Informasi\",\n",
    "                                expression='\"Curah Hujan\"',\n",
    "                                expression_type=\"PYTHON3\"\n",
    "                            )\n",
    "\n",
    "            poly_kec = poly_kecamatan[pulau_kecil]\n",
    "\n",
    "\n",
    "            Output_polygon_features_ach_union = os.path.join(output_loc_shp, f\"ach_bln_{pulau_kecil.lower()}_ver_{year}{month}\")\n",
    "            arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ach], \n",
    "                                 out_feature_class=Output_polygon_features_ach_union)\n",
    "\n",
    "            arcpy.management.AddField(\n",
    "                        in_table=Output_polygon_features_ach_union,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "            arcpy.management.CalculateGeometryAttributes(\n",
    "                    in_features=Output_polygon_features_ach_union,\n",
    "                    geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                    area_unit=\"HECTARES\")\n",
    "\n",
    "            # Menggabungkan polygon untuk di merge\n",
    "            ACH_to_merge.append(Output_polygon_features_ach)\n",
    "            print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            ####### Proses ASH untuk kategori pulau kecil\n",
    "            print(f\"Memulai Proses Interpolasi ASH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "            with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                arcpy.ga.IDW(\n",
    "                    in_features=input_data,\n",
    "                    z_field=\"SH_\",\n",
    "                    out_ga_layer=None,\n",
    "                    out_raster=os.path.join(output_loc_tiff, f\"ash_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\"),\n",
    "                    cell_size=gridsize_pkecil,\n",
    "                    power=2,\n",
    "                    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                    weight_field=None\n",
    "                )\n",
    "\n",
    "            raster_ash_pk = arcpy.Raster(os.path.join(output_loc_tiff, f\"ash_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\"))\n",
    "\n",
    "            raster_ach_pk_copy = os.path.join(raster_loc, f\"ash_bln_{pulau_kecil.lower()}_ver_{year}{month}.tif\")\n",
    "\n",
    "            copy_raster(raster_ach_pk, raster_ach_pk_copy)\n",
    "\n",
    "            row_list = (raster_ach_pk_copy, f'{pulau_kecil}')\n",
    "\n",
    "            raster_ASH_to_merge.append(row_list)\n",
    "\n",
    "            raster_ASH_to_merge_tif.append(raster_ash_pk)\n",
    "\n",
    "\n",
    "            print(f\"Proses Interpolasi ASH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "            # arcpy.management.AddRastersToMosaicDataset(\n",
    "            #                 in_mosaic_dataset= mosaic_bln_sh,\n",
    "            #                 raster_type=\"Raster Dataset\",\n",
    "            #                 input_path= raster_ash_pk,\n",
    "            #                 update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "            #                 update_boundary=\"UPDATE_BOUNDARY\",\n",
    "            #                 update_overviews=\"NO_OVERVIEWS\",\n",
    "            #                 maximum_pyramid_levels=None,\n",
    "            #                 maximum_cell_size=0,\n",
    "            #                 minimum_dimension=1500,\n",
    "            #                 spatial_reference=None,\n",
    "            #                 filter=\"\",\n",
    "            #                 sub_folder=\"SUBFOLDERS\",\n",
    "            #                 duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "            #                 build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "            #                 calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "            #                 build_thumbnails=\"NO_THUMBNAILS\",\n",
    "            #                 operation_description=\"\",\n",
    "            #                 force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "            #                 estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "            #                 aux_inputs=None,\n",
    "            #                 enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "            #                 cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_SH\")\n",
    "            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai . . .\")\n",
    "            point_extracted_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}\")\n",
    "            arcpy.sa.ExtractMultiValuesToPoints(point_extracted_pk, [[raster_ash_pk, \"SH\"]], \"NONE\")\n",
    "            # point_extracted_sh.save()\n",
    "            arcpy.management.AddFields(in_table=point_extracted_pk, field_description=[[\"LAT\", \"DOUBLE\", \"Latitude\", \"\", \"\", \"\"], [\"LONG\", \"DOUBLE\", \"Longitude\", \"\", \"\", \"\"]])[0]\n",
    "            arcpy.management.CalculateGeometryAttributes(in_features=point_extracted_pk, geometry_property=[[\"LAT\", \"POINT_Y\"], [\"LONG\", \"POINT_X\"]], coordinate_system=\"PROJCS[\\\"WGS_1984_Web_Mercator_Auxiliary_Sphere\\\",GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Mercator_Auxiliary_Sphere\\\"],PARAMETER[\\\"False_Easting\\\",0.0],PARAMETER[\\\"False_Northing\\\",0.0],PARAMETER[\\\"Central_Meridian\\\",0.0],PARAMETER[\\\"Standard_Parallel_1\\\",0.0],PARAMETER[\\\"Auxiliary_Sphere_Type\\\",0.0],UNIT[\\\"Meter\\\",1.0]]\", \n",
    "                                                                    coordinate_format=\"DD\")[0]\n",
    "            print(f\"Proses Extract Point Provinsi: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Export to csv Provinsi: {pulau_kecil} dimulai . . .\")\n",
    "            out_csv_table_pk = os.path.join(output_loc_csv, f\"bln_{pulau_kecil.lower()}_ver_{year}0{month}.csv\")\n",
    "            arcpy.conversion.ExportTable(\n",
    "                            in_table= point_extracted_pk,\n",
    "                            out_table= out_csv_table_pk,\n",
    "                            where_clause=\"\",\n",
    "                            use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "                            field_mapping=None,\n",
    "                            sort_field=None)\n",
    "\n",
    "            # Menggabungkan csv untuk di merge\n",
    "            CSV_to_merge.append(out_csv_table_pk)\n",
    "            print(f\"Proses Export to csv Provinsi: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "            print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "            out_raster_ash_pk = arcpy.sa.Reclassify(\n",
    "                in_raster=raster_ash_pk,\n",
    "                reclass_field=\"VALUE\",\n",
    "                remap=\"0 30 1;30 50 2;50 84 3;84 115 4;115 150 5;150 200 6;200 10000 7\",\n",
    "                missing_values=\"DATA\")\n",
    "\n",
    "            out_raster_ash_pk.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{pulau_kecil}_{year}{month}\"))\n",
    "            print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "            Output_polygon_features_ash = os.path.join(fgdb_temp, f\"ash_bln_{pulau_kecil}_ver_{year}{month}\")\n",
    "            arcpy.conversion.RasterToPolygon(in_raster=out_raster_ash_pk, out_polygon_features=Output_polygon_features_ash)\n",
    "            arcpy.management.AddFields(in_table=Output_polygon_features_ash, field_description= \"SH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"SH\",\n",
    "                                    expression=\"sh(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def sh(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"0-30\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"31-50\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"51-84\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"85-115\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"116-150\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"151-200\"\n",
    "                                    elif x == 7:\n",
    "                                        return \">200\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Kategori\",\n",
    "                                    expression=\"kategori(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def kategori(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"Normal\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    elif x == 7:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Periode\",\n",
    "                                    expression=f'\"{month_name} {year}\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "            arcpy.management.CalculateField(\n",
    "                                in_table=Output_polygon_features_ash,\n",
    "                                field=\"Informasi\",\n",
    "                                expression='\"Sifat Hujan\"',\n",
    "                                expression_type=\"PYTHON3\"\n",
    "                            )\n",
    "\n",
    "\n",
    "            poly_kec = poly_kecamatan[pulau_kecil]\n",
    "\n",
    "            Output_polygon_features_ash_union = os.path.join(output_loc_shp, f\"ash_bln_{pulau_kecil.lower()}_ver_{year}{month}\")\n",
    "            arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ash], \n",
    "                                 out_feature_class=Output_polygon_features_ash_union)\n",
    "\n",
    "            arcpy.management.AddField(\n",
    "                        in_table=Output_polygon_features_ash_union,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "            arcpy.management.CalculateGeometryAttributes(\n",
    "                    in_features=Output_polygon_features_ash_union,\n",
    "                    geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                    area_unit=\"HECTARES\")\n",
    "\n",
    "            # menggabungkan polygon untuk di merge\n",
    "            ASH_to_merge.append(Output_polygon_features_ash)\n",
    "            print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "        ####### Proses untuk kategori pulau besar\n",
    "        ####### Proses ACH Pulau Besar\n",
    "        else:\n",
    "            pulau_besar = r[0]\n",
    "            print(f\"Memulai Proses Interpolasi ACH Pulau Besar: {pulau_besar} . . .\")\n",
    "            with arcpy.EnvManager(extent=extent_pulau[pulau_besar], mask=pulau_feature[pulau_besar]):\n",
    "                arcpy.ga.IDW(\n",
    "                    in_features=input_data,\n",
    "                    z_field=\"CH\",\n",
    "                    out_ga_layer=None,\n",
    "                    out_raster=os.path.join(fgdb_temp, f\"interpolasi_ACH_Pulau_{pulau_besar}_{year}{month}\"),\n",
    "                    cell_size=gridsize_pbesar,\n",
    "                    power=2,\n",
    "                    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                    weight_field=None\n",
    "                )\n",
    "            raster_ach_pb = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ACH_Pulau_{pulau_besar}_{year}{month}\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Interpolasi ACH Pulau Besar: {pulau_besar} telah selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "            ######### Proses Masking ACH\n",
    "            print(f\"Proses Masking ACH Pulau Besar: {pulau_besar} dimulai . . .\")\n",
    "            with arcpy.da.SearchCursor(pulau_besar_merge, [[\"Pulau\", [\"Provinsi_Singkat\"]]]) as masks:\n",
    "                for r in masks:\n",
    "                    pulau_mask = r[0]\n",
    "                    provinsi = r[1]\n",
    "                    if pulau_mask == pulau_besar:\n",
    "                        print(f\"Memulai Mask Provinsi: {provinsi}  . . .\")\n",
    "\n",
    "                        # Membuat archive folder\n",
    "                        print(\"Membuat Archive\")\n",
    "                        pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                        output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_bln, tipe='TIFF', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                        print(\"Selesai Archive\")\n",
    "\n",
    "\n",
    "                        Extract_rast_ch = os.path.join(output_loc_tiff, f\"ach_bln_{provinsi.lower()}_ver_{year}{month}.tif\")\n",
    "                        Extract_by_Mask = Extract_rast_ch\n",
    "                        Extract_rast_ch = arcpy.sa.ExtractByMask(raster_ach_pb, pulau_feature[provinsi], \"INSIDE\", extent_pulau[provinsi])\n",
    "                        Extract_rast_ch.save(Extract_by_Mask)\n",
    "\n",
    "                        Extract_rast_ch_copy = os.path.join(raster_loc, f\"ach_bln_{provinsi.lower()}_ver_{year}{month}.tif\")\n",
    "\n",
    "                        copy_raster(Extract_rast_ch, Extract_rast_ch_copy)\n",
    "\n",
    "                        row_list = (Extract_rast_ch_copy, f'{provinsi}')\n",
    "\n",
    "                        raster_ACH_to_merge.append(row_list)\n",
    "\n",
    "                        raster_ACH_to_merge_tif.append(Extract_rast_ch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Proses Mask Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                        # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} dimulai . . .. \")\n",
    "                        # arcpy.management.AddRastersToMosaicDataset(\n",
    "                        #     in_mosaic_dataset= mosaic_bln_ch,\n",
    "                        #     raster_type=\"Raster Dataset\",\n",
    "                        #     input_path= Extract_rast_ch,\n",
    "                        #     update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                        #     update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                        #     update_overviews=\"NO_OVERVIEWS\",\n",
    "                        #     maximum_pyramid_levels=None,\n",
    "                        #     maximum_cell_size=0,\n",
    "                        #     minimum_dimension=1500,\n",
    "                        #     spatial_reference=None,\n",
    "                        #     filter=\"\",\n",
    "                        #     sub_folder=\"SUBFOLDERS\",\n",
    "                        #     duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                        #     build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                        #     calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                        #     build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                        #     operation_description=\"\",\n",
    "                        #     force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                        #     estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                        #     aux_inputs=None,\n",
    "                        #     enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                        #     cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "                        # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} selesai \")\n",
    "\n",
    "\n",
    "                        print(f\"Proses Extract Point Provinsi: {provinsi} dimulai ...\")\n",
    "                        titik_grid_extract_pb = os.path.join(fgdb_temp, f\"Titik_extract_{provinsi}_{year}{month}\")\n",
    "                        arcpy.management.CopyFeatures(in_features=titik_grid[provinsi], out_feature_class=titik_grid_extract_pb)\n",
    "                        point_extracted_pb = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pb, [[Extract_rast_ch, \"CH\"]], \"NONE\")\n",
    "                        # point_extracted_ch.save()\n",
    "                        print(f\"Proses Extract Point Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Memulai Reclassify Provinsi: {provinsi}  . . .\")\n",
    "                        out_raster_ach_pb = arcpy.sa.Reclassify(in_raster=Extract_rast_ch,\n",
    "                                                        reclass_field=\"VALUE\",\n",
    "                                                        remap=\"0 20 1;20 50 2;50 100 3;100 150 4;150 200 5;200 300 6;300 400 7;400 500 8;500 10000 9\",\n",
    "                                                        missing_values=\"DATA\")\n",
    "\n",
    "                        out_raster_ach_pb.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{provinsi}_{year}{month}\"))\n",
    "                        print(f\"Proses Reclassify Provinsi: {provinsi} telah selesai\")\n",
    "\n",
    "\n",
    "                        print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} dimulai . . . . . . . . . . . .\")\n",
    "                        # Membuat archive folder\n",
    "                        pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                        output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_bln, tipe='SHP', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                        Output_polygon_features_ach = os.path.join(fgdb_temp, f\"ach_bln_{provinsi}_ver_{year}{month}\")\n",
    "                        arcpy.conversion.RasterToPolygon(in_raster=out_raster_ach_pb, out_polygon_features=Output_polygon_features_ach)\n",
    "                        arcpy.management.AddFields(in_table=Output_polygon_features_ach, field_description= \"CH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"CH\",\n",
    "                                    expression=\"ch(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def ch(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"0-20\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"21-50\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"51-100\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"101-150\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"151-200\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"201-300\"\n",
    "                                    elif x == 7:\n",
    "                                        return \"301-400\"\n",
    "                                    elif x == 8:\n",
    "                                        return \"401-500\"\n",
    "                                    elif x ==9 :\n",
    "                                        return \">500\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"Kategori\",\n",
    "                                    expression=\"cat(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def cat(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"Rendah\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"Rendah\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"Rendah\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"Menengah\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"Menengah\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"Menengah\"\n",
    "                                    elif x == 7:\n",
    "                                        return \"Tinggi\"\n",
    "                                    elif x == 8:\n",
    "                                        return \"Sangat Tinggi\"\n",
    "                                    elif x ==9 :\n",
    "                                        return \"Sangat Tinggi\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"Periode\",\n",
    "                                    expression=f'\"{month_name} {year}\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "                        arcpy.management.CalculateField(\n",
    "                                in_table=Output_polygon_features_ach,\n",
    "                                field=\"Informasi\",\n",
    "                                expression='\"Curah Hujan\"',\n",
    "                                expression_type=\"PYTHON3\"\n",
    "                            )\n",
    "\n",
    "\n",
    "                        poly_kec = poly_kecamatan[provinsi]\n",
    "\n",
    "                        Output_polygon_features_ach_union = os.path.join(output_loc_shp, f\"ach_bln_{provinsi.lower()}_ver_{year}{month}\")\n",
    "                        arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ach], \n",
    "                                 out_feature_class= Output_polygon_features_ach_union)\n",
    "\n",
    "\n",
    "                        arcpy.management.AddField(\n",
    "                        in_table=Output_polygon_features_ach_union,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                        arcpy.management.CalculateGeometryAttributes(\n",
    "                                in_features=Output_polygon_features_ach_union,\n",
    "                                geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                                area_unit=\"HECTARES\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        # Menggabungkan polygon untuk di merge\n",
    "                        ACH_to_merge.append(Output_polygon_features_ach)\n",
    "                        print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} telah selesai\")\n",
    "                        print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            ####### Proses ASH Pulau Besar\n",
    "            ####### Proses Interpolasi ASH\n",
    "            print(f\"Memulai Proses Interpolasi ASH Pulau Besar: {pulau_besar}\")\n",
    "\n",
    "            with arcpy.EnvManager(extent=extent_pulau[pulau_besar], mask=pulau_feature[pulau_besar]):\n",
    "                arcpy.ga.IDW(\n",
    "                    in_features=input_data,\n",
    "                    z_field=\"SH_\",\n",
    "                    out_ga_layer=None,\n",
    "                    out_raster=os.path.join(fgdb_temp, f\"interpolasi_ASH_Pulau_{pulau_besar}_{year}{month}\"),\n",
    "                    cell_size=gridsize_pbesar,\n",
    "                    power=2,\n",
    "                    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                    weight_field=None\n",
    "                )\n",
    "\n",
    "            raster_ash = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ASH_Pulau_{pulau_besar}_{year}{month}\"))\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Proses Interpolasi ASH Pulau Besar: {pulau_besar} telah selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "            ######### Proses Masking ASH\n",
    "            print(f\"Proses Masking ASH Pulau Besar: {pulau_besar} dimulai . . .\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            with arcpy.da.SearchCursor(pulau_besar_merge, [[\"Pulau\", [\"Provinsi_Singkat\"]]]) as masks:\n",
    "                for r in masks:\n",
    "                    pulau_mask = r[0]\n",
    "                    provinsi = r[1]\n",
    "                    if pulau_mask == pulau_besar:\n",
    "                        print(f\"Memulai Mask ASH Provinsi: {provinsi}  . . .\")\n",
    "\n",
    "\n",
    "                        pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                        output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                    output_tipe_periode=output_tipe_bln, tipe='TIFF', \n",
    "                                                    nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "\n",
    "\n",
    "                        Extract_rast_sh = os.path.join(output_loc_tiff, f\"ash_bln_{provinsi.lower()}_ver_{year}{month}.tif\")\n",
    "                        Extract_by_Mask = Extract_rast_sh\n",
    "                        Extract_rast_sh = arcpy.sa.ExtractByMask(raster_ash, pulau_feature[provinsi], \"INSIDE\", extent_pulau[provinsi])\n",
    "                        Extract_rast_sh.save(Extract_by_Mask)\n",
    "\n",
    "\n",
    "                        Extract_rast_sh_copy = os.path.join(raster_loc, f\"ash_bln_{provinsi.lower()}_ver_{year}{month}.tif\")\n",
    "\n",
    "                        copy_raster(Extract_rast_sh, Extract_rast_sh_copy)\n",
    "\n",
    "                        row_list = (Extract_rast_sh_copy, f'{provinsi}')\n",
    "\n",
    "                        raster_ASH_to_merge.append(row_list)\n",
    "\n",
    "\n",
    "                        raster_ASH_to_merge_tif.append(Extract_rast_sh)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Proses Mask Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "                        print(f\"Proses Extract Point Provinsi: {provinsi} dimulai . . .\")\n",
    "                        point_extracted_pb = os.path.join(fgdb_temp, f\"Titik_extract_{provinsi}_{year}{month}\")\n",
    "                        arcpy.sa.ExtractMultiValuesToPoints(point_extracted_pb, [[Extract_rast_sh, \"SH\"]], \"NONE\")\n",
    "                        arcpy.management.AddFields(in_table=point_extracted_pb, field_description=[[\"LAT\", \"DOUBLE\", \"Latitude\", \"\", \"\", \"\"], [\"LONG\", \"DOUBLE\", \"Longitude\", \"\", \"\", \"\"]])[0]\n",
    "                        arcpy.management.CalculateGeometryAttributes(in_features=point_extracted_pb, geometry_property=[[\"LAT\", \"POINT_Y\"], [\"LONG\", \"POINT_X\"]],coordinate_system=\"PROJCS[\\\"WGS_1984_Web_Mercator_Auxiliary_Sphere\\\",GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Mercator_Auxiliary_Sphere\\\"],PARAMETER[\\\"False_Easting\\\",0.0],PARAMETER[\\\"False_Northing\\\",0.0],PARAMETER[\\\"Central_Meridian\\\",0.0],PARAMETER[\\\"Standard_Parallel_1\\\",0.0],PARAMETER[\\\"Auxiliary_Sphere_Type\\\",0.0],UNIT[\\\"Meter\\\",1.0]]\", \n",
    "                                                                    coordinate_format=\"DD\")[0]\n",
    "                        # point_extracted_sh.save()\n",
    "                        print(f\"Proses Extract Point Provinsi: {provinsi} selesai\")\n",
    "\n",
    "                        # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} dimulai . . .. \")\n",
    "                        # arcpy.management.AddRastersToMosaicDataset(\n",
    "                        #     in_mosaic_dataset= mosaic_bln_sh,\n",
    "                        #     raster_type=\"Raster Dataset\",\n",
    "                        #     input_path= Extract_rast_sh,\n",
    "                        #     update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                        #     update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                        #     update_overviews=\"NO_OVERVIEWS\",\n",
    "                        #     maximum_pyramid_levels=None,\n",
    "                        #     maximum_cell_size=0,\n",
    "                        #     minimum_dimension=1500,\n",
    "                        #     spatial_reference=None,\n",
    "                        #     filter=\"\",\n",
    "                        #     sub_folder=\"SUBFOLDERS\",\n",
    "                        #     duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                        #     build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                        #     calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                        #     build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                        #     operation_description=\"\",\n",
    "                        #     force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                        #     estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                        #     aux_inputs=None,\n",
    "                        #     enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                        #     )\n",
    "                        # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} selesai \")\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Proses Export to csv Provinsi: {provinsi} dimulai . . .\")\n",
    "\n",
    "                        pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                        output_loc_csv = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_bln, tipe='CSV', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                        out_csv_table_pb = os.path.join(output_loc_csv, f\"bln_{provinsi.lower()}_ver_{year}0{month}.csv\")\n",
    "                        arcpy.conversion.ExportTable(\n",
    "                            in_table= point_extracted_pb,\n",
    "                            out_table= out_csv_table_pb,\n",
    "                            where_clause=\"\",\n",
    "                            use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "                            field_mapping=None,\n",
    "                            sort_field=None)\n",
    "\n",
    "                        # Menggabungkan ke dalam list csv untuk di merge\n",
    "                        CSV_to_merge.append(out_csv_table_pb)\n",
    "                        print(f\"Proses Export to csv Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Memulai Reclassify Provinsi: {provinsi}  . . .\")\n",
    "                        out_raster_ash_pb = arcpy.sa.Reclassify(in_raster=Extract_rast_sh,\n",
    "                                                        reclass_field=\"VALUE\",\n",
    "                                                        remap=\"0 30 1;30 50 2;50 84 3;84 115 4;115 150 5;150 200 6;200 10000 7\",\n",
    "                                                        missing_values=\"DATA\")\n",
    "\n",
    "                        out_raster_ash_pb.save(os.path.join(fgdb_temp, f\"Reclass_ASH_{provinsi}_{year}{month}\"))\n",
    "                        print(f\"Proses Reclassify Provinsi: {provinsi} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} dimulai . . . . . . . . . . . .\")\n",
    "\n",
    "                        pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                        output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                               output_tipe_periode=output_tipe_bln, tipe='SHP', \n",
    "                                                               nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "\n",
    "                        Output_polygon_features_ash = os.path.join(fgdb_temp, f\"ash_bln_{provinsi}_ver_{year}{month}\")\n",
    "                        arcpy.conversion.RasterToPolygon(in_raster=out_raster_ash_pb, out_polygon_features=Output_polygon_features_ash)\n",
    "                        arcpy.management.AddFields(in_table=Output_polygon_features_ash, field_description= \"SH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"SH\",\n",
    "                                    expression=\"sh(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def sh(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"0-30\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"31-50\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"51-84\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"85-115\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"116-150\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"151-200\"\n",
    "                                    elif x == 7:\n",
    "                                        return \">200\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Kategori\",\n",
    "                                    expression=\"kategori(!gridcode!)\",\n",
    "                                    expression_type=\"PYTHON3\",\n",
    "                                    code_block=\"\"\"def kategori(x):\n",
    "                                    if x == 1:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 2:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 3:\n",
    "                                        return \"Bawah Normal\"\n",
    "                                    elif x == 4:\n",
    "                                        return \"Normal\"\n",
    "                                    elif x == 5:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    elif x == 6:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    elif x == 7:\n",
    "                                        return \"Atas Normal\"\n",
    "                                    \"\"\",\n",
    "                                    field_type=\"TEXT\",\n",
    "                                    enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "                        arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Periode\",\n",
    "                                    expression=f'\"{month_name} {year}\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "                        arcpy.management.CalculateField(\n",
    "                                in_table=Output_polygon_features_ash,\n",
    "                                field=\"Informasi\",\n",
    "                                expression='\"Sifat Hujan\"',\n",
    "                                expression_type=\"PYTHON3\"\n",
    "                            )\n",
    "\n",
    "                        poly_kec = poly_kecamatan[provinsi]\n",
    "\n",
    "\n",
    "                        Output_polygon_features_ash_union = os.path.join(output_loc_shp, f\"ash_bln_{provinsi.lower()}_ver_{year}{month}\")\n",
    "                        arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ach], \n",
    "                                 out_feature_class= Output_polygon_features_ash_union)\n",
    "\n",
    "                        arcpy.management.AddField(\n",
    "                                    in_table=Output_polygon_features_ash_union,\n",
    "                                    field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                        arcpy.management.CalculateGeometryAttributes(\n",
    "                                in_features=Output_polygon_features_ash_union,\n",
    "                                geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                                area_unit=\"HECTARES\")\n",
    "\n",
    "                        # Menggabungkan output polygon untuk di merge\n",
    "                        ASH_to_merge.append(Output_polygon_features_ash)\n",
    "                        print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} telah selesai\")\n",
    "                        print(\"\\n\")\n",
    "\n",
    "       \n",
    "\n",
    "# Proses se Indonesia \n",
    "#Mosaic CH\n",
    "\n",
    "print(\"Proses Update Mosaic Dataset ACH: Indonesia dimulai . . .\")\n",
    "\n",
    "mosaic_data_ch = os.getenv(\"MOSAIC_BLN_ACH\")\n",
    "\n",
    "for raster_path, area in raster_ACH_to_merge :\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_ch)\n",
    "\n",
    "delete_old_rasters(mosaic_data_ch)\n",
    "\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=mosaic_data_ch,\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\")\n",
    "print(\"Proses Update Mosaic Dataset ACH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Proses Update Mosaic Dataset ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "\n",
    "mosaic_data_sh = os.getenv(\"MOSAIC_BLN_ASH\")\n",
    "\n",
    "for raster_path, area in raster_ASH_to_merge :\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_sh)\n",
    "\n",
    "delete_old_rasters(mosaic_data_sh)\n",
    "\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=mosaic_data_sh,\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\")\n",
    "print(\"Proses Update Mosaic Dataset ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Proses Update Mosaic Dataset ACH: Indonesia dimulai . . .\")\n",
    "# # Re-Calculate Statistic Mosaic Dataset\n",
    "# arcpy.management.CalculateStatistics(\n",
    "#     in_raster_dataset=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_CH\",\n",
    "#     x_skip_factor=1,\n",
    "#     y_skip_factor=1,\n",
    "#     ignore_values=[],\n",
    "#     skip_existing=\"OVERWRITE\",\n",
    "#     area_of_interest=r\"in_memory\\feature_set1\")\n",
    "# print(\"Proses Update Mosaic Dataset ACH: Indonesia selesai\")\n",
    "# print(\"\\n\")\n",
    "\n",
    "\n",
    "# print(\"Proses Update Mosaic Dataset ASH: Indonesia dimulai . . .\")\n",
    "# arcpy.management.CalculateStatistics(\n",
    "#     in_raster_dataset=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_SH\",\n",
    "#     x_skip_factor=1,\n",
    "#     y_skip_factor=1,\n",
    "#     ignore_values=[],\n",
    "#     skip_existing=\"OVERWRITE\",\n",
    "#     area_of_interest=r\"in_memory\\feature_set1\")\n",
    "# print(\"Proses Update Mosaic Dataset ASH: Indonesia selesai\")\n",
    "# print(\"\\n\")\n",
    "\n",
    "print(\"Proses Merge Raster ACH dan ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "output_loc_tiff = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_bln, tipe='TIFF')\n",
    "\n",
    "\n",
    "arcpy.MosaicToNewRaster_management(\n",
    "    input_rasters=raster_ACH_to_merge_tif,\n",
    "    output_location=output_loc_tiff,  # Direktori output\n",
    "    raster_dataset_name_with_extension=f\"ach_bln_indo_ver_{year}{month}.tif\",\n",
    "    coordinate_system_for_the_raster=None,  # Sistem koordinat, bisa None untuk menggunakan sistem koordinat raster input\n",
    "    pixel_type=\"32_BIT_FLOAT\",\n",
    "    cellsize=None,\n",
    "    number_of_bands=1,\n",
    "    mosaic_method=\"MEAN\" ,\n",
    "    mosaic_colormap_mode=\"FIRST\"  # Mode kolormap, bisa \"FIRST\", \"LAST\", \"MATCH\", dll.\n",
    "    )\n",
    "\n",
    "arcpy.MosaicToNewRaster_management(\n",
    "    input_rasters=raster_ASH_to_merge_tif,\n",
    "    output_location=output_loc_tiff,  # Direktori output\n",
    "    raster_dataset_name_with_extension= f\"ash_bln_indo_ver_{year}{month}.tif\",\n",
    "    coordinate_system_for_the_raster=None,  # Sistem koordinat, bisa None untuk menggunakan sistem koordinat raster input\n",
    "    pixel_type=\"32_BIT_FLOAT\",\n",
    "    cellsize=None,\n",
    "    number_of_bands=1,\n",
    "    mosaic_method=\"MEAN\" ,\n",
    "    mosaic_colormap_mode=\"FIRST\"  # Mode kolormap, bisa \"FIRST\", \"LAST\", \"MATCH\", dll.\n",
    "    )\n",
    "\n",
    "print(\"Proses Merge Raster ACH dan ASH: Indonesia selesai\")\n",
    "\n",
    "\n",
    "print(\"Proses Merge Polygon ACH dan ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "#Membuat archiving\n",
    "pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "output_loc_shp = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_bln, tipe='SHP')\n",
    "\n",
    "\n",
    "# Merge polygon menjadi se Indonesia\n",
    "kec_indo = os.getenv(\"POLY_KEC\")\n",
    "arcpy.management.Merge(ACH_to_merge, os.path.join(fgdb_temp, f\"ach_bln_indo_ver_{year}{month}\"))\n",
    "poly_indo_ach = os.path.join(output_loc_shp, f\"ach_bln_indo_ver_{year}{month}\")\n",
    "arcpy.analysis.Union(in_features=[kec_indo, os.path.join(fgdb_temp, f\"ach_bln_indo_ver_{year}{month}\")], \n",
    "                                 out_feature_class=poly_indo_ach)\n",
    "\n",
    "arcpy.management.AddField(\n",
    "                        in_table=poly_indo_ach,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "        in_features=poly_indo_ach,\n",
    "        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "        area_unit=\"HECTARES\")\n",
    "\n",
    "folder_layout = os.getenv(\"FOLDER_LAYOUT\")\n",
    "\n",
    "arcpy.CopyFeatures_management(poly_indo_ach, os.path.join(folder_layout, 'polygon_ach_bln'))\n",
    "\n",
    "\n",
    "arcpy.management.Merge(ASH_to_merge, os.path.join(fgdb_temp, f\"ash_bln_indo_ver_{year}{month}\"))\n",
    "poly_indo_ash = os.path.join(output_loc_shp, f\"ash_bln_indo_ver_{year}{month}\")\n",
    "arcpy.analysis.Union(in_features=[kec_indo, os.path.join(fgdb_temp, f\"ash_bln_indo_ver_{year}{month}\")], \n",
    "                                 out_feature_class= poly_indo_ash)\n",
    "arcpy.management.AddField(\n",
    "                        in_table=poly_indo_ash,\n",
    "                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "arcpy.management.CalculateGeometryAttributes(\n",
    "        in_features=poly_indo_ash,\n",
    "        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "        area_unit=\"HECTARES\")\n",
    "\n",
    "folder_layout = os.getenv(\"FOLDER_LAYOUT\")\n",
    "\n",
    "arcpy.CopyFeatures_management(poly_indo_ash, os.path.join(folder_layout, 'polygon_ash_bln'))\n",
    "\n",
    "print(\"Proses Merge Polygon ACH dan ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Proses Merge CSV ACH dan ASH: Indonesia dimulai . . .\")\n",
    "#Mmebuiat archive\n",
    "output_loc_csv = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_bln, tipe='CSV')\n",
    "\n",
    "# Merge csv se Indonesia\n",
    "combined_df = pd.DataFrame()\n",
    "for file in CSV_to_merge:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file, delimiter=';')\n",
    "    # Append the DataFrame to the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "combined_df.to_csv(os.path.join(output_loc_csv, f\"bln_indo_ver_{year}{month}.csv\"), index=False)\n",
    "print(\"Proses Merge CSV ACH dan ASH: Indonesia selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"PROSES ANALISA BULANAN SELESAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import datetime\n",
    "import locale\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_clear_fgdb_temp import empty_fgdb\n",
    "from utils.proses1_update_table_summary import update_table\n",
    "from utils.proses1_preprocess import Preprocessing\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "from utils.proses1_data_process import interpolasi_bln, interpolasi_das\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "## Get time\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.now()\n",
    "current_date = datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "# Get geodatabase\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "output_table_name = \"output_1_proses1_table\"\n",
    "output_feature_name = \"output_2_proses1_feature_point\"\n",
    "\n",
    "\n",
    "## Input folder structure\n",
    "main_folder = os.getenv(\"MAIN_FOLDER\")\n",
    "folder_bulanan = r'BULANAN'\n",
    "folder_dasarian = r'DASARIAN'\n",
    "file_name_bulanan = f'BlendGSMAP_POS.{year}{month}.xls'\n",
    "file_name_dasarian = f'BlendGSMAP_POS.{year}{month}dec0{current_dasarian}.xls'\n",
    "\n",
    "# Output folder structure\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "output_level_ind = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA-BULANAN'\n",
    "output_tipe_das = 'ANALISA-DASARIAN'\n",
    "\n",
    "# Get full folder path\n",
    "file_path_bulanan = os.path.join(main_folder, folder_bulanan)\n",
    "file_path_dasarian = os.path.join(main_folder, folder_dasarian)\n",
    "\n",
    "# File input\n",
    "file_input_bulanan = os.path.join(file_path_bulanan, file_name_bulanan)\n",
    "file_input_dasarian = os.path.join(file_path_dasarian, file_name_dasarian)\n",
    "\n",
    "\n",
    "\n",
    "# map project\n",
    "map_project = os.getenv(\"APRX_PROJECT\")\n",
    "\n",
    "\n",
    "            \n",
    "preprocessing_das = Preprocessing(fgdb_temp, file_input_dasarian)\n",
    "\n",
    "# # Panggil metode Get_Excel untuk mengonversi file Excel ke tabel\n",
    "\n",
    "point_das = preprocessing_das.Excel_to_Feature(output_table_name = output_table_name+'_das', output_feature_name = output_feature_name+'_das')\n",
    "\n",
    "print(\"Proses Ekstraksi Table Excel Selesai\")\n",
    "\n",
    "\n",
    "print(\"Proses 1 dimulai\")\n",
    "start_time = datetime.now()\n",
    "print(\"Analisa Data Dasarian dimulai\")\n",
    "\n",
    "poly_indo_ach, poly_indo_ash, raster_ACH_to_merge, raster_ASH_to_merge = interpolasi_das(input_data= point_das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def copy_raster(input_raster, output_raster):\n",
    "    \"\"\"\n",
    "    Copies a raster dataset from the input location to the output location.\n",
    "\n",
    "    Parameters:\n",
    "    input_raster (str): Path to the input raster dataset.\n",
    "    output_raster (str): Path to the output raster dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use the CopyRaster function to copy the raster\n",
    "        arcpy.management.CopyRaster(\n",
    "                in_raster=input_raster,\n",
    "                out_rasterdataset=output_raster,\n",
    "                config_keyword=\"\",\n",
    "                background_value=None,\n",
    "                nodata_value=\"\",\n",
    "                onebit_to_eightbit=\"NONE\",\n",
    "                colormap_to_RGB=\"NONE\",\n",
    "                pixel_type=\"\",\n",
    "                scale_pixel_value=\"NONE\",\n",
    "                RGB_to_Colormap=\"NONE\",\n",
    "                format=\"\",\n",
    "                transform=\"NONE\",\n",
    "                process_as_multidimensional=\"CURRENT_SLICE\",\n",
    "                build_multidimensional_transpose=\"NO_TRANSPOSE\"\n",
    ")\n",
    "        print(f\"Raster copied from {input_raster} to {output_raster}\")\n",
    "    except arcpy.ExecuteError:\n",
    "        print(arcpy.GetMessages(2))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n",
    "# Function to add raster and update fields\n",
    "def add_raster_and_update_fields(raster_path, area, mosaic_data):\n",
    "    # Add the raster to the mosaic dataset\n",
    "    # Add the raster to the mosaic dataset\n",
    "    # Add the raster to the mosaic dataset\n",
    "    arcpy.management.AddRastersToMosaicDataset(\n",
    "        in_mosaic_dataset=mosaic_data,\n",
    "        raster_type=\"Raster Dataset\",\n",
    "        input_path=raster_path,\n",
    "        update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "        update_boundary=\"UPDATE_BOUNDARY\",\n",
    "        update_overviews=\"NO_OVERVIEWS\",\n",
    "        maximum_pyramid_levels=None,\n",
    "        maximum_cell_size=0,\n",
    "        minimum_dimension=1500,\n",
    "        spatial_reference=None,\n",
    "        filter=\"\",\n",
    "        sub_folder=\"SUBFOLDERS\",\n",
    "        duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "        build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "        calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "        build_thumbnails=\"NO_THUMBNAILS\",\n",
    "        operation_description=\"\",\n",
    "        force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "        estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "        aux_inputs=None,\n",
    "        enable_pixel_cache=\"NO_PIXEL_CACHE\"\n",
    "    )\n",
    "    \n",
    "    # Get the current date in the format YYYY-MM-DD\n",
    "    # current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Add a unique identifier using timestamp down to microseconds\n",
    "    unique_id = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "    \n",
    "    # Find the highest OBJECTID to identify the newly added raster\n",
    "    max_objectid = None\n",
    "    with arcpy.da.SearchCursor(mosaic_data, [\"objectid\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            if max_objectid is None or row[0] > max_objectid:\n",
    "                max_objectid = row[0]\n",
    "\n",
    "    # Update the fields for the newly added raster\n",
    "    with arcpy.da.UpdateCursor(mosaic_data, [\"objectid\", \"area_upt\", \"date\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] == max_objectid:\n",
    "                row[1] = area\n",
    "                row[2] = current_date\n",
    "                cursor.updateRow(row)\n",
    "\n",
    "    print(f\"Berhasil menambahkan {area}\")\n",
    "\n",
    "# Function to delete rasters older than two months\n",
    "def delete_old_rasters(mosaic_data):\n",
    "    # Calculate the date two months ago from today\n",
    "    \n",
    "    two_months_ago = datetime.now() - timedelta(days=60)\n",
    "    \n",
    "    # Use an UpdateCursor to delete rasters older than two months\n",
    "    with arcpy.da.UpdateCursor(mosaic_data, [\"objectid\", \"date\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            # Check if row[1] is already a datetime object\n",
    "            if isinstance(row[1], datetime):\n",
    "                raster_date = row[1]\n",
    "            else:\n",
    "                raster_date = datetime.strptime(row[1], \"%Y-%m-%d\")\n",
    "            \n",
    "            if raster_date < two_months_ago:\n",
    "                cursor.deleteRow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mosaic_data_ch = os.getenv(\"MOSAIC_DAS_ACH\")\n",
    "mosaic_data_sh = os.getenv(\"MOSAIC_DAS_ASH\")\n",
    "\n",
    "print(\"Raster ACH\")\n",
    "\n",
    "for raster_path, area in raster_ACH_to_merge :\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_ch)\n",
    "\n",
    "delete_old_rasters(mosaic_data_ch)\n",
    "\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=mosaic_data_ch,\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\")\n",
    "\n",
    "print(\"Raster ACH selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raster ASH\")\n",
    "\n",
    "for raster_path, area in raster_ASH_to_merge :\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_sh)\n",
    "\n",
    "delete_old_rasters(mosaic_data_sh)\n",
    "\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=mosaic_data_sh,\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\")\n",
    "\n",
    "print(\"Raster ASH selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import arcpy\n",
    "\n",
    "def delete_old_rasters(mosaic_data):\n",
    "    # Calculate the date two months ago from today\n",
    "    two_months_ago = datetime.now() - timedelta(days=60)\n",
    "    \n",
    "    # Use an UpdateCursor to delete rasters older than two months\n",
    "    with arcpy.da.UpdateCursor(mosaic_data, [\"OBJECTID\", \"date\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            # Check if the date is empty, contains only whitespace, or is an invalid format\n",
    "            if not row[1] or str(row[1]).strip() == \"\":\n",
    "                print(f\"Skipping row with OBJECTID {row[0]} due to missing or invalid date.\")\n",
    "                continue\n",
    "            \n",
    "            # Check if row[1] is already a datetime object\n",
    "            if isinstance(row[1], datetime):\n",
    "                raster_date = row[1]\n",
    "            else:\n",
    "                try:\n",
    "                    raster_date = datetime.strptime(row[1], \"%Y-%m-%d\")\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping row with OBJECTID {row[0]} due to invalid date format.\")\n",
    "                    continue\n",
    "            \n",
    "            # Delete rows where the date is older than two months\n",
    "            if raster_date < two_months_ago:\n",
    "                cursor.deleteRow()\n",
    "                \n",
    "                \n",
    "\n",
    "                from datetime import datetime, timedelta\n",
    "import arcpy\n",
    "\n",
    "def delete_old_rasters2(mosaic_data):\n",
    "    # Calculate the date two months ago from today\n",
    "    two_months_ago = datetime.now() - timedelta(days=60)\n",
    "    \n",
    "    # Use an UpdateCursor to delete rasters older than two months\n",
    "    with arcpy.da.UpdateCursor(mosaic_data, [\"OBJECTID\", \"date\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            # If the date is None, assume it's an old entry and delete it\n",
    "            if row[1] is None:\n",
    "                cursor.deleteRow()\n",
    "                continue\n",
    "            \n",
    "            # Check if row[1] is already a datetime object\n",
    "            if isinstance(row[1], datetime):\n",
    "                raster_date = row[1]\n",
    "            else:\n",
    "                raster_date = datetime.strptime(row[1], \"%Y-%m-%d\")\n",
    "            \n",
    "            # Delete rows where the date is older than two months\n",
    "            if raster_date < two_months_ago:\n",
    "                cursor.deleteRow()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_old_rasters2(mosaic_data_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import datetime\n",
    "import locale\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_clear_fgdb_temp import empty_fgdb\n",
    "from utils.proses1_update_table_summary import update_table\n",
    "from utils.proses1_preprocess import Preprocessing\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "from utils.proses1_data_process import interpolasi_bln, interpolasi_das\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "## Get time\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.now()\n",
    "current_date = datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "# Get geodatabase\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "output_table_name = \"output_1_proses1_table\"\n",
    "output_feature_name = \"output_2_proses1_feature_point\"\n",
    "\n",
    "\n",
    "## Input folder structure\n",
    "main_folder = os.getenv(\"MAIN_FOLDER\")\n",
    "folder_bulanan = r'BULANAN'\n",
    "folder_dasarian = r'DASARIAN'\n",
    "file_name_bulanan = f'BlendGSMAP_POS.{year}{month}.xls'\n",
    "file_name_dasarian = f'BlendGSMAP_POS.{year}{month}dec0{current_dasarian}.xls'\n",
    "\n",
    "# Output folder structure\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "output_level_ind = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA-BULANAN'\n",
    "output_tipe_das = 'ANALISA-DASARIAN'\n",
    "\n",
    "# Get full folder path\n",
    "file_path_bulanan = os.path.join(main_folder, folder_bulanan)\n",
    "file_path_dasarian = os.path.join(main_folder, folder_dasarian)\n",
    "\n",
    "# File input\n",
    "file_input_bulanan = os.path.join(file_path_bulanan, file_name_bulanan)\n",
    "file_input_dasarian = os.path.join(file_path_dasarian, file_name_dasarian)\n",
    "\n",
    "\n",
    "\n",
    "# map project\n",
    "map_project = os.getenv(\"APRX_PROJECT\")\n",
    "\n",
    "preprocessing_das = Preprocessing(fgdb_temp, file_input_dasarian)\n",
    "            \n",
    "            # # Panggil metode Get_Excel untuk mengonversi file Excel ke tabel\n",
    "point_das = preprocessing_das.Excel_to_Feature(output_table_name = output_table_name+'_das', output_feature_name = output_feature_name+'_das')\n",
    "            \n",
    "\n",
    "\n",
    "# # Panggil metode Get_Excel untuk mengonversi file Excel ke tabel\n",
    "\n",
    "\n",
    "\n",
    "print(\"Proses Ekstraksi Table Excel Selesai\")\n",
    "\n",
    "\n",
    "print(\"Proses 1 dimulai\")\n",
    "start_time = datetime.now()\n",
    "print(\"Analisa Data Dasarian dimulai\")\n",
    "\n",
    "poly_indo_ach, poly_indo_ash, raster_ACH_to_merge, raster_ASH_to_merge = interpolasi_das(input_data= point_das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mosaic_data_ch = os.getenv(\"MOSAIC_BLN_ACH\")\n",
    "mosaic_data_sh = os.getenv(\"MOSAIC_BLN_ASH\")\n",
    "\n",
    "print(\"Raster ACH\")\n",
    "\n",
    "for raster_path, area in raster_ACH_to_merge :\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_ch)\n",
    "\n",
    "delete_old_rasters(mosaic_data_ch)\n",
    "\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=mosaic_data_ch,\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\")\n",
    "\n",
    "arcpy.management.SetRasterProperties(\n",
    "        in_raster=mosaic_data_ch,\n",
    "        data_type=\"GENERIC\",\n",
    "        statistics=\"1 0 10000 # #\",\n",
    "        stats_file=None,\n",
    "        nodata=None,\n",
    "        key_properties=None,\n",
    "        multidimensional_info=None,\n",
    "    )\n",
    "\n",
    "print(\"Update Mosaic Raster CH selesai\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Raster ACH selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.proses1_raster_mosaic import copy_raster, add_raster_and_update_fields, delete_old_rasters\n",
    "\n",
    "\n",
    "print(\"Mengupdate Mosaic Raster SH\")\n",
    "mosaic_data_sh = os.getenv(\"MOSAIC_DAS_ASH\")\n",
    "\n",
    "for raster_path, area in raster_ASH_to_merge:\n",
    "    add_raster_and_update_fields(raster_path, area, mosaic_data_sh\n",
    "                                 \n",
    "\n",
    "delete_old_rasters(mosaic_data_sh)\n",
    "\n",
    "arcpy.management.CalculateStatistics(\n",
    "    in_raster_dataset=mosaic_data_sh,\n",
    "    x_skip_factor=1,\n",
    "    y_skip_factor=1,\n",
    "    ignore_values=[],\n",
    "    skip_existing=\"OVERWRITE\")\n",
    "\n",
    "arcpy.management.SetRasterProperties(\n",
    "        in_raster=mosaic_data_sh,\n",
    "        data_type=\"GENERIC\",\n",
    "        statistics=\"1 0 10000 # #\",\n",
    "        stats_file=None,\n",
    "        nodata=None,\n",
    "        key_properties=None,\n",
    "        multidimensional_info=None,\n",
    "    )\n",
    "\n",
    "print(\"Update Mosaic Raster CH selesai\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.proses1_get_download_data import test_download_data_bln, test_download_data_das\n",
    "\n",
    "\n",
    "test_download_data_bln()\n",
    "print(\"data bulanan success\")\n",
    "test_download_data_das()\n",
    "print(\"data dasarian syccess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = r'F:\\\\SIPINTAR-IKLIM-BMKG-PROSES1\\\\DOWNLOAD\\\\DASARIAN'\n",
    "path_2 = r'F:\\SIPINTER-IKLIM-BMKG-PROSES1\\DOWNLOAD\\DASARIAN'\n",
    "if os.path.exists(path_2):\n",
    "    print(\"Ada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = r'F:\\\\SIPINTER-IKLIM-BMKG-PROSES1\\\\DOWNLOAD\\\\DASARIAN'\n",
    "path_2 = r'F:\\SIPINTER-IKLIM-BMKG-PROSES1\\DOWNLOAD\\DASARIAN'\n",
    "\n",
    "print(\"Path exists:\", os.path.exists(path))\n",
    "print(\"Path 2 exists:\", os.path.exists(path_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import datetime\n",
    "import locale\n",
    "from utils.proses1_raster_mosaic import copy_raster, add_raster_and_update_fields, delete_old_rasters\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_clear_fgdb_temp import empty_fgdb\n",
    "from utils.proses1_update_table_summary import update_table\n",
    "from utils.proses1_preprocess import Preprocessing\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "from utils.proses1_data_process import interpolasi_bln, interpolasi_das\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "## Get time\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.now()\n",
    "current_date = datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "# Get geodatabase\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "output_table_name = \"output_1_proses1_table\"\n",
    "output_feature_name = \"output_2_proses1_feature_point\"\n",
    "\n",
    "\n",
    "## Input folder structure\n",
    "main_folder = os.getenv(\"MAIN_FOLDER\")\n",
    "folder_bulanan = r'BULANAN'\n",
    "folder_dasarian = r'DASARIAN'\n",
    "file_name_bulanan = f'BlendGSMAP_POS.{year}{month}.xls'\n",
    "file_name_dasarian = f'BlendGSMAP_POS.{year}{month}dec0{current_dasarian}.xls'\n",
    "\n",
    "# Output folder structure\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "output_level_ind = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA-BULANAN'\n",
    "output_tipe_das = 'ANALISA-DASARIAN'\n",
    "\n",
    "# Get full folder path\n",
    "file_path_bulanan = os.path.join(main_folder, folder_bulanan)\n",
    "file_path_dasarian = os.path.join(main_folder, folder_dasarian)\n",
    "\n",
    "# File input\n",
    "file_input_bulanan = os.path.join(file_path_bulanan, file_name_bulanan)\n",
    "file_input_dasarian = os.path.join(file_path_dasarian, file_name_dasarian)\n",
    "\n",
    "\n",
    "\n",
    "# map project\n",
    "map_project = os.getenv(\"APRX_PROJECT\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists(file_input_dasarian):\n",
    "        try:\n",
    "            print(\"Proses Ekstraksi Table Excel dimulai ... \")\n",
    "\n",
    "            # Memulai ekstraksi excel ke feature point\n",
    "            \n",
    "            preprocessing_das = Preprocessing(fgdb_temp, file_input_dasarian)\n",
    "\n",
    "            # # Panggil metode Get_Excel untuk mengonversi file Excel ke tabel\n",
    "        \n",
    "            point_das = preprocessing_das.Excel_to_Feature(output_table_name = output_table_name+'_das', output_feature_name = output_feature_name+'_das')\n",
    "\n",
    "            print(\"Proses Ekstraksi Table Excel Selesai\")\n",
    "\n",
    "\n",
    "            print(\"Proses 1 dimulai\")\n",
    "            start_time = datetime.now()\n",
    "            print(\"Analisa Data Dasarian dimulai\")\n",
    "\n",
    "            poly_indo_ach, poly_indo_ash, raster_ACH_to_merge, raster_ASH_to_merge = interpolasi_das(input_data= point_das)\n",
    "            \n",
    "\n",
    "            end_time = datetime.now()\n",
    "            duration = end_time - start_time\n",
    "\n",
    "            print(f\"Analisa Data Dasarian selesai selama: {(duration.total_seconds() % 3600) // 60} menit\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "            print(\"Proses Pembuatan Laporan Dasarian dimulai\")\n",
    "\n",
    "            start_time = datetime.now()\n",
    "\n",
    "            pelaporan = PembuatanPetaLaporan(map_project=map_project)\n",
    "\n",
    "            peta1_bulanan = pelaporan.peta_1(periode_informasi='ANALISA_DASARIAN')\n",
    "\n",
    "            peta2_bulanan = pelaporan.peta_2(periode_informasi='ANALISA_DASARIAN')\n",
    "\n",
    "            infografis_ch = pelaporan.infografis_das(feature = poly_indo_ach, tipe_informasi='ANALISA_CURAH_HUJAN')\n",
    "\n",
    "            infografis_sh = pelaporan.infografis_das(feature = poly_indo_ash, tipe_informasi='ANALISA_SIFAT_HUJAN')\n",
    "\n",
    "            laporan_ch = pelaporan.laporan_das2(feature = poly_indo_ach, tipe_informasi='ANALISA_CURAH_HUJAN')\n",
    "\n",
    "            laporan_sh = pelaporan.laporan_das2(feature = poly_indo_ash, tipe_informasi='ANALISA_SIFAT_HUJAN')\n",
    "\n",
    "\n",
    "            end_time = datetime.now()\n",
    "            duration2 = end_time - start_time\n",
    "\n",
    "\n",
    "            print(f\"Proses 1 selesai selama: {(duration2.total_seconds() % 3600) // 60} menit\")\n",
    "\n",
    "\n",
    "            print(\"Mengupdate Tabel Summary\")\n",
    "\n",
    "            update_table(feature = poly_indo_ach, tipe_informasi='ANALISA_CURAH_HUJAN', periode='DASARIAN')\n",
    "            update_table(feature = poly_indo_ash, tipe_informasi='ANALISA_SIFAT_HUJAN', periode='DASARIAN')\n",
    "\n",
    "            print(\"Update Tabel Summary selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "            print(\"Mengupdate Mosaic Raster CH\")\n",
    "            mosaic_data_ch = os.getenv(\"MOSAIC_DAS_ACH\")\n",
    "\n",
    "            for raster_path, area in raster_ACH_to_merge:\n",
    "                add_raster_and_update_fields(raster_path, area, mosaic_data_ch)\n",
    "                \n",
    "            time.sleep(20)\n",
    "\n",
    "            delete_old_rasters(mosaic_data_ch)\n",
    "\n",
    "            arcpy.management.CalculateStatistics(\n",
    "                in_raster_dataset=mosaic_data_ch,\n",
    "                x_skip_factor=1,\n",
    "                y_skip_factor=1,\n",
    "                ignore_values=[],\n",
    "                skip_existing=\"OVERWRITE\")\n",
    "            \n",
    "            arcpy.management.SetRasterProperties(\n",
    "                    in_raster=mosaic_data_ch,\n",
    "                    data_type=\"GENERIC\",\n",
    "                    statistics=\"1 0 10000 # #\",\n",
    "                    stats_file=None,\n",
    "                    nodata=None,\n",
    "                    key_properties=None,\n",
    "                    multidimensional_info=None,\n",
    "                )\n",
    "            \n",
    "            print(\"Update Mosaic Raster CH selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "            print(\"Mengupdate Mosaic Raster SH\")\n",
    "            mosaic_data_sh = os.getenv(\"MOSAIC_DAS_ASH\")\n",
    "\n",
    "            for raster_path, area in raster_ASH_to_merge:\n",
    "                add_raster_and_update_fields(raster_path, area, mosaic_data_sh)\n",
    "            \n",
    "            time.sleep(20)\n",
    "\n",
    "            delete_old_rasters(mosaic_data_sh)\n",
    "\n",
    "            arcpy.management.CalculateStatistics(\n",
    "                in_raster_dataset=mosaic_data_sh,\n",
    "                x_skip_factor=1,\n",
    "                y_skip_factor=1,\n",
    "                ignore_values=[],\n",
    "                skip_existing=\"OVERWRITE\")\n",
    "\n",
    "            arcpy.management.SetRasterProperties(\n",
    "                    in_raster=mosaic_data_sh,\n",
    "                    data_type=\"GENERIC\",\n",
    "                    statistics=\"1 0 10000 # #\",\n",
    "                    stats_file=None,\n",
    "                    nodata=None,\n",
    "                    key_properties=None,\n",
    "                    multidimensional_info=None,\n",
    "                )\n",
    "            print(\"Update Mosaic Raster SH selesai\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "            print(\"Hapus semua data temp\")\n",
    "            empty_fgdb(fgdb_temp)\n",
    "            print(\"Data temp terhapus\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Input Data Terbaru Tidak Ditemukan atau Belum Terupdate\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "from config import extent_pulau, pulau_feature, titik_grid, nama_prov, poly_kecamatan, nama_prov_folder\n",
    "from utils.proses1_raster_mosaic import copy_raster, add_raster_and_update_fields, delete_old_rasters\n",
    "from utils.proses1_archiving import ArchivingFolder\n",
    "from utils.dasarian import get_current_dasarian\n",
    "import arcgis\n",
    "from arcgis.features import GeoAccessor\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import locale\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set time for dataset\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "\n",
    "# Set parameter\n",
    "gridsize_pkecil = os.getenv(\"GRID_PKECIL\")\n",
    "gridsize_pbesar= os.getenv(\"GRID_PBESAR\")\n",
    "\n",
    "\n",
    "# Set folder structure\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "output_level_ind = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA_BULANAN'\n",
    "output_tipe_das = 'ANALISA_DASARIAN'\n",
    "\n",
    "\n",
    "\n",
    "# All output folder path Bulanan - Prov\n",
    "output_prov = os.path.join(output_folder, output_level_prov)\n",
    "\n",
    "\n",
    "# Set file to loop code\n",
    "pulau_reference = os.getenv(\"PULAU_REFERENCE\")\n",
    "pulau_besar_merge = os.getenv(\"PULAU_BESAR_MERGE\")\n",
    "\n",
    "\n",
    "# Set data for I/O\n",
    "raster_loc = os.getenv(\"RASTER_LOC\")\n",
    "fgdb_input = os.getenv(\"FGDB_TEMP\")\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "mosaic_bln_ch= os.getenv(\"MOSAIC_BLN_ACH\")\n",
    "mosaic_bln_sh= os.getenv(\"MOSAIC_BLN_ASH\")\n",
    "mosaic_das_ch= os.getenv(\"MOSAIC_DAS_ACH\")\n",
    "mosaic_das_sh= os.getenv(\"MOSAIC_DAS_ASH\")\n",
    "main_output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "input_data_bln = os.path.join(fgdb_temp, 'output_2_proses1_feature_point_bln')\n",
    "input_data_das = os.path.join(fgdb_temp, 'output_2_proses1_feature_point_das')\n",
    "\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Environment ArcPY\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "## Get time\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.now()\n",
    "current_date = datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "\n",
    "\n",
    "# Get geodatabase\n",
    "fgdb_temp = os.getenv(\"FGDB_TEMP\")\n",
    "output_table_name = \"output_1_proses1_table\"\n",
    "output_feature_name = \"output_2_proses1_feature_point\"\n",
    "\n",
    "\n",
    "## Input folder structure\n",
    "main_folder = os.getenv(\"MAIN_FOLDER\")\n",
    "folder_bulanan = r'BULANAN'\n",
    "folder_dasarian = r'DASARIAN'\n",
    "file_name_bulanan = f'BlendGSMAP_POS.{year}{month}.xls'\n",
    "file_name_dasarian = f'BlendGSMAP_POS.{year}{month}dec0{current_dasarian}.xls'\n",
    "\n",
    "# Output folder structure\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "output_level_ind = 'INDONESIA'\n",
    "output_level_prov = 'PROVINSI'\n",
    "output_tipe_bln = 'ANALISA-BULANAN'\n",
    "output_tipe_das = 'ANALISA-DASARIAN'\n",
    "\n",
    "# Get full folder path\n",
    "file_path_dasarian = os.path.join(main_folder, folder_dasarian)\n",
    "\n",
    "# File input\n",
    "file_input_dasarian = os.path.join(file_path_dasarian, file_name_dasarian)\n",
    "\n",
    "\n",
    "# map project\n",
    "map_project = os.getenv(\"APRX_PROJECT\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Proses Download Data dimulai ... \")\n",
    "test_download_data_das()\n",
    "print(\"Proses Download Data selesai ... \")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Proses Ekstraksi Table Excel dimulai ... \")\n",
    "\n",
    "# Memulai ekstraksi excel ke feature point\n",
    "\n",
    "preprocessing_das = Preprocessing(fgdb_temp, file_input_dasarian)\n",
    "\n",
    "# # Panggil metode Get_Excel untuk mengonversi file Excel ke tabel\n",
    "\n",
    "point_das = preprocessing_das.Excel_to_Feature(output_table_name = output_table_name+'_das', output_feature_name = output_feature_name+'_das')\n",
    "\n",
    "\n",
    "print(\"PROSES ANALISA DASARIAN DIMULAI . . .\")\n",
    "    \n",
    "raster_ACH_to_merge = []\n",
    "raster_ASH_to_merge = []\n",
    "raster_ACH_to_merge_tif = []\n",
    "raster_ASH_to_merge_tif = []\n",
    "ACH_to_merge = []\n",
    "ASH_to_merge = []\n",
    "CSV_to_merge = []\n",
    "\n",
    "poly_indo_ach = None\n",
    "poly_indo_ash = None\n",
    "\n",
    "\n",
    "with arcpy.da.SearchCursor(pulau_reference, [[\"Pulau_Singkat\", [\"Is_Besar\"]]]) as cursors:  # Membaca feature service untuk mmeisahkan proses looping pulau besar dan pulau kecil berdasarkan atribut\n",
    "    for r in cursors:\n",
    "        try:\n",
    "            if r[1] == \"False\":  # val False = Pulau Kecil dan va True = Pulau Besar\n",
    "                pulau_kecil = r[0]\n",
    "                print(f\"Memulai Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "\n",
    "                ####### Proses untuk kategori pulau kecil\\\n",
    "                ####### Proses ACH untuk kategori pulau kecil\n",
    "                # Create new folder\n",
    "\n",
    "                pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                   output_tipe_periode=output_tipe_das, tipe='TIFF', \n",
    "                                                                   nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "\n",
    "                # Start Process\n",
    "\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features= input_data,\n",
    "                        z_field=\"CH\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(output_loc_tiff, f\"ach_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\"),\n",
    "                        cell_size=gridsize_pkecil,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "                raster_ach_pk = arcpy.Raster(os.path.join(output_loc_tiff, f\"ach_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\"))\n",
    "                raster_ach_pk_copy = os.path.join(raster_loc, f\"ach_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "\n",
    "                copy_raster(raster_ach_pk, raster_ach_pk_copy)\n",
    "\n",
    "                row_list_ch = (raster_ach_pk_copy, f'{pulau_kecil}')\n",
    "\n",
    "                raster_ACH_to_merge.append(row_list_ch)\n",
    "\n",
    "\n",
    "                raster_ACH_to_merge_tif.append(raster_ach_pk)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Interpolasi ACH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "                # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "                # arcpy.management.AddRastersToMosaicDataset(\n",
    "                #                 in_mosaic_dataset= mosaic_bln_ch,\n",
    "                #                 raster_type=\"Raster Dataset\",\n",
    "                #                 input_path= raster_ach_pk,\n",
    "                #                 update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                #                 update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                #                 update_overviews=\"NO_OVERVIEWS\",\n",
    "                #                 maximum_pyramid_levels=None,\n",
    "                #                 maximum_cell_size=0,\n",
    "                #                 minimum_dimension=1500,\n",
    "                #                 spatial_reference=None,\n",
    "                #                 filter=\"\",\n",
    "                #                 sub_folder=\"SUBFOLDERS\",\n",
    "                #                 duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                #                 build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                #                 calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                #                 build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                #                 operation_description=\"\",\n",
    "                #                 force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                #                 estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                #                 aux_inputs=None,\n",
    "                #                 enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                #                 cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "                # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai ...\")\n",
    "\n",
    "                pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                output_loc_csv = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                   output_tipe_periode=output_tipe_das, tipe='CSV', \n",
    "                                                                   nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "\n",
    "\n",
    "                titik_grid_extract_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}das0{current_dasarian}\")\n",
    "                arcpy.management.CopyFeatures(in_features=titik_grid[pulau_kecil], out_feature_class=titik_grid_extract_pk)\n",
    "                point_extracted_pk = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pk, [[raster_ach_pk, \"CH\"]], \"NONE\")\n",
    "                # point_extracted_ch.save()\n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Reclassify ACH Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                out_raster_ach_pk = arcpy.sa.Reclassify(\n",
    "                    in_raster=raster_ach_pk,\n",
    "                    reclass_field=\"VALUE\",\n",
    "                    remap=\"0 10 1;10 20 2;20 50 3;50 75 4;75 100 5;100 150 6;150 200 7;200 300 8;300 10000 9\",\n",
    "                    missing_values=\"DATA\")\n",
    "\n",
    "                out_raster_ach_pk.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{pulau_kecil}_{year}{month}das0{current_dasarian}\"))\n",
    "                print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                # Pembuatan archive\n",
    "                output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                   output_tipe_periode=output_tipe_das, tipe='SHP', \n",
    "                                                                   nama_prov=nama_prov_folder, pulau_kecil=pulau_kecil)\n",
    "                Output_polygon_features_ach = os.path.join(fgdb_temp, f\"ach_das_{pulau_kecil}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                arcpy.conversion.RasterToPolygon(in_raster=out_raster_ach_pk, out_polygon_features=Output_polygon_features_ach)\n",
    "                arcpy.management.AddFields(in_table=Output_polygon_features_ach, field_description= \"CH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                arcpy.management.CalculateField(\n",
    "                            in_table=Output_polygon_features_ach,\n",
    "                            field=\"CH\",\n",
    "                            expression=\"ch(!gridcode!)\",\n",
    "                            expression_type=\"PYTHON3\",\n",
    "                            code_block=\"\"\"def ch(x):\n",
    "                            if x == 1:\n",
    "                                return \"0-10\"\n",
    "                            elif x == 2:\n",
    "                                return \"11-20\"\n",
    "                            elif x == 3:\n",
    "                                return \"21-50\"\n",
    "                            elif x == 4:\n",
    "                                return \"51-75\"\n",
    "                            elif x == 5:\n",
    "                                return \"76-100\"\n",
    "                            elif x == 6:\n",
    "                                return \"101-150\"\n",
    "                            elif x == 7:\n",
    "                                return \"151-200\"\n",
    "                            elif x == 8:\n",
    "                                return \"201-300\"\n",
    "                            elif x ==9 :\n",
    "                                return \">300\"\n",
    "                            \"\"\",\n",
    "                            field_type=\"TEXT\",\n",
    "                            enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                arcpy.management.CalculateField(\n",
    "                            in_table=Output_polygon_features_ach,\n",
    "                            field=\"Kategori\",\n",
    "                            expression=\"cat(!gridcode!)\",\n",
    "                            expression_type=\"PYTHON3\",\n",
    "                            code_block=\"\"\"def cat(x):\n",
    "                            if x == 1:\n",
    "                                return \"Rendah\"\n",
    "                            elif x == 2:\n",
    "                                return \"Rendah\"\n",
    "                            elif x == 3:\n",
    "                                return \"Rendah\"\n",
    "                            elif x == 4:\n",
    "                                return \"Menengah\"\n",
    "                            elif x == 5:\n",
    "                                return \"Menengah\"\n",
    "                            elif x == 6:\n",
    "                                return \"Menengah\"\n",
    "                            elif x == 7:\n",
    "                                return \"Tinggi\"\n",
    "                            elif x == 8:\n",
    "                                return \"Sangat Tinggi\"\n",
    "                            elif x ==9 :\n",
    "                                return \"Sangat Tinggi\"\n",
    "                            \"\"\",\n",
    "                            field_type=\"TEXT\",\n",
    "                            enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "                arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ach,\n",
    "                                        field=\"Periode\",\n",
    "                                        expression=f'\"Dasarian {current_dasarian} {month_name} {year}\"',\n",
    "                                        expression_type=\"PYTHON3\"\n",
    "                                    )\n",
    "                arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"Informasi\",\n",
    "                                    expression='\"Curah Hujan\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "\n",
    "                poly_kec = poly_kecamatan[pulau_kecil]\n",
    "\n",
    "                Output_polygon_features_ach_union = os.path.join(output_loc_shp, f\"ach_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ach], \n",
    "                                     out_feature_class=Output_polygon_features_ach_union)\n",
    "\n",
    "\n",
    "                arcpy.management.AddField(\n",
    "                            in_table=Output_polygon_features_ach_union,\n",
    "                            field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                arcpy.management.CalculateGeometryAttributes(\n",
    "                        in_features=Output_polygon_features_ach_union,\n",
    "                        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                        area_unit=\"HECTARES\")\n",
    "\n",
    "\n",
    "\n",
    "                # Menggabungkan polygon untuk di merge\n",
    "                ACH_to_merge.append(Output_polygon_features_ach)\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "                ####### Proses ASH untuk kategori pulau kecil\n",
    "                print(f\"Memulai Proses Interpolasi ASH Pulau Kecil: {pulau_kecil} . . .\")\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_kecil], mask=pulau_feature[pulau_kecil]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features=input_data,\n",
    "                        z_field=\"SH_\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(output_loc_tiff, f\"ash_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\"),\n",
    "                        cell_size=gridsize_pkecil,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "\n",
    "                raster_ash_pk = arcpy.Raster(os.path.join(output_loc_tiff, f\"ash_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\"))\n",
    "\n",
    "                raster_ash_pk_copy = os.path.join(raster_loc, f\"ash_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "\n",
    "                copy_raster(raster_ash_pk, raster_ash_pk_copy)\n",
    "\n",
    "                row_list_sh = (raster_ash_pk_copy, f'{pulau_kecil}')\n",
    "\n",
    "                raster_ASH_to_merge.append(row_list_sh)\n",
    "\n",
    "                raster_ASH_to_merge_tif.append(raster_ash_pk)\n",
    "\n",
    "\n",
    "                print(f\"Proses Interpolasi ASH Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "                # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} dimulai . . .. \")\n",
    "                # arcpy.management.AddRastersToMosaicDataset(\n",
    "                #                 in_mosaic_dataset= mosaic_bln_sh,\n",
    "                #                 raster_type=\"Raster Dataset\",\n",
    "                #                 input_path= raster_ash_pk,\n",
    "                #                 update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                #                 update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                #                 update_overviews=\"NO_OVERVIEWS\",\n",
    "                #                 maximum_pyramid_levels=None,\n",
    "                #                 maximum_cell_size=0,\n",
    "                #                 minimum_dimension=1500,\n",
    "                #                 spatial_reference=None,\n",
    "                #                 filter=\"\",\n",
    "                #                 sub_folder=\"SUBFOLDERS\",\n",
    "                #                 duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                #                 build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                #                 calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                #                 build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                #                 operation_description=\"\",\n",
    "                #                 force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                #                 estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                #                 aux_inputs=None,\n",
    "                #                 enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                #                 cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_SH\")\n",
    "                # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {pulau_kecil} selesai \")\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Extract Point Pulau Kecil: {pulau_kecil} dimulai . . .\")\n",
    "                point_extracted_pk = os.path.join(fgdb_temp, f\"Titik_extract_{pulau_kecil}_{year}{month}das0{current_dasarian}\")\n",
    "                arcpy.sa.ExtractMultiValuesToPoints(point_extracted_pk, [[raster_ash_pk, \"SH\"]], \"NONE\")\n",
    "                # point_extracted_sh.save()\n",
    "                arcpy.management.AddFields(in_table=point_extracted_pk, field_description=[[\"LAT\", \"DOUBLE\", \"Latitude\", \"\", \"\", \"\"], [\"LONG\", \"DOUBLE\", \"Longitude\", \"\", \"\", \"\"]])[0]\n",
    "                arcpy.management.CalculateGeometryAttributes(in_features=point_extracted_pk, geometry_property=[[\"LAT\", \"POINT_Y\"], [\"LONG\", \"POINT_X\"]], coordinate_system=\"PROJCS[\\\"WGS_1984_Web_Mercator_Auxiliary_Sphere\\\",GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Mercator_Auxiliary_Sphere\\\"],PARAMETER[\\\"False_Easting\\\",0.0],PARAMETER[\\\"False_Northing\\\",0.0],PARAMETER[\\\"Central_Meridian\\\",0.0],PARAMETER[\\\"Standard_Parallel_1\\\",0.0],PARAMETER[\\\"Auxiliary_Sphere_Type\\\",0.0],UNIT[\\\"Meter\\\",1.0]]\", \n",
    "                                                                        coordinate_format=\"DD\")[0]\n",
    "                print(f\"Proses Extract Point Provinsi: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Export to csv Provinsi: {pulau_kecil} dimulai . . .\")\n",
    "                out_csv_table_pk = os.path.join(output_loc_csv, f\"das_{pulau_kecil.lower()}_ver_{year}0{month}das0{current_dasarian}.csv\")\n",
    "                arcpy.conversion.ExportTable(\n",
    "                                in_table= point_extracted_pk,\n",
    "                                out_table= out_csv_table_pk,\n",
    "                                where_clause=\"\",\n",
    "                                use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "                                field_mapping=None,\n",
    "                                sort_field=None)\n",
    "\n",
    "                # Menggabungkan csv untuk di merge\n",
    "                CSV_to_merge.append(out_csv_table_pk)\n",
    "                print(f\"Proses Export to csv Provinsi: {pulau_kecil} selesai\")\n",
    "\n",
    "\n",
    "                print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                out_raster_ash_pk = arcpy.sa.Reclassify(\n",
    "                    in_raster=raster_ash_pk,\n",
    "                    reclass_field=\"VALUE\",\n",
    "                    remap=\"0 30 1;30 50 2;50 84 3;84 115 4;115 150 5;150 200 6;200 10000 7\",\n",
    "                    missing_values=\"DATA\")\n",
    "\n",
    "                out_raster_ash_pk.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{pulau_kecil}_{year}{month}das0{current_dasarian}\"))\n",
    "                print(f\"Proses Reclassify Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} dimulai . . . . . . . . . . . .\")\n",
    "                Output_polygon_features_ash = os.path.join(fgdb_temp, f\"ash_das_{pulau_kecil}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                arcpy.conversion.RasterToPolygon(in_raster=out_raster_ash_pk, out_polygon_features=Output_polygon_features_ash)\n",
    "                arcpy.management.AddFields(in_table=Output_polygon_features_ash, field_description= \"SH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"SH\",\n",
    "                                        expression=\"sh(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def sh(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"0-30\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"31-50\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"51-84\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"85-115\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"116-150\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"151-200\"\n",
    "                                        elif x == 7:\n",
    "                                            return \">200\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"Kategori\",\n",
    "                                        expression=\"kategori(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def kategori(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"Normal\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "                arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"Periode\",\n",
    "                                        expression=f'\"Dasarian {current_dasarian} {month_name} {year}\"',\n",
    "                                        expression_type=\"PYTHON3\"\n",
    "                                    )\n",
    "                arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Informasi\",\n",
    "                                    expression='\"Sifat Hujan\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "\n",
    "\n",
    "                poly_kec = poly_kecamatan[pulau_kecil]\n",
    "\n",
    "                Output_polygon_features_ash_union = os.path.join(output_loc_shp, f\"ash_das_{pulau_kecil.lower()}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ash], \n",
    "                                     out_feature_class=Output_polygon_features_ash_union)\n",
    "\n",
    "                arcpy.management.AddField(\n",
    "                            in_table=Output_polygon_features_ash_union,\n",
    "                            field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                arcpy.management.CalculateGeometryAttributes(\n",
    "                        in_features=Output_polygon_features_ash_union,\n",
    "                        geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                        area_unit=\"HECTARES\")\n",
    "\n",
    "\n",
    "\n",
    "                # menggabungkan polygon untuk di merge\n",
    "                ASH_to_merge.append(Output_polygon_features_ash)\n",
    "                print(f\"Proses Konversi Raster to Polygon Pulau Kecil: {pulau_kecil} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "            ####### Proses untuk kategori pulau besar\n",
    "            ####### Proses ACH Pulau Besar\n",
    "            else:\n",
    "                pulau_besar = r[0]\n",
    "                print(f\"Memulai Proses Interpolasi ACH Pulau Besar: {pulau_besar} . . .\")\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_besar], mask=pulau_feature[pulau_besar]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features=input_data,\n",
    "                        z_field=\"CH\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(fgdb_temp, f\"interpolasi_ACH_Pulau_{pulau_besar}_{year}{month}das0{current_dasarian}\"),\n",
    "                        cell_size=gridsize_pbesar,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "                raster_ach_pb = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ACH_Pulau_{pulau_besar}_{year}{month}das0{current_dasarian}\"))\n",
    "\n",
    "\n",
    "                #raster_ACH_to_merge.append(raster_ach_pb)\n",
    "\n",
    "\n",
    "                print(f\"Proses Interpolasi ACH Pulau Besar: {pulau_besar} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "                ######### Proses Masking ACH\n",
    "                print(f\"Proses Masking ACH Pulau Besar: {pulau_besar} dimulai . . .\")\n",
    "                with arcpy.da.SearchCursor(pulau_besar_merge, [[\"Pulau\", [\"Provinsi_Singkat\"]]]) as masks:\n",
    "                    for r in masks:\n",
    "                        pulau_mask = r[0]\n",
    "                        provinsi = r[1]\n",
    "                        if pulau_mask == pulau_besar:\n",
    "                            print(f\"Memulai Mask Provinsi: {provinsi}  . . .\")\n",
    "\n",
    "                            # Membuat archive folder\n",
    "                            print(\"Membuat Archive\")\n",
    "                            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                            output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                   output_tipe_periode=output_tipe_das, tipe='TIFF', \n",
    "                                                                   nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                            print(\"Selesai Archive\")\n",
    "\n",
    "\n",
    "                            Extract_rast_ch = os.path.join(output_loc_tiff, f\"ach_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "                            Extract_by_Mask = Extract_rast_ch\n",
    "                            Extract_rast_ch = arcpy.sa.ExtractByMask(raster_ach_pb, pulau_feature[provinsi], \"INSIDE\", extent_pulau[provinsi])\n",
    "                            Extract_rast_ch.save(Extract_by_Mask)\n",
    "\n",
    "                            Extract_rast_ch_copy = os.path.join(raster_loc, f\"ach_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "\n",
    "                            copy_raster(Extract_rast_ch, Extract_rast_ch_copy)\n",
    "\n",
    "                            row_list_ch = (Extract_rast_ch_copy, f'{provinsi}')\n",
    "\n",
    "                            raster_ACH_to_merge.append(row_list_ch)\n",
    "\n",
    "                            raster_ACH_to_merge_tif.append(Extract_rast_ch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Proses Mask Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} dimulai . . .. \")\n",
    "                            # arcpy.management.AddRastersToMosaicDataset(\n",
    "                            #     in_mosaic_dataset= mosaic_bln_ch,\n",
    "                            #     raster_type=\"Raster Dataset\",\n",
    "                            #     input_path= Extract_rast_ch,\n",
    "                            #     update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                            #     update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                            #     update_overviews=\"NO_OVERVIEWS\",\n",
    "                            #     maximum_pyramid_levels=None,\n",
    "                            #     maximum_cell_size=0,\n",
    "                            #     minimum_dimension=1500,\n",
    "                            #     spatial_reference=None,\n",
    "                            #     filter=\"\",\n",
    "                            #     sub_folder=\"SUBFOLDERS\",\n",
    "                            #     duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                            #     build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                            #     calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                            #     build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                            #     operation_description=\"\",\n",
    "                            #     force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                            #     estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                            #     aux_inputs=None,\n",
    "                            #     enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                            #     cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_CH\")\n",
    "                            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} selesai \")\n",
    "\n",
    "\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} dimulai ...\")\n",
    "                            titik_grid_extract_pb = os.path.join(fgdb_temp, f\"Titik_extract_{provinsi}_{year}{month}das0{current_dasarian}\")\n",
    "                            arcpy.management.CopyFeatures(in_features=titik_grid[provinsi], out_feature_class=titik_grid_extract_pb)\n",
    "                            point_extracted_pb = arcpy.sa.ExtractMultiValuesToPoints(titik_grid_extract_pb, [[Extract_rast_ch, \"CH\"]], \"NONE\")\n",
    "                            # point_extracted_ch.save()\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Memulai Reclassify Provinsi: {provinsi}  . . .\")\n",
    "                            out_raster_ach_pb = arcpy.sa.Reclassify(in_raster=Extract_rast_ch,\n",
    "                                                            reclass_field=\"VALUE\",\n",
    "                                                            remap=\"0 10 1;10 20 2;20 50 3;50 75 4;75 100 5;100 150 6;150 200 7;200 300 8;300 10000 9\",\n",
    "                                                            missing_values=\"DATA\")\n",
    "\n",
    "                            out_raster_ach_pb.save(os.path.join(fgdb_temp, f\"Reclass_ACH_{provinsi}_{year}{month}das0{current_dasarian}\"))\n",
    "                            print(f\"Proses Reclassify Provinsi: {provinsi} telah selesai\")\n",
    "\n",
    "\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} dimulai . . . . . . . . . . . .\")\n",
    "                            # Membuat archive folder\n",
    "                            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                            output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                   output_tipe_periode=output_tipe_das, tipe='SHP', \n",
    "                                                                   nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                            Output_polygon_features_ach = os.path.join(fgdb_temp, f\"ach_das_{provinsi}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                            arcpy.conversion.RasterToPolygon(in_raster=out_raster_ach_pb, out_polygon_features=Output_polygon_features_ach)\n",
    "                            arcpy.management.AddFields(in_table=Output_polygon_features_ach, field_description= \"CH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ach,\n",
    "                                        field=\"CH\",\n",
    "                                        expression=\"ch(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def ch(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"0-10\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"11-20\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"21-50\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"51-75\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"76-100\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"101-150\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"151-200\"\n",
    "                                        elif x == 8:\n",
    "                                            return \"201-300\"\n",
    "                                        elif x ==9 :\n",
    "                                            return \">300\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ach,\n",
    "                                        field=\"Kategori\",\n",
    "                                        expression=\"cat(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def cat(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"Rendah\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"Rendah\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"Rendah\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"Menengah\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"Menengah\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"Menengah\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"Tinggi\"\n",
    "                                        elif x == 8:\n",
    "                                            return \"Sangat Tinggi\"\n",
    "                                        elif x ==9 :\n",
    "                                            return \"Sangat Tinggi\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ach,\n",
    "                                        field=\"Periode\",\n",
    "                                        expression=f'\"Dasarian {current_dasarian} {month_name} {year}\"',\n",
    "                                        expression_type=\"PYTHON3\"\n",
    "                                    )\n",
    "                            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ach,\n",
    "                                    field=\"Informasi\",\n",
    "                                    expression='\"Curah Hujan\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "\n",
    "                            poly_kec = poly_kecamatan[provinsi]\n",
    "\n",
    "                            Output_polygon_features_ach_union = os.path.join(output_loc_shp, f\"ach_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                            arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ach], \n",
    "                                     out_feature_class= Output_polygon_features_ach_union)\n",
    "\n",
    "\n",
    "                            arcpy.management.AddField(\n",
    "                                        in_table=Output_polygon_features_ach_union,\n",
    "                                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                            arcpy.management.CalculateGeometryAttributes(\n",
    "                                    in_features=Output_polygon_features_ach_union,\n",
    "                                    geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                                    area_unit=\"HECTARES\")\n",
    "\n",
    "\n",
    "\n",
    "                            # Menggabungkan polygon untuk di merge\n",
    "                            ACH_to_merge.append(Output_polygon_features_ach)\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} telah selesai\")\n",
    "                            print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "                ####### Proses ASH Pulau Besar\n",
    "                ####### Proses Interpolasi ASH\n",
    "                print(f\"Memulai Proses Interpolasi ASH Pulau Besar: {pulau_besar}\")\n",
    "\n",
    "                with arcpy.EnvManager(extent=extent_pulau[pulau_besar], mask=pulau_feature[pulau_besar]):\n",
    "                    arcpy.ga.IDW(\n",
    "                        in_features=input_data,\n",
    "                        z_field=\"SH_\",\n",
    "                        out_ga_layer=None,\n",
    "                        out_raster=os.path.join(fgdb_temp, f\"interpolasi_ASH_Pulau_{pulau_besar}_{year}{month}das0{current_dasarian}\"),\n",
    "                        cell_size=gridsize_pbesar,\n",
    "                        power=2,\n",
    "                        search_neighborhood=\"NBRTYPE=Standard S_MAJOR=12,2269298067831 S_MINOR=12,2269298067831 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "                        weight_field=None\n",
    "                    )\n",
    "\n",
    "                raster_ash = arcpy.Raster(os.path.join(fgdb_temp, f\"interpolasi_ASH_Pulau_{pulau_besar}_{year}{month}das0{current_dasarian}\"))\n",
    "\n",
    "                #raster_ASH_to_merge.append(raster_ash)\n",
    "\n",
    "                print(f\"Proses Interpolasi ASH Pulau Besar: {pulau_besar} telah selesai\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "                ######### Proses Masking ASH\n",
    "                print(f\"Proses Masking ASH Pulau Besar: {pulau_besar} dimulai . . .\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                with arcpy.da.SearchCursor(pulau_besar_merge, [[\"Pulau\", [\"Provinsi_Singkat\"]]]) as masks:\n",
    "                    for r in masks:\n",
    "                        pulau_mask = r[0]\n",
    "                        provinsi = r[1]\n",
    "                        if pulau_mask == pulau_besar:\n",
    "                            print(f\"Memulai Mask ASH Provinsi: {provinsi}  . . .\")\n",
    "\n",
    "\n",
    "                            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                            output_loc_tiff = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                        output_tipe_periode=output_tipe_das, tipe='TIFF', \n",
    "                                                        nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "\n",
    "\n",
    "                            Extract_rast_sh = os.path.join(output_loc_tiff, f\"ash_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "                            Extract_by_Mask = Extract_rast_sh\n",
    "                            Extract_rast_sh = arcpy.sa.ExtractByMask(raster_ash, pulau_feature[provinsi], \"INSIDE\", extent_pulau[provinsi])\n",
    "                            Extract_rast_sh.save(Extract_by_Mask)\n",
    "\n",
    "\n",
    "                            Extract_rast_sh_copy = os.path.join(raster_loc, f\"ash_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}.tif\")\n",
    "\n",
    "                            copy_raster(Extract_rast_sh, Extract_rast_sh_copy)\n",
    "\n",
    "                            row_list_sh = (Extract_rast_sh_copy, f'{provinsi}')\n",
    "\n",
    "                            raster_ASH_to_merge.append(row_list_sh)\n",
    "\n",
    "                            raster_ASH_to_merge_tif.append(Extract_rast_sh)\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Proses Mask Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} dimulai . . .\")\n",
    "                            point_extracted_pb = os.path.join(fgdb_temp, f\"Titik_extract_{provinsi}_{year}{month}das0{current_dasarian}\")\n",
    "                            arcpy.sa.ExtractMultiValuesToPoints(point_extracted_pb, [[Extract_rast_sh, \"SH\"]], \"NONE\")\n",
    "                            arcpy.management.AddFields(in_table=point_extracted_pb, field_description=[[\"LAT\", \"DOUBLE\", \"Latitude\", \"\", \"\", \"\"], [\"LONG\", \"DOUBLE\", \"Longitude\", \"\", \"\", \"\"]])[0]\n",
    "                            arcpy.management.CalculateGeometryAttributes(in_features=point_extracted_pb, geometry_property=[[\"LAT\", \"POINT_Y\"], [\"LONG\", \"POINT_X\"]],coordinate_system=\"PROJCS[\\\"WGS_1984_Web_Mercator_Auxiliary_Sphere\\\",GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Mercator_Auxiliary_Sphere\\\"],PARAMETER[\\\"False_Easting\\\",0.0],PARAMETER[\\\"False_Northing\\\",0.0],PARAMETER[\\\"Central_Meridian\\\",0.0],PARAMETER[\\\"Standard_Parallel_1\\\",0.0],PARAMETER[\\\"Auxiliary_Sphere_Type\\\",0.0],UNIT[\\\"Meter\\\",1.0]]\", \n",
    "                                                                        coordinate_format=\"DD\")[0]\n",
    "                            # point_extracted_sh.save()\n",
    "                            print(f\"Proses Extract Point Provinsi: {provinsi} selesai\")\n",
    "\n",
    "                            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} dimulai . . .. \")\n",
    "                            # arcpy.management.AddRastersToMosaicDataset(\n",
    "                            #     in_mosaic_dataset= mosaic_bln_sh,\n",
    "                            #     raster_type=\"Raster Dataset\",\n",
    "                            #     input_path= Extract_rast_sh,\n",
    "                            #     update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "                            #     update_boundary=\"UPDATE_BOUNDARY\",\n",
    "                            #     update_overviews=\"NO_OVERVIEWS\",\n",
    "                            #     maximum_pyramid_levels=None,\n",
    "                            #     maximum_cell_size=0,\n",
    "                            #     minimum_dimension=1500,\n",
    "                            #     spatial_reference=None,\n",
    "                            #     filter=\"\",\n",
    "                            #     sub_folder=\"SUBFOLDERS\",\n",
    "                            #     duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "                            #     build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "                            #     calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "                            #     build_thumbnails=\"NO_THUMBNAILS\",\n",
    "                            #     operation_description=\"\",\n",
    "                            #     force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "                            #     estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "                            #     aux_inputs=None,\n",
    "                            #     enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "                            #     cache_location=r\"C:\\Users\\mjanuadi\\AppData\\Local\\ESRI\\rasterproxies\\Mosaic_Dataset_SH\")\n",
    "                            # print(f\"Proses Memasukan Ke Mosaic Dataset Provinsi: {provinsi} selesai \")\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Proses Export to csv Provinsi: {provinsi} dimulai . . .\")\n",
    "\n",
    "                            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                            output_loc_csv = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                   output_tipe_periode=output_tipe_das, tipe='CSV', \n",
    "                                                                   nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "                            out_csv_table_pb = os.path.join(output_loc_csv, f\"das_{provinsi.lower()}_ver_{year}0{month}das0{current_dasarian}.csv\")\n",
    "                            arcpy.conversion.ExportTable(\n",
    "                                in_table= point_extracted_pb,\n",
    "                                out_table= out_csv_table_pb,\n",
    "                                where_clause=\"\",\n",
    "                                use_field_alias_as_name=\"NOT_USE_ALIAS\",\n",
    "                                field_mapping=None,\n",
    "                                sort_field=None)\n",
    "\n",
    "                            # Menggabungkan ke dalam list csv untuk di merge\n",
    "                            CSV_to_merge.append(out_csv_table_pb)\n",
    "                            print(f\"Proses Export to csv Provinsi: {provinsi} selesai\")\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Memulai Reclassify Provinsi: {provinsi}  . . .\")\n",
    "                            out_raster_ash_pb = arcpy.sa.Reclassify(in_raster=Extract_rast_sh,\n",
    "                                                            reclass_field=\"VALUE\",\n",
    "                                                            remap=\"0 30 1;30 50 2;50 84 3;84 115 4;115 150 5;150 200 6;200 10000 7\",\n",
    "                                                            missing_values=\"DATA\")\n",
    "\n",
    "                            out_raster_ash_pb.save(os.path.join(fgdb_temp, f\"Reclass_ASH_{provinsi}_{year}{month}das0{current_dasarian}\"))\n",
    "                            print(f\"Proses Reclassify Provinsi: {provinsi} telah selesai\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} dimulai . . . . . . . . . . . .\")\n",
    "\n",
    "                            pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "                            output_loc_shp = pembuatan_archiving.archive_prov(output_level_prov=output_level_prov, \n",
    "                                                                   output_tipe_periode=output_tipe_das, tipe='SHP', \n",
    "                                                                   nama_prov=nama_prov_folder, pulau_kecil=provinsi)\n",
    "\n",
    "\n",
    "                            Output_polygon_features_ash = os.path.join(fgdb_temp, f\"ash_das_{provinsi}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                            arcpy.conversion.RasterToPolygon(in_raster=out_raster_ash_pb, out_polygon_features=Output_polygon_features_ash)\n",
    "                            arcpy.management.AddFields(in_table=Output_polygon_features_ash, field_description= \"SH TEXT # 255 # #;Kategori TEXT # 255 # #;Periode TEXT # 255 # #;Informasi TEXT # 255 # #\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"SH\",\n",
    "                                        expression=\"sh(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def sh(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"0-30\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"31-50\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"51-84\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"85-115\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"116-150\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"151-200\"\n",
    "                                        elif x == 7:\n",
    "                                            return \">200\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"Kategori\",\n",
    "                                        expression=\"kategori(!gridcode!)\",\n",
    "                                        expression_type=\"PYTHON3\",\n",
    "                                        code_block=\"\"\"def kategori(x):\n",
    "                                        if x == 1:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 2:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 3:\n",
    "                                            return \"Bawah Normal\"\n",
    "                                        elif x == 4:\n",
    "                                            return \"Normal\"\n",
    "                                        elif x == 5:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 6:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        elif x == 7:\n",
    "                                            return \"Atas Normal\"\n",
    "                                        \"\"\",\n",
    "                                        field_type=\"TEXT\",\n",
    "                                        enforce_domains=\"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "\n",
    "                            arcpy.management.CalculateField(\n",
    "                                        in_table=Output_polygon_features_ash,\n",
    "                                        field=\"Periode\",\n",
    "                                        expression=f'\"Dasarian {current_dasarian} {month_name} {year}\"',\n",
    "                                        expression_type=\"PYTHON3\"\n",
    "                                    )\n",
    "                            arcpy.management.CalculateField(\n",
    "                                    in_table=Output_polygon_features_ash,\n",
    "                                    field=\"Informasi\",\n",
    "                                    expression='\"Sifat Hujan\"',\n",
    "                                    expression_type=\"PYTHON3\"\n",
    "                                )\n",
    "\n",
    "\n",
    "                            poly_kec = poly_kecamatan[provinsi]\n",
    "\n",
    "\n",
    "                            Output_polygon_features_ash_union = os.path.join(output_loc_shp, f\"ash_das_{provinsi.lower()}_ver_{year}{month}das0{current_dasarian}\")\n",
    "                            arcpy.analysis.Union(in_features=[poly_kec, Output_polygon_features_ash], \n",
    "                                     out_feature_class= Output_polygon_features_ash_union)\n",
    "\n",
    "\n",
    "                            arcpy.management.AddField(\n",
    "                                        in_table=Output_polygon_features_ash_union,\n",
    "                                        field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "                            arcpy.management.CalculateGeometryAttributes(\n",
    "                                    in_features=Output_polygon_features_ash_union,\n",
    "                                    geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "                                    area_unit=\"HECTARES\")\n",
    "\n",
    "\n",
    "\n",
    "                            # Menggabungkan output polygon untuk di merge\n",
    "                            ASH_to_merge.append(Output_polygon_features_ash)\n",
    "                            print(f\"Proses Konversi Raster to Polygon Provinsi: {provinsi} telah selesai\")\n",
    "                            print(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error di pengolahan Pulau/Provinsi {r[0]}: {e}\")\n",
    "            continue  # Skip to the next island\n",
    "\n",
    "\n",
    "try:\n",
    "    # Proses se Indonesia\n",
    "\n",
    "    # print(\"Proses Update Mosaic Dataset ACH: Indonesia dimulai . . .\")\n",
    "    # # Re-Calculate Statistic Mosaic Dataset\n",
    "    # arcpy.management.CalculateStatistics(\n",
    "    #     in_raster_dataset=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_CH\",\n",
    "    #     x_skip_factor=1,\n",
    "    #     y_skip_factor=1,\n",
    "    #     ignore_values=[],\n",
    "    #     skip_existing=\"OVERWRITE\",\n",
    "    #     area_of_interest=r\"in_memory\\feature_set1\")\n",
    "    # print(\"Proses Update Mosaic Dataset ACH: Indonesia selesai\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "\n",
    "    # print(\"Proses Update Mosaic Dataset ASH: Indonesia dimulai . . .\")\n",
    "    # arcpy.management.CalculateStatistics(\n",
    "    #     in_raster_dataset=r\"D:\\Project\\BMKG SiPinter Iklim\\BMKG_SiPinter\\fgdb_temp4.gdb\\Mosaic_Dataset_SH\",\n",
    "    #     x_skip_factor=1,\n",
    "    #     y_skip_factor=1,\n",
    "    #     ignore_values=[],\n",
    "    #     skip_existing=\"OVERWRITE\",\n",
    "    #     area_of_interest=r\"in_memory\\feature_set1\")\n",
    "    # print(\"Proses Update Mosaic Dataset ASH: Indonesia selesai\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    print(\"Proses Merge Raster ACH dan ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "    pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "    output_loc_tiff = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_das, tipe='TIFF')\n",
    "\n",
    "\n",
    "    arcpy.MosaicToNewRaster_management(\n",
    "        input_rasters=raster_ACH_to_merge_tif,\n",
    "        output_location=output_loc_tiff,  # Direktori output\n",
    "        raster_dataset_name_with_extension=f\"ach_das_indo_ver_{year}{month}das0{current_dasarian}.tif\",\n",
    "        coordinate_system_for_the_raster=None,  # Sistem koordinat, bisa None untuk menggunakan sistem koordinat raster input\n",
    "        pixel_type=\"32_BIT_FLOAT\",\n",
    "        cellsize=None,\n",
    "        number_of_bands=1,\n",
    "        mosaic_method=\"MEAN\" ,\n",
    "        mosaic_colormap_mode=\"FIRST\"  # Mode kolormap, bisa \"FIRST\", \"LAST\", \"MATCH\", dll.\n",
    "        )\n",
    "\n",
    "    arcpy.MosaicToNewRaster_management(\n",
    "        input_rasters=raster_ASH_to_merge_tif,\n",
    "        output_location=output_loc_tiff,  # Direktori output\n",
    "        raster_dataset_name_with_extension= f\"ash_das_indo_ver_{year}{month}das0{current_dasarian}.tif\",\n",
    "        coordinate_system_for_the_raster=None,  # Sistem koordinat, bisa None untuk menggunakan sistem koordinat raster input\n",
    "        pixel_type=\"32_BIT_FLOAT\",\n",
    "        cellsize=None,\n",
    "        number_of_bands=1,\n",
    "        mosaic_method=\"MEAN\" ,\n",
    "        mosaic_colormap_mode=\"FIRST\"  # Mode kolormap, bisa \"FIRST\", \"LAST\", \"MATCH\", dll.\n",
    "        )\n",
    "\n",
    "    print(\"Proses Merge Raster ACH dan ASH: Indonesia selesai\")\n",
    "\n",
    "\n",
    "    print(\"Proses Merge Polygon ACH dan ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "    #Membuat archiving\n",
    "    pembuatan_archiving = ArchivingFolder(output_folder)\n",
    "    output_loc_shp = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_das, tipe='SHP')\n",
    "\n",
    "\n",
    "    # Merge polygon menjadi se Indonesia\n",
    "    kec_indo = os.getenv(\"POLY_KEC\")\n",
    "    arcpy.management.Merge(ACH_to_merge, os.path.join(fgdb_temp, f\"ach_das_indo_ver_{year}{month}das0{current_dasarian}\"))\n",
    "    poly_indo_ach = os.path.join(output_loc_shp, f\"ach_das_indo_ver_{year}{month}das0{current_dasarian}\")\n",
    "    arcpy.analysis.Union(in_features=[kec_indo, os.path.join(fgdb_temp, f\"ach_das_indo_ver_{year}{month}das0{current_dasarian}\")], \n",
    "                                     out_feature_class=poly_indo_ach)\n",
    "    arcpy.management.AddField(\n",
    "                            in_table=poly_indo_ach,\n",
    "                            field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "    arcpy.management.CalculateGeometryAttributes(\n",
    "            in_features=poly_indo_ach,\n",
    "            geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "            area_unit=\"HECTARES\")\n",
    "\n",
    "    folder_layout = os.getenv(\"FOLDER_LAYOUT\")\n",
    "\n",
    "    arcpy.CopyFeatures_management(poly_indo_ach, os.path.join(folder_layout, 'polygon_ach_das'))\n",
    "\n",
    "\n",
    "\n",
    "    arcpy.management.Merge(ASH_to_merge, os.path.join(fgdb_temp, f\"ash_das_indo_ver_{year}{month}das0{current_dasarian}\"))\n",
    "    poly_indo_ash = os.path.join(output_loc_shp, f\"ash_das_indo_ver_{year}{month}das0{current_dasarian}\")\n",
    "    arcpy.analysis.Union(in_features=[kec_indo, os.path.join(fgdb_temp, f\"ash_das_indo_ver_{year}{month}das0{current_dasarian}\")], \n",
    "                                     out_feature_class=poly_indo_ash)\n",
    "\n",
    "    arcpy.management.AddField(\n",
    "                            in_table=poly_indo_ash,\n",
    "                            field_name=\"Area_H\", field_type=\"DOUBLE\")\n",
    "\n",
    "    arcpy.management.CalculateGeometryAttributes(\n",
    "            in_features=poly_indo_ash,\n",
    "            geometry_property=[[\"Area_H\", \"AREA_GEODESIC\"]],\n",
    "            area_unit=\"HECTARES\")\n",
    "\n",
    "    arcpy.CopyFeatures_management(poly_indo_ash, os.path.join(folder_layout, 'polygon_ash_das'))\n",
    "\n",
    "\n",
    "    print(\"Proses Merge Polygon ACH dan ASH: Indonesia selesai\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    print(\"Proses Merge CSV ACH dan ASH: Indonesia dimulai . . .\")\n",
    "    #Mmebuiat archive\n",
    "    output_loc_csv = pembuatan_archiving.archive_indo(output_level_indo= output_level_ind, output_tipe_periode=output_tipe_das, tipe='CSV')\n",
    "\n",
    "    # Merge csv se Indonesia\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file in CSV_to_merge:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file, delimiter=';')\n",
    "        # Append the DataFrame to the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    combined_df.to_csv(os.path.join(output_loc_csv, f\"das_indo_ver_{year}0{month}das0{current_dasarian}.csv\"), index=False)\n",
    "    print(\"Proses Merge CSV ACH dan ASH: Indonesia selesai\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    # ## MOSAIC RASTER WEB\n",
    "    # print(\"Proses Update Mosaic Dataset ACH: Indonesia dimulai . . .\")\n",
    "\n",
    "    # mosaic_data_ch = os.getenv(\"MOSAIC_DAS_ACH\")\n",
    "\n",
    "    # for raster_path, area in raster_ACH_to_merge :\n",
    "    #     add_raster_and_update_fields(raster_path, area, mosaic_data_ch)\n",
    "\n",
    "    # delete_old_rasters(mosaic_data_ch)\n",
    "\n",
    "    # arcpy.management.CalculateStatistics(\n",
    "    #     in_raster_dataset=mosaic_data_ch,\n",
    "    #     x_skip_factor=1,\n",
    "    #     y_skip_factor=1,\n",
    "    #     ignore_values=[],\n",
    "    #     skip_existing=\"OVERWRITE\")\n",
    "    # print(\"Proses Update Mosaic Dataset ACH: Indonesia selesai\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "\n",
    "    # print(\"Proses Update Mosaic Dataset ASH: Indonesia dimulai . . .\")\n",
    "\n",
    "\n",
    "    # mosaic_data_sh = os.getenv(\"MOSAIC_DAS_ASH\")\n",
    "\n",
    "    # for raster_path, area in raster_ASH_to_merge :\n",
    "    #     add_raster_and_update_fields(raster_path, area, mosaic_data_sh)\n",
    "\n",
    "    # delete_old_rasters(mosaic_data_sh)\n",
    "\n",
    "    # arcpy.management.CalculateStatistics(\n",
    "    #     in_raster_dataset=mosaic_data_sh,\n",
    "    #     x_skip_factor=1,\n",
    "    #     y_skip_factor=1,\n",
    "    #     ignore_values=[],\n",
    "    #     skip_existing=\"OVERWRITE\")\n",
    "    # print(\"Proses Update Mosaic Dataset ASH: Indonesia selesai\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    return poly_indo_ach, poly_indo_ash, raster_ACH_to_merge, raster_ASH_to_merge\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error Pengolahan Data Indonesia\")\n",
    "\n",
    "print(\"PROSES ANALISA DASARIAN SELESAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.now()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.now()\n",
    "formatted_date = today.strftime(\"%Y%m%d\")\n",
    "print(formatted_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.proses1_get_download_data import test_download_data_das, test_download_data_bln\n",
    "\n",
    "test_download_data_bln()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date=datetime.datetime.today()\n",
    "get_year = today_date.strftime(\"%Y\")\n",
    "get_month = today_date.strftime(\"%m\")\n",
    "get_date = today_date.strftime(\"%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import datetime\n",
    "from utils.proses1_access_server import downloadBulk\n",
    "\n",
    "def test_download_data_bln():\n",
    "    main_url = \"http://172.19.1.208/\"\n",
    "    secondary_url = \"http://172.19.3.97/\"\n",
    "\n",
    "    download_folder = r\"F:\\SIPINTER-IKLIM-BMKG-PROSES1\\DOWNLOAD\"\n",
    "    progress = \"BULANAN\"\n",
    "    parameter = \"ANALISIS\"\n",
    "#     current_time = datetime.datetime.now()\n",
    "#     formatted_today = current_time.strftime(\"%Y%m%d\")\n",
    "#     today = datetime.datetime.strptime(formatted_today, \"%Y%m%d\")\n",
    "    today = datetime.datetime.strptime(\"20241111\", \"%Y%m%d\")\n",
    "    #formatted_date = today.strftime(\"%Y%m%d\")\n",
    "\n",
    "    \n",
    "    \n",
    "    object_download = downloadBulk(\n",
    "        main_root_url=main_url,\n",
    "        secondary_root_url=secondary_url,\n",
    "        download_folder=download_folder,\n",
    "        progress_type=progress,\n",
    "        parameter=parameter,\n",
    "        today_date=today)\n",
    "\n",
    "    object_download.file_from_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_download_data_bln()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_download_data_das():\n",
    "    main_url = \"http://172.19.1.208/\"\n",
    "    secondary_url = \"http://172.19.3.97/\"\n",
    "\n",
    "    download_folder = r\"F:\\SIPINTER-IKLIM-BMKG-PROSES1\\DOWNLOAD\"\n",
    "    progress = \"DASARIAN\"\n",
    "    parameter = \"ANALISIS\"\n",
    "    today = datetime.datetime.now()\n",
    "    # formatted_date = today.strftime(\"%Y%m%d\")\n",
    "    #today_min1 = today - datetime.timedelta(days=1)\n",
    "    object_download = downloadBulk(\n",
    "        main_root_url=main_url,\n",
    "        secondary_root_url=secondary_url,\n",
    "        download_folder=download_folder,\n",
    "        progress_type=progress,\n",
    "        parameter=parameter,\n",
    "        today_date=today)\n",
    "\n",
    "    object_download.file_from_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_download_data_das()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from utils.proses1_access_server import downloadBulk\n",
    "\n",
    "main_url = \"http://172.19.1.208/\"\n",
    "secondary_url = \"http://172.19.3.97/\"\n",
    "\n",
    "download_folder = r\"F:\\SIPINTER-IKLIM-BMKG-PROSES1\\DOWNLOAD\"\n",
    "progress = \"DASARIAN\"\n",
    "parameter = \"ANALISIS\"\n",
    "\n",
    "# current_time = datetime.datetime.now()\n",
    "# formatted_today = current_time.strftime(\"%Y%m%d\")\n",
    "# today = datetime.datetime.strptime(formatted_today, \"%Y%m%d\")\n",
    "today = datetime.datetime.strptime(\"20241111\", \"%Y%m%d\")\n",
    "#today = datetime.datetime.now().strftime(\"%Y%m%d\")  # Use only the date part\n",
    "#today = datetime.datetime.strptime(today, \"%Y%m%d\")\n",
    "\n",
    "\n",
    "# formatted_date = today.strftime(\"%Y%m%d\")\n",
    "#today_min1 = today - datetime.timedelta(days=1)\n",
    "object_download = downloadBulk(\n",
    "    main_root_url=main_url,\n",
    "    secondary_root_url=secondary_url,\n",
    "    download_folder=download_folder,\n",
    "    progress_type=progress,\n",
    "    parameter=parameter,\n",
    "    today_date=today)\n",
    "\n",
    "object_download.file_from_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today1 = datetime.datetime.strptime(\"20241004\", \"%Y%m%d\")\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now() \n",
    "formatted_today = current_time.strftime(\"%Y%m%d\") \n",
    "today2 = datetime.datetime.strptime(formatted_today, \"%Y%m%d\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(today1, today2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.proses1_download_data_from_server import *\n",
    "\n",
    "download_data(main_url_das, secondary_url_das, local_file_path_das )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data(main_url_bln, secondary_url_bln, local_file_path_bln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smbprotocol.connection import Connection\n",
    "from smbprotocol.session import Session\n",
    "from smbprotocol.tree import TreeConnect\n",
    "from smbprotocol.file import File\n",
    "import os\n",
    "\n",
    "# Define your variables\n",
    "OUTPUT_FOLDER = r'\\\\192.168.27.19\\data_bmkg\\data_automation\\PINTER_IKLIM'\n",
    "USERNAME = 'Administrator'  # Replace with your username\n",
    "PASSWORD = '4rcG!$1kl1m2024'  # Replace with your password\n",
    "\n",
    "# Set up the connection\n",
    "connection = Connection(uuid.uuid4(), '192.168.27.19', 445)\n",
    "connection.connect()\n",
    "\n",
    "# Start a session\n",
    "session = Session(connection, USERNAME, PASSWORD)\n",
    "session.connect()\n",
    "\n",
    "# Connect to the share\n",
    "tree = TreeConnect(session, r'\\\\192.168.27.19\\data_bmkg')\n",
    "tree.connect()\n",
    "\n",
    "# Now you can access files in the OUTPUT_FOLDER\n",
    "# Example: List files in OUTPUT_FOLDER\n",
    "try:\n",
    "    directory = File(tree, OUTPUT_FOLDER)\n",
    "    directory.create()\n",
    "    for file in directory.list():\n",
    "        print(file.file_name)\n",
    "finally:\n",
    "    directory.close()\n",
    "    tree.disconnect()\n",
    "    session.disconnect()\n",
    "    connection.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smbprotocol\n",
    "from smbprotocol import create_connection\n",
    "from smbprotocol import open_file\n",
    "from smbprotocol import FileAttributes\n",
    "from smbprotocol import FileAccess\n",
    "from smbprotocol import FileShare\n",
    "from smbprotocol import SecurityContext\n",
    "\n",
    "# Define the server, share, and path\n",
    "server = \"192.168.27.19\"\n",
    "share = \"data_bmkg\"\n",
    "folder_path = r\"\\data_automation\\PINTER_IKLIM\"\n",
    "username = 'Administrator' \n",
    "password = '4rcG!$1kl1m2024'\n",
    "\n",
    "# Initialize the SMB protocol\n",
    "smbprotocol.ClientConfig(username=username, password=password)\n",
    "\n",
    "# Create a connection to the server\n",
    "conn = create_connection(server, 445)\n",
    "\n",
    "# Access the file on the network share\n",
    "file_path = f\"\\\\\\\\{server}\\\\{share}{folder_path}\"\n",
    "\n",
    "try:\n",
    "    # Open the file or directory for reading\n",
    "    with open_file(file_path, \"r\") as file:\n",
    "        data = file.read()\n",
    "        print(data)\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing the path: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def authenticate():\n",
    "# Map the network drive\n",
    "    subprocess.run(['net', 'use', r'\\\\192.168.27.19\\data_bmkg', '/user:Administrator', '4rcG!$1kl1m2024'])\n",
    "\n",
    "print(\"success\")\n",
    "\n",
    "# Now you can access the folder in your script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def map_network_drive(network_path, username, password):\n",
    "    try:\n",
    "        # Attempt to map the network drive\n",
    "        result = subprocess.run(['net', 'use', network_path, f'/user:{username}', password], check=True, capture_output=True)\n",
    "        print(f\"Successfully connected to {network_path}\")\n",
    "\n",
    "        # List the contents of the directory\n",
    "        contents = os.listdir(network_path)\n",
    "        print(\"Contents of the directory:\")\n",
    "        for item in contents:\n",
    "            print(item)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to connect to {network_path}: {e.stderr.decode()}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The specified network path was not found: {network_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Replace these variables with your actual values\n",
    "network_path = r'\\\\192.168.27.19\\data_bmkg'\n",
    "username = 'arcgis' \n",
    "password = '4rcG!$1kl1m2024'\n",
    "\n",
    "map_network_drive(network_path, username, password)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def first_date_of_previous_month():\n",
    "    today = datetime.now() - timedelta(days=25) # Get the current date\n",
    "    # Calculate the first day of the current month\n",
    "    first_of_current_month = today.replace(day=1)\n",
    "    # Subtract one day to get the last day of the previous month\n",
    "    last_of_previous_month = first_of_current_month - timedelta(days=1)\n",
    "    # Get the first day of the previous month\n",
    "    first_of_previous_month = last_of_previous_month.replace(day=1)\n",
    "    return first_of_previous_month\n",
    "\n",
    "# Example usage\n",
    "first_date = first_date_of_previous_month()\n",
    "print(first_date.strftime(\"%Y-%m-%d\"))  # Print in YYYY-MM-DD format\n",
    "first_date_str = first_date.strftime(\"%Y-%m-%d\")\n",
    "first_date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def first_date_of_previous_month():\n",
    "    today = datetime.now()  # Get the current date\n",
    "    # Calculate the first day of the current month\n",
    "    first_of_current_month = today.replace(day=1)\n",
    "    # Subtract one day to get the last day of the previous month\n",
    "    last_of_previous_month = first_of_current_month - timedelta(days=1)\n",
    "    # Get the first day of the previous month\n",
    "    first_of_previous_month = last_of_previous_month.replace(day=1)\n",
    "    return first_of_previous_month.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# # Example usage\n",
    "# first_date = first_date_of_previous_month().strftime(\"%Y-%m-%d\")\n",
    "# print(first_date)  # Print in YYYY-MM-DD format\n",
    "\n",
    "date_input = first_date_of_previous_month()\n",
    "date_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def first_date_of_dasarian():\n",
    "    today = datetime.now() - timedelta(days=19) # Get the current date\n",
    "    # Calculate the number of days since the start of the cycle\n",
    "    days_since_start = today.day % 10\n",
    "    # Calculate the first day of the current dasarian cycle\n",
    "    first_dasarian_date = today - timedelta(days=days_since_start)\n",
    "    return first_dasarian_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Example usage\n",
    "first_date = first_date_of_dasarian()\n",
    "print(first_date.strftime(\"%Y-%m-%d\"))  # Print in YYYY-MM-DD format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prov = ['ACEH JAYA', 'SUMATERA UTARA']\n",
    "print(list_prov.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def first_date_of_previous_month():\n",
    "    today = datetime.datetime.now()  # Get the current date\n",
    "    # Calculate the first day of the current month\n",
    "    first_of_current_month = today.replace(day=1)\n",
    "    # Subtract one day to get the last day of the previous month\n",
    "    last_of_previous_month = first_of_current_month - timedelta(days=1)\n",
    "    # Get the first day of the previous month\n",
    "    first_of_previous_month = last_of_previous_month.replace(day=1)\n",
    "    first_of_previous_month_str = first_of_previous_month.strftime(\"%d-%m-%Y\")\n",
    "    return first_of_previous_month, first_of_previous_month_str\n",
    "\n",
    "def first_date_of_dasarian():\n",
    "    today = datetime.datetime.now() # Get the current date\n",
    "    # Calculate the number of days since the start of the cycle\n",
    "    days_since_start = today.day % 10\n",
    "    # Calculate the first day of the current dasarian cycle\n",
    "    first_dasarian_date = today - timedelta(days=days_since_start)\n",
    "    first_dasarian_date_str = first_dasarian_date.strftime(\"%d-%m-%Y\")\n",
    "    return first_dasarian_date, first_dasarian_date_str\n",
    "\n",
    "\n",
    "date_input_bln, date_input_bln_str = first_date_of_previous_month()\n",
    "date_input_das, date_input_das_str = first_date_of_dasarian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = r\"F:\\ASSET\\spatial\\BMKG_PinterIklim\\proses1_data_layout.gdb\\polygon_ash_bln\"\n",
    "dataframe = pd.DataFrame.spatial.from_featureclass(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.proses1_dataframe_process import dataframe_indo, dataframe_upt\n",
    "indo_df_complete, prov_df_complete_clean, pulau_df_complete_clean, top_by_kategori, sgt_tinggi, tinggi, menengah, rendah = dataframe_indo(dataframe, tipe_informasi=\"ANALISIS_CURAH_HUJAN\")\n",
    "df = prov_df_complete_clean\n",
    "\n",
    "df = df.rename(columns={'Wilayah' : 'wilayah', 'Rendah (%)': 'rendah', 'Menengah (%)': 'menengah', 'Tinggi (%)' : 'tinggi', 'Sangat Tinggi (%)': 'sangat_tinggi'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wilayah</th>\n",
       "      <th>rendah</th>\n",
       "      <th>menengah</th>\n",
       "      <th>tinggi</th>\n",
       "      <th>sangat_tinggi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACEH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BALI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANTEN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENGKULU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DKI JAKARTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GORONTALO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JAMBI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KALIMANTAN BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KALIMANTAN SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KALIMANTAN TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KALIMANTAN TIMUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KALIMANTAN UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KEPULAUAN BANGKA BELITUNG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KEPULAUAN RIAU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MALUKU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MALUKU UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NUSA TENGGARA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NUSA TENGGARA TIMUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PAPUA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PAPUA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PAPUA BARAT DAYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PAPUA PEGUNUNGAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PAPUA SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PAPUA TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RIAU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SULAWESI BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SULAWESI TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SULAWESI TENGGARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SULAWESI UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SUMATERA UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      wilayah  rendah  menengah  tinggi  sangat_tinggi\n",
       "0                   INDONESIA     0.0       0.0     0.0            0.0\n",
       "1                        ACEH     0.0       0.0     0.0            0.0\n",
       "2                        BALI     0.0       0.0     0.0            0.0\n",
       "3                      BANTEN     0.0       0.0     0.0            0.0\n",
       "4                    BENGKULU     0.0       0.0     0.0            0.0\n",
       "5               DI YOGYAKARTA     0.0       0.0     0.0            0.0\n",
       "6                 DKI JAKARTA     0.0       0.0     0.0            0.0\n",
       "7                   GORONTALO     0.0       0.0     0.0            0.0\n",
       "8                       JAMBI     0.0       0.0     0.0            0.0\n",
       "9                  JAWA BARAT     0.0       0.0     0.0            0.0\n",
       "10                JAWA TENGAH     0.0       0.0     0.0            0.0\n",
       "11                 JAWA TIMUR     0.0       0.0     0.0            0.0\n",
       "12           KALIMANTAN BARAT     0.0       0.0     0.0            0.0\n",
       "13         KALIMANTAN SELATAN     0.0       0.0     0.0            0.0\n",
       "14          KALIMANTAN TENGAH     0.0       0.0     0.0            0.0\n",
       "15           KALIMANTAN TIMUR     0.0       0.0     0.0            0.0\n",
       "16           KALIMANTAN UTARA     0.0       0.0     0.0            0.0\n",
       "17  KEPULAUAN BANGKA BELITUNG     0.0       0.0     0.0            0.0\n",
       "18             KEPULAUAN RIAU     0.0       0.0     0.0            0.0\n",
       "19                    LAMPUNG     0.0       0.0     0.0            0.0\n",
       "20                     MALUKU     0.0       0.0     0.0            0.0\n",
       "21               MALUKU UTARA     0.0       0.0     0.0            0.0\n",
       "22        NUSA TENGGARA BARAT     0.0       0.0     0.0            0.0\n",
       "23        NUSA TENGGARA TIMUR     0.0       0.0     0.0            0.0\n",
       "24                      PAPUA     0.0       0.0     0.0            0.0\n",
       "25                PAPUA BARAT     0.0       0.0     0.0            0.0\n",
       "26           PAPUA BARAT DAYA     0.0       0.0     0.0            0.0\n",
       "27           PAPUA PEGUNUNGAN     0.0       0.0     0.0            0.0\n",
       "28              PAPUA SELATAN     0.0       0.0     0.0            0.0\n",
       "29               PAPUA TENGAH     0.0       0.0     0.0            0.0\n",
       "30                       RIAU     0.0       0.0     0.0            0.0\n",
       "31             SULAWESI BARAT     0.0       0.0     0.0            0.0\n",
       "32           SULAWESI SELATAN     0.0       0.0     0.0            0.0\n",
       "33            SULAWESI TENGAH     0.0       0.0     0.0            0.0\n",
       "34          SULAWESI TENGGARA     0.0       0.0     0.0            0.0\n",
       "35             SULAWESI UTARA     0.0       0.0     0.0            0.0\n",
       "36             SUMATERA BARAT     0.0       0.0     0.0            0.0\n",
       "37           SUMATERA SELATAN     0.0       0.0     0.0            0.0\n",
       "38             SUMATERA UTARA     0.0       0.0     0.0            0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Wilayah' : 'wilayah', 'Rendah (%)': 'rendah', 'Menengah (%)': 'menengah', 'Tinggi (%)' : 'tinggi', 'Sangat Tinggi (%)': 'sangat_tinggi'})\n",
    "df['periode_informasi'] = 'Bulanan'\n",
    "df['jenis_informasi'] = 'CH'\n",
    "df['tipe_informasi'] = 'Analisis'\n",
    "df['date'] = date_input_bln_str\n",
    "df['date_datetime'] = date_input_bln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wilayah</th>\n",
       "      <th>rendah</th>\n",
       "      <th>menengah</th>\n",
       "      <th>tinggi</th>\n",
       "      <th>sangat_tinggi</th>\n",
       "      <th>periode_informasi</th>\n",
       "      <th>jenis_informasi</th>\n",
       "      <th>tipe_informasi</th>\n",
       "      <th>date</th>\n",
       "      <th>date_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     wilayah  rendah  menengah  tinggi  sangat_tinggi periode_informasi  \\\n",
       "0  INDONESIA     0.0       0.0     0.0            0.0           Bulanan   \n",
       "\n",
       "  jenis_informasi tipe_informasi        date              date_datetime  \n",
       "0              CH       Analisis  01-11-2024 2024-11-01 18:49:02.787702  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sde_table_path = r\"F:\\ASSET\\spatial\\BMKG_PinterIklim\\PostgreSQL-gisdbiklim-geodb_bmkg(sde).sde\\geodb_bmkg.sde.summary_indonesia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [field.name for field in arcpy.ListFields(sde_table_path)]\n",
    "data = []\n",
    "with arcpy.da.SearchCursor(sde_table_path, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "# Convert the data to a pandas DataFrame\n",
    "df_sde = pd.DataFrame(data, columns=fields)\n",
    "df_sde['date_datetime'] = pd.to_datetime(df_sde['date_datetime'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid</th>\n",
       "      <th>objectid_1</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>rendah</th>\n",
       "      <th>menengah</th>\n",
       "      <th>tinggi</th>\n",
       "      <th>sangat_tinggi</th>\n",
       "      <th>bawah_normal</th>\n",
       "      <th>normal</th>\n",
       "      <th>atas_normal</th>\n",
       "      <th>periode_informasi</th>\n",
       "      <th>jenis_informasi</th>\n",
       "      <th>tipe_informasi</th>\n",
       "      <th>date</th>\n",
       "      <th>date_datetime</th>\n",
       "      <th>admin_1</th>\n",
       "      <th>admin_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>2.886322e+06</td>\n",
       "      <td>9.273601e+07</td>\n",
       "      <td>4.082480e+06</td>\n",
       "      <td>2.521981e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>CH</td>\n",
       "      <td>Prediksi</td>\n",
       "      <td>20241230</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>7.957729e+06</td>\n",
       "      <td>9.025470e+07</td>\n",
       "      <td>1.719112e+06</td>\n",
       "      <td>2.795457e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>CH</td>\n",
       "      <td>Prediksi</td>\n",
       "      <td>20250110</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>4.715448e+06</td>\n",
       "      <td>8.222145e+07</td>\n",
       "      <td>1.182954e+07</td>\n",
       "      <td>1.190533e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>CH</td>\n",
       "      <td>Prediksi</td>\n",
       "      <td>20241210</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>4.637268e+06</td>\n",
       "      <td>9.010290e+07</td>\n",
       "      <td>5.076200e+06</td>\n",
       "      <td>1.423508e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>CH</td>\n",
       "      <td>Prediksi</td>\n",
       "      <td>20241220</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>PROVINSI NANGGROE ACEH DARUSSALAM</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.955000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>CH</td>\n",
       "      <td>Prediksi</td>\n",
       "      <td>20241210</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>PROVINSI</td>\n",
       "      <td>PROVINSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>930</td>\n",
       "      <td>None</td>\n",
       "      <td>PROVINSI SUMATERA UTARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>SH</td>\n",
       "      <td>Prediksi</td>\n",
       "      <td>01-01-2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>PROVINSI</td>\n",
       "      <td>PROVINSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>931</td>\n",
       "      <td>None</td>\n",
       "      <td>PROVINSI SUMATERA UTARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.84</td>\n",
       "      <td>97.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>SH</td>\n",
       "      <td>Prediksi</td>\n",
       "      <td>01-02-2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>PROVINSI</td>\n",
       "      <td>PROVINSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>932</td>\n",
       "      <td>None</td>\n",
       "      <td>PROVINSI SUMATERA UTARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.47</td>\n",
       "      <td>165.57</td>\n",
       "      <td>0.28</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>SH</td>\n",
       "      <td>Prediksi</td>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>PROVINSI</td>\n",
       "      <td>PROVINSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>933</td>\n",
       "      <td>None</td>\n",
       "      <td>PROVINSI SUMATERA UTARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.47</td>\n",
       "      <td>165.57</td>\n",
       "      <td>0.28</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>SH</td>\n",
       "      <td>Prediksi</td>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>PROVINSI</td>\n",
       "      <td>PROVINSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>934</td>\n",
       "      <td>None</td>\n",
       "      <td>PROVINSI SUMATERA UTARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.47</td>\n",
       "      <td>79.34</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>SH</td>\n",
       "      <td>Prediksi</td>\n",
       "      <td>01-04-2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>PROVINSI</td>\n",
       "      <td>PROVINSI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     objectid objectid_1                            wilayah        rendah  \\\n",
       "0           1       None                          Indonesia  2.886322e+06   \n",
       "1           2       None                          Indonesia  7.957729e+06   \n",
       "2           3       None                          Indonesia  4.715448e+06   \n",
       "3           4       None                          Indonesia  4.637268e+06   \n",
       "4           5       None  PROVINSI NANGGROE ACEH DARUSSALAM  0.000000e+00   \n",
       "..        ...        ...                                ...           ...   \n",
       "929       930       None            PROVINSI SUMATERA UTARA           NaN   \n",
       "930       931       None            PROVINSI SUMATERA UTARA           NaN   \n",
       "931       932       None            PROVINSI SUMATERA UTARA           NaN   \n",
       "932       933       None            PROVINSI SUMATERA UTARA           NaN   \n",
       "933       934       None            PROVINSI SUMATERA UTARA           NaN   \n",
       "\n",
       "         menengah        tinggi  sangat_tinggi  bawah_normal  normal  \\\n",
       "0    9.273601e+07  4.082480e+06   2.521981e+05           NaN     NaN   \n",
       "1    9.025470e+07  1.719112e+06   2.795457e+04           NaN     NaN   \n",
       "2    8.222145e+07  1.182954e+07   1.190533e+06           NaN     NaN   \n",
       "3    9.010290e+07  5.076200e+06   1.423508e+05           NaN     NaN   \n",
       "4    9.955000e+01  0.000000e+00   0.000000e+00           NaN     NaN   \n",
       "..            ...           ...            ...           ...     ...   \n",
       "929           NaN           NaN            NaN          0.00   99.66   \n",
       "930           NaN           NaN            NaN          1.84   97.00   \n",
       "931           NaN           NaN            NaN         33.47  165.57   \n",
       "932           NaN           NaN            NaN         33.47  165.57   \n",
       "933           NaN           NaN            NaN         19.47   79.34   \n",
       "\n",
       "     atas_normal periode_informasi jenis_informasi tipe_informasi        date  \\\n",
       "0            NaN          Dasarian              CH       Prediksi    20241230   \n",
       "1            NaN          Dasarian              CH       Prediksi    20250110   \n",
       "2            NaN          Dasarian              CH       Prediksi    20241210   \n",
       "3            NaN          Dasarian              CH       Prediksi    20241220   \n",
       "4            NaN          Dasarian              CH       Prediksi    20241210   \n",
       "..           ...               ...             ...            ...         ...   \n",
       "929         0.00           Bulanan              SH       Prediksi  01-01-2025   \n",
       "930         0.82           Bulanan              SH       Prediksi  01-02-2025   \n",
       "931         0.28           Bulanan              SH       Prediksi  01-03-2025   \n",
       "932         0.28           Bulanan              SH       Prediksi  01-03-2025   \n",
       "933         0.85           Bulanan              SH       Prediksi  01-04-2025   \n",
       "\n",
       "    date_datetime   admin_1   admin_2  \n",
       "0      2001-01-01      None      None  \n",
       "1      2001-01-01      None      None  \n",
       "2      2001-01-01      None      None  \n",
       "3      2001-01-01      None      None  \n",
       "4      2001-01-01  PROVINSI  PROVINSI  \n",
       "..            ...       ...       ...  \n",
       "929           NaT  PROVINSI  PROVINSI  \n",
       "930           NaT  PROVINSI  PROVINSI  \n",
       "931           NaT  PROVINSI  PROVINSI  \n",
       "932           NaT  PROVINSI  PROVINSI  \n",
       "933           NaT  PROVINSI  PROVINSI  \n",
       "\n",
       "[934 rows x 17 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_months_ago = datetime.datetime.now() - timedelta(days=10)\n",
    "\n",
    "unique_columns = ['wilayah', 'periode_informasi','jenis_informasi', 'tipe_informasi', 'date']\n",
    "df_new = df[~df[unique_columns].apply(tuple, 1).isin(df_sde[unique_columns].apply(tuple, 1))]\n",
    "\n",
    "df_filtered = df_sde[~((df_sde['tipe_informasi'] == 'Analisis') & \n",
    "                                    (df_sde['date_datetime'] < two_months_ago))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid</th>\n",
       "      <th>objectid_1</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>rendah</th>\n",
       "      <th>menengah</th>\n",
       "      <th>tinggi</th>\n",
       "      <th>sangat_tinggi</th>\n",
       "      <th>bawah_normal</th>\n",
       "      <th>normal</th>\n",
       "      <th>atas_normal</th>\n",
       "      <th>periode_informasi</th>\n",
       "      <th>jenis_informasi</th>\n",
       "      <th>tipe_informasi</th>\n",
       "      <th>date</th>\n",
       "      <th>date_datetime</th>\n",
       "      <th>admin_1</th>\n",
       "      <th>admin_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>313</td>\n",
       "      <td>None</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>11.96</td>\n",
       "      <td>62.35</td>\n",
       "      <td>17.17</td>\n",
       "      <td>8.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>30-11-2024</td>\n",
       "      <td>2024-11-30 03:12:56</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>314</td>\n",
       "      <td>None</td>\n",
       "      <td>ACEH</td>\n",
       "      <td>1.01</td>\n",
       "      <td>44.44</td>\n",
       "      <td>26.26</td>\n",
       "      <td>28.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>30-11-2024</td>\n",
       "      <td>2024-11-30 03:12:56</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>315</td>\n",
       "      <td>None</td>\n",
       "      <td>BALI</td>\n",
       "      <td>15.15</td>\n",
       "      <td>63.64</td>\n",
       "      <td>16.16</td>\n",
       "      <td>5.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>30-11-2024</td>\n",
       "      <td>2024-11-30 03:12:56</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>316</td>\n",
       "      <td>None</td>\n",
       "      <td>BANTEN</td>\n",
       "      <td>9.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>30-11-2024</td>\n",
       "      <td>2024-11-30 03:12:56</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>317</td>\n",
       "      <td>None</td>\n",
       "      <td>BENGKULU</td>\n",
       "      <td>5.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>30-11-2024</td>\n",
       "      <td>2024-11-30 03:12:56</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>386</td>\n",
       "      <td>None</td>\n",
       "      <td>SULAWESI TENGGARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>SH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>30-11-2024</td>\n",
       "      <td>2024-11-30 03:22:01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>387</td>\n",
       "      <td>None</td>\n",
       "      <td>SULAWESI UTARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.24</td>\n",
       "      <td>26.26</td>\n",
       "      <td>49.49</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>SH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>30-11-2024</td>\n",
       "      <td>2024-11-30 03:22:01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>388</td>\n",
       "      <td>None</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>SH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>30-11-2024</td>\n",
       "      <td>2024-11-30 03:22:01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>389</td>\n",
       "      <td>None</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>SH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>30-11-2024</td>\n",
       "      <td>2024-11-30 03:22:01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>390</td>\n",
       "      <td>None</td>\n",
       "      <td>SUMATERA UTARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>74.00</td>\n",
       "      <td>Dasarian</td>\n",
       "      <td>SH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>30-11-2024</td>\n",
       "      <td>2024-11-30 03:22:01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     objectid objectid_1            wilayah  rendah  menengah  tinggi  \\\n",
       "312       313       None          INDONESIA   11.96     62.35   17.17   \n",
       "313       314       None               ACEH    1.01     44.44   26.26   \n",
       "314       315       None               BALI   15.15     63.64   16.16   \n",
       "315       316       None             BANTEN    9.00     55.00   24.00   \n",
       "316       317       None           BENGKULU    5.00     78.00   15.00   \n",
       "..        ...        ...                ...     ...       ...     ...   \n",
       "385       386       None  SULAWESI TENGGARA     NaN       NaN     NaN   \n",
       "386       387       None     SULAWESI UTARA     NaN       NaN     NaN   \n",
       "387       388       None     SUMATERA BARAT     NaN       NaN     NaN   \n",
       "388       389       None   SUMATERA SELATAN     NaN       NaN     NaN   \n",
       "389       390       None     SUMATERA UTARA     NaN       NaN     NaN   \n",
       "\n",
       "     sangat_tinggi  bawah_normal  normal  atas_normal periode_informasi  \\\n",
       "312           8.53           NaN     NaN          NaN          Dasarian   \n",
       "313          28.28           NaN     NaN          NaN          Dasarian   \n",
       "314           5.05           NaN     NaN          NaN          Dasarian   \n",
       "315          12.00           NaN     NaN          NaN          Dasarian   \n",
       "316           2.00           NaN     NaN          NaN          Dasarian   \n",
       "..             ...           ...     ...          ...               ...   \n",
       "385            NaN         25.00   31.00        44.00          Dasarian   \n",
       "386            NaN         24.24   26.26        49.49          Dasarian   \n",
       "387            NaN         23.00   22.00        55.00          Dasarian   \n",
       "388            NaN         15.00   36.00        49.00          Dasarian   \n",
       "389            NaN         13.00   13.00        74.00          Dasarian   \n",
       "\n",
       "    jenis_informasi tipe_informasi        date       date_datetime admin_1  \\\n",
       "312              CH       Analisis  30-11-2024 2024-11-30 03:12:56    None   \n",
       "313              CH       Analisis  30-11-2024 2024-11-30 03:12:56    None   \n",
       "314              CH       Analisis  30-11-2024 2024-11-30 03:12:56    None   \n",
       "315              CH       Analisis  30-11-2024 2024-11-30 03:12:56    None   \n",
       "316              CH       Analisis  30-11-2024 2024-11-30 03:12:56    None   \n",
       "..              ...            ...         ...                 ...     ...   \n",
       "385              SH       Analisis  30-11-2024 2024-11-30 03:22:01    None   \n",
       "386              SH       Analisis  30-11-2024 2024-11-30 03:22:01    None   \n",
       "387              SH       Analisis  30-11-2024 2024-11-30 03:22:01    None   \n",
       "388              SH       Analisis  30-11-2024 2024-11-30 03:22:01    None   \n",
       "389              SH       Analisis  30-11-2024 2024-11-30 03:22:01    None   \n",
       "\n",
       "    admin_2  \n",
       "312    None  \n",
       "313    None  \n",
       "314    None  \n",
       "315    None  \n",
       "316    None  \n",
       "..      ...  \n",
       "385    None  \n",
       "386    None  \n",
       "387    None  \n",
       "388    None  \n",
       "389    None  \n",
       "\n",
       "[78 rows x 17 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[df_filtered['tipe_informasi'] == 'Analisis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wilayah</th>\n",
       "      <th>rendah</th>\n",
       "      <th>menengah</th>\n",
       "      <th>tinggi</th>\n",
       "      <th>sangat_tinggi</th>\n",
       "      <th>periode_informasi</th>\n",
       "      <th>jenis_informasi</th>\n",
       "      <th>tipe_informasi</th>\n",
       "      <th>date</th>\n",
       "      <th>date_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACEH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BALI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANTEN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENGKULU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DKI JAKARTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GORONTALO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JAMBI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KALIMANTAN BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KALIMANTAN SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KALIMANTAN TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KALIMANTAN TIMUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KALIMANTAN UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KEPULAUAN BANGKA BELITUNG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KEPULAUAN RIAU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MALUKU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MALUKU UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NUSA TENGGARA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NUSA TENGGARA TIMUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PAPUA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PAPUA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PAPUA BARAT DAYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PAPUA PEGUNUNGAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PAPUA SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PAPUA TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RIAU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SULAWESI BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SULAWESI TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SULAWESI TENGGARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SULAWESI UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SUMATERA UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      wilayah  rendah  menengah  tinggi  sangat_tinggi  \\\n",
       "0                   INDONESIA     0.0       0.0     0.0            0.0   \n",
       "1                        ACEH     0.0       0.0     0.0            0.0   \n",
       "2                        BALI     0.0       0.0     0.0            0.0   \n",
       "3                      BANTEN     0.0       0.0     0.0            0.0   \n",
       "4                    BENGKULU     0.0       0.0     0.0            0.0   \n",
       "5               DI YOGYAKARTA     0.0       0.0     0.0            0.0   \n",
       "6                 DKI JAKARTA     0.0       0.0     0.0            0.0   \n",
       "7                   GORONTALO     0.0       0.0     0.0            0.0   \n",
       "8                       JAMBI     0.0       0.0     0.0            0.0   \n",
       "9                  JAWA BARAT     0.0       0.0     0.0            0.0   \n",
       "10                JAWA TENGAH     0.0       0.0     0.0            0.0   \n",
       "11                 JAWA TIMUR     0.0       0.0     0.0            0.0   \n",
       "12           KALIMANTAN BARAT     0.0       0.0     0.0            0.0   \n",
       "13         KALIMANTAN SELATAN     0.0       0.0     0.0            0.0   \n",
       "14          KALIMANTAN TENGAH     0.0       0.0     0.0            0.0   \n",
       "15           KALIMANTAN TIMUR     0.0       0.0     0.0            0.0   \n",
       "16           KALIMANTAN UTARA     0.0       0.0     0.0            0.0   \n",
       "17  KEPULAUAN BANGKA BELITUNG     0.0       0.0     0.0            0.0   \n",
       "18             KEPULAUAN RIAU     0.0       0.0     0.0            0.0   \n",
       "19                    LAMPUNG     0.0       0.0     0.0            0.0   \n",
       "20                     MALUKU     0.0       0.0     0.0            0.0   \n",
       "21               MALUKU UTARA     0.0       0.0     0.0            0.0   \n",
       "22        NUSA TENGGARA BARAT     0.0       0.0     0.0            0.0   \n",
       "23        NUSA TENGGARA TIMUR     0.0       0.0     0.0            0.0   \n",
       "24                      PAPUA     0.0       0.0     0.0            0.0   \n",
       "25                PAPUA BARAT     0.0       0.0     0.0            0.0   \n",
       "26           PAPUA BARAT DAYA     0.0       0.0     0.0            0.0   \n",
       "27           PAPUA PEGUNUNGAN     0.0       0.0     0.0            0.0   \n",
       "28              PAPUA SELATAN     0.0       0.0     0.0            0.0   \n",
       "29               PAPUA TENGAH     0.0       0.0     0.0            0.0   \n",
       "30                       RIAU     0.0       0.0     0.0            0.0   \n",
       "31             SULAWESI BARAT     0.0       0.0     0.0            0.0   \n",
       "32           SULAWESI SELATAN     0.0       0.0     0.0            0.0   \n",
       "33            SULAWESI TENGAH     0.0       0.0     0.0            0.0   \n",
       "34          SULAWESI TENGGARA     0.0       0.0     0.0            0.0   \n",
       "35             SULAWESI UTARA     0.0       0.0     0.0            0.0   \n",
       "36             SUMATERA BARAT     0.0       0.0     0.0            0.0   \n",
       "37           SUMATERA SELATAN     0.0       0.0     0.0            0.0   \n",
       "38             SUMATERA UTARA     0.0       0.0     0.0            0.0   \n",
       "\n",
       "   periode_informasi jenis_informasi tipe_informasi        date  \\\n",
       "0            Bulanan              CH       Analisis  01-11-2024   \n",
       "1            Bulanan              CH       Analisis  01-11-2024   \n",
       "2            Bulanan              CH       Analisis  01-11-2024   \n",
       "3            Bulanan              CH       Analisis  01-11-2024   \n",
       "4            Bulanan              CH       Analisis  01-11-2024   \n",
       "5            Bulanan              CH       Analisis  01-11-2024   \n",
       "6            Bulanan              CH       Analisis  01-11-2024   \n",
       "7            Bulanan              CH       Analisis  01-11-2024   \n",
       "8            Bulanan              CH       Analisis  01-11-2024   \n",
       "9            Bulanan              CH       Analisis  01-11-2024   \n",
       "10           Bulanan              CH       Analisis  01-11-2024   \n",
       "11           Bulanan              CH       Analisis  01-11-2024   \n",
       "12           Bulanan              CH       Analisis  01-11-2024   \n",
       "13           Bulanan              CH       Analisis  01-11-2024   \n",
       "14           Bulanan              CH       Analisis  01-11-2024   \n",
       "15           Bulanan              CH       Analisis  01-11-2024   \n",
       "16           Bulanan              CH       Analisis  01-11-2024   \n",
       "17           Bulanan              CH       Analisis  01-11-2024   \n",
       "18           Bulanan              CH       Analisis  01-11-2024   \n",
       "19           Bulanan              CH       Analisis  01-11-2024   \n",
       "20           Bulanan              CH       Analisis  01-11-2024   \n",
       "21           Bulanan              CH       Analisis  01-11-2024   \n",
       "22           Bulanan              CH       Analisis  01-11-2024   \n",
       "23           Bulanan              CH       Analisis  01-11-2024   \n",
       "24           Bulanan              CH       Analisis  01-11-2024   \n",
       "25           Bulanan              CH       Analisis  01-11-2024   \n",
       "26           Bulanan              CH       Analisis  01-11-2024   \n",
       "27           Bulanan              CH       Analisis  01-11-2024   \n",
       "28           Bulanan              CH       Analisis  01-11-2024   \n",
       "29           Bulanan              CH       Analisis  01-11-2024   \n",
       "30           Bulanan              CH       Analisis  01-11-2024   \n",
       "31           Bulanan              CH       Analisis  01-11-2024   \n",
       "32           Bulanan              CH       Analisis  01-11-2024   \n",
       "33           Bulanan              CH       Analisis  01-11-2024   \n",
       "34           Bulanan              CH       Analisis  01-11-2024   \n",
       "35           Bulanan              CH       Analisis  01-11-2024   \n",
       "36           Bulanan              CH       Analisis  01-11-2024   \n",
       "37           Bulanan              CH       Analisis  01-11-2024   \n",
       "38           Bulanan              CH       Analisis  01-11-2024   \n",
       "\n",
       "                date_datetime  \n",
       "0  2024-11-01 18:49:02.787702  \n",
       "1  2024-11-01 18:49:02.787702  \n",
       "2  2024-11-01 18:49:02.787702  \n",
       "3  2024-11-01 18:49:02.787702  \n",
       "4  2024-11-01 18:49:02.787702  \n",
       "5  2024-11-01 18:49:02.787702  \n",
       "6  2024-11-01 18:49:02.787702  \n",
       "7  2024-11-01 18:49:02.787702  \n",
       "8  2024-11-01 18:49:02.787702  \n",
       "9  2024-11-01 18:49:02.787702  \n",
       "10 2024-11-01 18:49:02.787702  \n",
       "11 2024-11-01 18:49:02.787702  \n",
       "12 2024-11-01 18:49:02.787702  \n",
       "13 2024-11-01 18:49:02.787702  \n",
       "14 2024-11-01 18:49:02.787702  \n",
       "15 2024-11-01 18:49:02.787702  \n",
       "16 2024-11-01 18:49:02.787702  \n",
       "17 2024-11-01 18:49:02.787702  \n",
       "18 2024-11-01 18:49:02.787702  \n",
       "19 2024-11-01 18:49:02.787702  \n",
       "20 2024-11-01 18:49:02.787702  \n",
       "21 2024-11-01 18:49:02.787702  \n",
       "22 2024-11-01 18:49:02.787702  \n",
       "23 2024-11-01 18:49:02.787702  \n",
       "24 2024-11-01 18:49:02.787702  \n",
       "25 2024-11-01 18:49:02.787702  \n",
       "26 2024-11-01 18:49:02.787702  \n",
       "27 2024-11-01 18:49:02.787702  \n",
       "28 2024-11-01 18:49:02.787702  \n",
       "29 2024-11-01 18:49:02.787702  \n",
       "30 2024-11-01 18:49:02.787702  \n",
       "31 2024-11-01 18:49:02.787702  \n",
       "32 2024-11-01 18:49:02.787702  \n",
       "33 2024-11-01 18:49:02.787702  \n",
       "34 2024-11-01 18:49:02.787702  \n",
       "35 2024-11-01 18:49:02.787702  \n",
       "36 2024-11-01 18:49:02.787702  \n",
       "37 2024-11-01 18:49:02.787702  \n",
       "38 2024-11-01 18:49:02.787702  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wilayah</th>\n",
       "      <th>rendah</th>\n",
       "      <th>menengah</th>\n",
       "      <th>tinggi</th>\n",
       "      <th>sangat_tinggi</th>\n",
       "      <th>periode_informasi</th>\n",
       "      <th>jenis_informasi</th>\n",
       "      <th>tipe_informasi</th>\n",
       "      <th>date</th>\n",
       "      <th>date_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACEH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BALI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANTEN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENGKULU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DKI JAKARTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GORONTALO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JAMBI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KALIMANTAN BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KALIMANTAN SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KALIMANTAN TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KALIMANTAN TIMUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KALIMANTAN UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KEPULAUAN BANGKA BELITUNG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KEPULAUAN RIAU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MALUKU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MALUKU UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NUSA TENGGARA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NUSA TENGGARA TIMUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PAPUA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PAPUA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PAPUA BARAT DAYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PAPUA PEGUNUNGAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PAPUA SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PAPUA TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RIAU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SULAWESI BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SULAWESI TENGAH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SULAWESI TENGGARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SULAWESI UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SUMATERA UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bulanan</td>\n",
       "      <td>CH</td>\n",
       "      <td>Analisis</td>\n",
       "      <td>01-11-2024</td>\n",
       "      <td>2024-11-01 18:49:02.787702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      wilayah  rendah  menengah  tinggi  sangat_tinggi  \\\n",
       "0                   INDONESIA     0.0       0.0     0.0            0.0   \n",
       "1                        ACEH     0.0       0.0     0.0            0.0   \n",
       "2                        BALI     0.0       0.0     0.0            0.0   \n",
       "3                      BANTEN     0.0       0.0     0.0            0.0   \n",
       "4                    BENGKULU     0.0       0.0     0.0            0.0   \n",
       "5               DI YOGYAKARTA     0.0       0.0     0.0            0.0   \n",
       "6                 DKI JAKARTA     0.0       0.0     0.0            0.0   \n",
       "7                   GORONTALO     0.0       0.0     0.0            0.0   \n",
       "8                       JAMBI     0.0       0.0     0.0            0.0   \n",
       "9                  JAWA BARAT     0.0       0.0     0.0            0.0   \n",
       "10                JAWA TENGAH     0.0       0.0     0.0            0.0   \n",
       "11                 JAWA TIMUR     0.0       0.0     0.0            0.0   \n",
       "12           KALIMANTAN BARAT     0.0       0.0     0.0            0.0   \n",
       "13         KALIMANTAN SELATAN     0.0       0.0     0.0            0.0   \n",
       "14          KALIMANTAN TENGAH     0.0       0.0     0.0            0.0   \n",
       "15           KALIMANTAN TIMUR     0.0       0.0     0.0            0.0   \n",
       "16           KALIMANTAN UTARA     0.0       0.0     0.0            0.0   \n",
       "17  KEPULAUAN BANGKA BELITUNG     0.0       0.0     0.0            0.0   \n",
       "18             KEPULAUAN RIAU     0.0       0.0     0.0            0.0   \n",
       "19                    LAMPUNG     0.0       0.0     0.0            0.0   \n",
       "20                     MALUKU     0.0       0.0     0.0            0.0   \n",
       "21               MALUKU UTARA     0.0       0.0     0.0            0.0   \n",
       "22        NUSA TENGGARA BARAT     0.0       0.0     0.0            0.0   \n",
       "23        NUSA TENGGARA TIMUR     0.0       0.0     0.0            0.0   \n",
       "24                      PAPUA     0.0       0.0     0.0            0.0   \n",
       "25                PAPUA BARAT     0.0       0.0     0.0            0.0   \n",
       "26           PAPUA BARAT DAYA     0.0       0.0     0.0            0.0   \n",
       "27           PAPUA PEGUNUNGAN     0.0       0.0     0.0            0.0   \n",
       "28              PAPUA SELATAN     0.0       0.0     0.0            0.0   \n",
       "29               PAPUA TENGAH     0.0       0.0     0.0            0.0   \n",
       "30                       RIAU     0.0       0.0     0.0            0.0   \n",
       "31             SULAWESI BARAT     0.0       0.0     0.0            0.0   \n",
       "32           SULAWESI SELATAN     0.0       0.0     0.0            0.0   \n",
       "33            SULAWESI TENGAH     0.0       0.0     0.0            0.0   \n",
       "34          SULAWESI TENGGARA     0.0       0.0     0.0            0.0   \n",
       "35             SULAWESI UTARA     0.0       0.0     0.0            0.0   \n",
       "36             SUMATERA BARAT     0.0       0.0     0.0            0.0   \n",
       "37           SUMATERA SELATAN     0.0       0.0     0.0            0.0   \n",
       "38             SUMATERA UTARA     0.0       0.0     0.0            0.0   \n",
       "\n",
       "   periode_informasi jenis_informasi tipe_informasi        date  \\\n",
       "0            Bulanan              CH       Analisis  01-11-2024   \n",
       "1            Bulanan              CH       Analisis  01-11-2024   \n",
       "2            Bulanan              CH       Analisis  01-11-2024   \n",
       "3            Bulanan              CH       Analisis  01-11-2024   \n",
       "4            Bulanan              CH       Analisis  01-11-2024   \n",
       "5            Bulanan              CH       Analisis  01-11-2024   \n",
       "6            Bulanan              CH       Analisis  01-11-2024   \n",
       "7            Bulanan              CH       Analisis  01-11-2024   \n",
       "8            Bulanan              CH       Analisis  01-11-2024   \n",
       "9            Bulanan              CH       Analisis  01-11-2024   \n",
       "10           Bulanan              CH       Analisis  01-11-2024   \n",
       "11           Bulanan              CH       Analisis  01-11-2024   \n",
       "12           Bulanan              CH       Analisis  01-11-2024   \n",
       "13           Bulanan              CH       Analisis  01-11-2024   \n",
       "14           Bulanan              CH       Analisis  01-11-2024   \n",
       "15           Bulanan              CH       Analisis  01-11-2024   \n",
       "16           Bulanan              CH       Analisis  01-11-2024   \n",
       "17           Bulanan              CH       Analisis  01-11-2024   \n",
       "18           Bulanan              CH       Analisis  01-11-2024   \n",
       "19           Bulanan              CH       Analisis  01-11-2024   \n",
       "20           Bulanan              CH       Analisis  01-11-2024   \n",
       "21           Bulanan              CH       Analisis  01-11-2024   \n",
       "22           Bulanan              CH       Analisis  01-11-2024   \n",
       "23           Bulanan              CH       Analisis  01-11-2024   \n",
       "24           Bulanan              CH       Analisis  01-11-2024   \n",
       "25           Bulanan              CH       Analisis  01-11-2024   \n",
       "26           Bulanan              CH       Analisis  01-11-2024   \n",
       "27           Bulanan              CH       Analisis  01-11-2024   \n",
       "28           Bulanan              CH       Analisis  01-11-2024   \n",
       "29           Bulanan              CH       Analisis  01-11-2024   \n",
       "30           Bulanan              CH       Analisis  01-11-2024   \n",
       "31           Bulanan              CH       Analisis  01-11-2024   \n",
       "32           Bulanan              CH       Analisis  01-11-2024   \n",
       "33           Bulanan              CH       Analisis  01-11-2024   \n",
       "34           Bulanan              CH       Analisis  01-11-2024   \n",
       "35           Bulanan              CH       Analisis  01-11-2024   \n",
       "36           Bulanan              CH       Analisis  01-11-2024   \n",
       "37           Bulanan              CH       Analisis  01-11-2024   \n",
       "38           Bulanan              CH       Analisis  01-11-2024   \n",
       "\n",
       "                date_datetime  \n",
       "0  2024-11-01 18:49:02.787702  \n",
       "1  2024-11-01 18:49:02.787702  \n",
       "2  2024-11-01 18:49:02.787702  \n",
       "3  2024-11-01 18:49:02.787702  \n",
       "4  2024-11-01 18:49:02.787702  \n",
       "5  2024-11-01 18:49:02.787702  \n",
       "6  2024-11-01 18:49:02.787702  \n",
       "7  2024-11-01 18:49:02.787702  \n",
       "8  2024-11-01 18:49:02.787702  \n",
       "9  2024-11-01 18:49:02.787702  \n",
       "10 2024-11-01 18:49:02.787702  \n",
       "11 2024-11-01 18:49:02.787702  \n",
       "12 2024-11-01 18:49:02.787702  \n",
       "13 2024-11-01 18:49:02.787702  \n",
       "14 2024-11-01 18:49:02.787702  \n",
       "15 2024-11-01 18:49:02.787702  \n",
       "16 2024-11-01 18:49:02.787702  \n",
       "17 2024-11-01 18:49:02.787702  \n",
       "18 2024-11-01 18:49:02.787702  \n",
       "19 2024-11-01 18:49:02.787702  \n",
       "20 2024-11-01 18:49:02.787702  \n",
       "21 2024-11-01 18:49:02.787702  \n",
       "22 2024-11-01 18:49:02.787702  \n",
       "23 2024-11-01 18:49:02.787702  \n",
       "24 2024-11-01 18:49:02.787702  \n",
       "25 2024-11-01 18:49:02.787702  \n",
       "26 2024-11-01 18:49:02.787702  \n",
       "27 2024-11-01 18:49:02.787702  \n",
       "28 2024-11-01 18:49:02.787702  \n",
       "29 2024-11-01 18:49:02.787702  \n",
       "30 2024-11-01 18:49:02.787702  \n",
       "31 2024-11-01 18:49:02.787702  \n",
       "32 2024-11-01 18:49:02.787702  \n",
       "33 2024-11-01 18:49:02.787702  \n",
       "34 2024-11-01 18:49:02.787702  \n",
       "35 2024-11-01 18:49:02.787702  \n",
       "36 2024-11-01 18:49:02.787702  \n",
       "37 2024-11-01 18:49:02.787702  \n",
       "38 2024-11-01 18:49:02.787702  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contoh DataFrame A (data baru yang diproses)\n",
    "data_A = {\n",
    "    'date': ['2024-12-09', '2024-12-10'],\n",
    "    'wilayah': ['Jakarta', 'Bandung'],\n",
    "    'jenis_produk': ['A', 'B'],\n",
    "    'value': [100, 200]\n",
    "}\n",
    "df_A = pd.DataFrame(data_A)\n",
    "\n",
    "# Contoh DataFrame B (data untuk visualisasi)\n",
    "data_B = {\n",
    "    'date': ['2024-12-09', '2024-12-08'],\n",
    "    'wilayah': ['Jakarta', 'Bandung'],\n",
    "    'jenis_produk': ['A', 'A'],\n",
    "    'value': [50, 150]\n",
    "}\n",
    "df_B = pd.DataFrame(data_B)\n",
    "\n",
    "# # Menggabungkan df_A ke df_B berdasarkan kolom 'date', 'wilayah', dan 'jenis_produk'\n",
    "# df_combined = pd.merge(df_B, df_A, on=['date', 'wilayah', 'jenis_produk'], how='outer', suffixes=('_B', '_A'))\n",
    "\n",
    "# # Memilih nilai dari df_A jika ada, jika tidak gunakan nilai dari df_B\n",
    "# df_combined['value'] = df_combined['value_A'].combine_first(df_combined['value_B'])\n",
    "\n",
    "# # Menghapus kolom yang tidak diperlukan\n",
    "# df_combined = df_combined[['date', 'wilayah', 'jenis_produk', 'value']]\n",
    "\n",
    "# # Hasil akhir\n",
    "# print(df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>jenis_produk</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>A</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-10</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>B</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wilayah jenis_produk  value\n",
       "0  2024-12-09  Jakarta            A    100\n",
       "1  2024-12-10  Bandung            B    200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>jenis_produk</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>A</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>A</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wilayah jenis_produk  value\n",
       "0  2024-12-09  Jakarta            A     50\n",
       "1  2024-12-08  Bandung            A    150"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.merge(df_B, df_A, on=['date', 'wilayah', 'jenis_produk'], how='outer', suffixes=('_B', '_A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>jenis_produk</th>\n",
       "      <th>value_B</th>\n",
       "      <th>value_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>A</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>A</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-10</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wilayah jenis_produk  value_B  value_A\n",
       "0  2024-12-09  Jakarta            A     50.0    100.0\n",
       "1  2024-12-08  Bandung            A    150.0      NaN\n",
       "2  2024-12-10  Bandung            B      NaN    200.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['value'] = df_combined['value_A'].combine_first(df_combined['value_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>jenis_produk</th>\n",
       "      <th>value_B</th>\n",
       "      <th>value_A</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>A</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>A</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-10</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wilayah jenis_produk  value_B  value_A  value\n",
       "0  2024-12-09  Jakarta            A     50.0    100.0  100.0\n",
       "1  2024-12-08  Bandung            A    150.0      NaN  150.0\n",
       "2  2024-12-10  Bandung            B      NaN    200.0  200.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Contoh DataFrame A (data baru yang diproses)\n",
    "data_A = {\n",
    "    'date': ['2024-12-09', '2024-12-10', '2024-12-11', '2024-12-12', '2024-12-13'],\n",
    "    'wilayah': ['Jakarta', 'Bandung', 'Surabaya', 'Medan', 'Bali'],\n",
    "    'jenis_produk': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'value': [100, 200, 300, 400, 500]\n",
    "}\n",
    "df_A = pd.DataFrame(data_A)\n",
    "\n",
    "# Contoh DataFrame B (data untuk visualisasi)\n",
    "data_B = {\n",
    "    'date': ['2024-12-09', '2024-12-08', '2024-12-11', '2024-12-14'],\n",
    "    'wilayah': ['Jakarta', 'Bandung', 'Surabaya', 'Medan'],\n",
    "    'jenis_produk': ['A', 'A', 'C', 'D'],\n",
    "    'value': [50, 150, 250, 350]\n",
    "}\n",
    "df_B = pd.DataFrame(data_B)\n",
    "\n",
    "# Mengatur 'date', 'wilayah', dan 'jenis_produk' sebagai index untuk update\n",
    "df_A.set_index(['date', 'wilayah', 'jenis_produk'], inplace=True)\n",
    "df_B.set_index(['date', 'wilayah', 'jenis_produk'], inplace=True)\n",
    "\n",
    "# # Memperbarui df_B dengan nilai dari df_A\n",
    "df_B.update(df_A)\n",
    "\n",
    "# # Mencari baris di df_A yang tidak ada di df_B\n",
    "new_rows = df_A[~df_A.index.isin(df_B.index)]\n",
    "\n",
    "# # Menggabungkan baris baru ke df_B\n",
    "df_B = pd.concat([df_B, new_rows])\n",
    "\n",
    "# # Mengembalikan index menjadi kolom biasa\n",
    "df_B.reset_index(inplace=True)\n",
    "\n",
    "# # Hasil akhir\n",
    "# print(df_B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>jenis_produk</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-12-09</th>\n",
       "      <th>Jakarta</th>\n",
       "      <th>A</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-10</th>\n",
       "      <th>Bandung</th>\n",
       "      <th>B</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-11</th>\n",
       "      <th>Surabaya</th>\n",
       "      <th>C</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-12</th>\n",
       "      <th>Medan</th>\n",
       "      <th>D</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-13</th>\n",
       "      <th>Bali</th>\n",
       "      <th>E</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  value\n",
       "date       wilayah  jenis_produk       \n",
       "2024-12-09 Jakarta  A               100\n",
       "2024-12-10 Bandung  B               200\n",
       "2024-12-11 Surabaya C               300\n",
       "2024-12-12 Medan    D               400\n",
       "2024-12-13 Bali     E               500"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>jenis_produk</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-12-09</th>\n",
       "      <th>Jakarta</th>\n",
       "      <th>A</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-08</th>\n",
       "      <th>Bandung</th>\n",
       "      <th>A</th>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-11</th>\n",
       "      <th>Surabaya</th>\n",
       "      <th>C</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-14</th>\n",
       "      <th>Medan</th>\n",
       "      <th>D</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-10</th>\n",
       "      <th>Bandung</th>\n",
       "      <th>B</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-12</th>\n",
       "      <th>Medan</th>\n",
       "      <th>D</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-13</th>\n",
       "      <th>Bali</th>\n",
       "      <th>E</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  value\n",
       "date       wilayah  jenis_produk       \n",
       "2024-12-09 Jakarta  A               100\n",
       "2024-12-08 Bandung  A               150\n",
       "2024-12-11 Surabaya C               300\n",
       "2024-12-14 Medan    D               350\n",
       "2024-12-10 Bandung  B               200\n",
       "2024-12-12 Medan    D               400\n",
       "2024-12-13 Bali     E               500"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B.update(df_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>jenis_produk</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-12-10</th>\n",
       "      <th>Bandung</th>\n",
       "      <th>B</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-12</th>\n",
       "      <th>Medan</th>\n",
       "      <th>D</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-13</th>\n",
       "      <th>Bali</th>\n",
       "      <th>E</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 value\n",
       "date       wilayah jenis_produk       \n",
       "2024-12-10 Bandung B               200\n",
       "2024-12-12 Medan   D               400\n",
       "2024-12-13 Bali    E               500"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>jenis_produk</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>A</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-10</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>B</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        date  wilayah jenis_produk  value\n",
       "0      0  2024-12-09  Jakarta            A    100\n",
       "1      1  2024-12-10  Bandung            B    200"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipe_informasi = 'ANALISIS_SIFAT_HUJAN'\n",
    "\n",
    "wilayah_upt = 'DI YOGYAKARTA'\n",
    "data = dataframe[['Kategori', 'PROPINSI', 'KABUPATEN', 'KECAMATAN', 'Area_H']]\n",
    "\n",
    "data = data[data['PROPINSI'] == 'DI YOGYAKARTA']\n",
    "\n",
    "# Agregasi Propinsi\n",
    "sum_area = data['Area_H'].sum()\n",
    "cat_df = data.groupby('Kategori')['Area_H'].sum()\n",
    "prov_df = round(cat_df / sum_area, 4)\n",
    "prov_df = prov_df.reset_index()\n",
    "prov_df = prov_df.rename({'Area_H' : 'Persentase',}, axis='columns')\n",
    "prov_df['Persentase'] = round(prov_df['Persentase']*100,2)\n",
    "prov_df['Persentase%'] = round(prov_df['Persentase'],2).astype(str) + '%'\n",
    "prov_df.drop(prov_df.index[0], inplace=True)\n",
    "prov_df[\"Wilayah\"] = f'PROVINSI {wilayah_upt}'\n",
    "\n",
    "categories_ch = ['Rendah', 'Menengah', 'Tinggi', 'Sangat Tinggi']\n",
    "categories_sh = ['Bawah Normal', 'Normal', 'Atas Normal']\n",
    "\n",
    "if tipe_informasi == 'ANALISIS_CURAH_HUJAN':\n",
    "    all_combinations = pd.MultiIndex.from_product([prov_df['Wilayah'].unique(), categories_ch], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "    prov_df_complete = all_combinations.merge(prov_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "    prov_df_complete['Persentase'] = prov_df_complete['Persentase'].fillna(0)\n",
    "    prov_df_complete['Persentase%'] = prov_df_complete['Persentase%'].fillna('0%')\n",
    "    non_zero_df = prov_df_complete[prov_df_complete['Persentase'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Persentase'].sum()\n",
    "    non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "    prov_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "    if 'Persentase%' in prov_df_complete.columns:\n",
    "        prov_df_complete['Persentase%'] = prov_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "    prov_df_pivot = pd.pivot(prov_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "    prov_df_pivot = prov_df_pivot.reset_index()\n",
    "    prov_df_pivot.columns.name = None\n",
    "\n",
    "    # Agregasi Kabupaten\n",
    "    kab_area_sum = data.groupby('KABUPATEN')['Area_H'].sum()\n",
    "    kab_cat_area_sum = data.groupby(['Kategori','KABUPATEN'])['Area_H'].sum()\n",
    "    kab_df = round(kab_cat_area_sum / kab_area_sum, 4)\n",
    "    kab_df = kab_df.reset_index()\n",
    "    kab_df = kab_df[(kab_df['Kategori'] != \" \") & (kab_df['KABUPATEN'] != \" \")]\n",
    "    kab_df['Area_H'] = round(kab_df['Area_H']*100, 2)\n",
    "    all_combinations_kab = pd.MultiIndex.from_product([kab_df['KABUPATEN'].unique(), categories_ch], names=['KABUPATEN', 'Kategori']).to_frame(index=False)\n",
    "    kab_df_complete = all_combinations_kab.merge(kab_df, on=['KABUPATEN', 'Kategori'], how='left')\n",
    "    kab_df_complete['Area_H'] = kab_df_complete['Area_H'].fillna(0)\n",
    "    kab_df_complete_clean = pd.DataFrame()\n",
    "    for name, group in kab_df_complete.groupby('KABUPATEN'):\n",
    "        non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Area_H'].sum()\n",
    "        \n",
    "        if total_non_zero > 0:\n",
    "            non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "        \n",
    "        group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "        kab_df_complete_clean = pd.concat([kab_df_complete_clean, group])\n",
    "\n",
    "    kab_df_complete_clean = kab_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    top_5_areas = kab_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(5, 'Area_H')).reset_index(drop=True)\n",
    "    top_by_kategori = top_5_areas.groupby('Kategori')['KABUPATEN'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "    kab_df_complete_clean = pd.pivot(kab_df_complete_clean, index='KABUPATEN', columns='Kategori', values='Area_H')\n",
    "    kab_df_complete_clean = kab_df_complete_clean.reset_index()\n",
    "    kab_df_complete_clean.columns.name = None\n",
    "    kab_df_complete_clean.drop(kab_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "\n",
    "    # Agregasi Kecamatan\n",
    "    kec_area_sum = data.groupby('KECAMATAN')['Area_H'].sum()\n",
    "    kec_cat_area_sum = data.groupby(['Kategori','KECAMATAN'])['Area_H'].sum()\n",
    "    kec_df = round(kec_cat_area_sum / kec_area_sum, 4)\n",
    "    kec_df = kec_df.reset_index()\n",
    "    kec_df = kec_df[(kec_df['Kategori'] != \" \") & (kec_df['KECAMATAN'] != \" \")]\n",
    "    kec_df['Area_H'] = round(kec_df['Area_H']*100, 2)\n",
    "    all_combinations_kec = pd.MultiIndex.from_product([kec_df['KECAMATAN'].unique(), categories_ch], names=['KECAMATAN', 'Kategori']).to_frame(index=False)\n",
    "    kec_df_complete = all_combinations_kec.merge(kec_df, on=['KECAMATAN', 'Kategori'], how='left')\n",
    "    kec_df_complete['Area_H'] = kec_df_complete['Area_H'].fillna(0)\n",
    "    kec_df_complete_clean = pd.DataFrame()\n",
    "    for name, group in kec_df_complete.groupby('KECAMATAN'):\n",
    "        non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Area_H'].sum()\n",
    "        \n",
    "        if total_non_zero > 0:\n",
    "            non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "        \n",
    "        group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "        kec_df_complete_clean = pd.concat([kec_df_complete_clean, group])\n",
    "\n",
    "    kec_df_complete_clean = kec_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "    kec_df_complete_clean = pd.pivot(kec_df_complete_clean, index='KECAMATAN', columns='Kategori', values='Area_H')\n",
    "    kec_df_complete_clean = kec_df_complete_clean.reset_index()\n",
    "    kec_df_complete_clean.columns.name = None\n",
    "    kec_df_complete_clean.drop(kec_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "    # concat kecamatan, kabupaten, provinsi\n",
    "    kec_df_complete_clean = kec_df_complete_clean.rename(columns={'KECAMATAN': 'Wilayah'})\n",
    "    kab_df_complete_clean = kab_df_complete_clean.rename(columns={'KABUPATEN': 'Wilayah'})\n",
    "#     kec_df_complete_clean = pd.concat([kab_df_complete_clean, kec_df_complete_clean], ignore_index=True)\n",
    "#     kec_df_complete_clean = pd.concat([prov_df_pivot, kec_df_complete_clean], ignore_index=True)\n",
    "\n",
    "\n",
    "    # # Concat Propinsi to kabupaten\n",
    "    # kab_df_complete_clean = kab_df_complete_clean.rename(columns={'KABUPATEN': 'Wilayah'})\n",
    "    kab_df_complete_clean = pd.concat([prov_df_pivot, kab_df_complete_clean], ignore_index=True)\n",
    "\n",
    "    # Get kategori value for agregasi propinsi\n",
    "    sgt_tinggi = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Sangat Tinggi', 'Persentase'].values[0]\n",
    "    tinggi = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Tinggi', 'Persentase'].values[0]\n",
    "    rendah = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Rendah', 'Persentase'].values[0]\n",
    "    menengah =  prov_df_complete.loc[prov_df_complete['Kategori'] == 'Menengah', 'Persentase'].values[0]\n",
    "    \n",
    "\n",
    "    kab_df_complete_clean = kab_df_complete_clean.rename(columns={'Rendah': 'Rendah (%)', 'Menengah': 'Menengah (%)','Tinggi': 'Tinggi (%)', 'Sangat Tinggi': 'Sangat Tinggi (%)'})\n",
    "    new_order = ['Wilayah', 'Rendah (%)', 'Menengah (%)', 'Tinggi (%)', 'Sangat Tinggi (%)']\n",
    "    kab_df_complete_clean = kab_df_complete_clean[new_order]\n",
    "    \n",
    "elif tipe_informasi == 'ANALISIS_SIFAT_HUJAN':\n",
    "    all_combinations = pd.MultiIndex.from_product([prov_df['Wilayah'].unique(), categories_sh], names=['Wilayah', 'Kategori']).to_frame(index=False)\n",
    "    prov_df_complete = all_combinations.merge(prov_df, on=['Wilayah', 'Kategori'], how='left')\n",
    "    prov_df_complete['Persentase'] = prov_df_complete['Persentase'].fillna(0)\n",
    "    prov_df_complete['Persentase%'] = prov_df_complete['Persentase%'].fillna('0%')\n",
    "    non_zero_df = prov_df_complete[prov_df_complete['Persentase'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Persentase'].sum()\n",
    "    non_zero_df['Persentase'] = (non_zero_df['Persentase'] * (100 / total_non_zero)).round(2)\n",
    "    prov_df_complete.loc[non_zero_df.index, 'Persentase'] = non_zero_df['Persentase']\n",
    "\n",
    "    # Update the 'Persentase%' column if it exists\n",
    "    if 'Persentase%' in prov_df_complete.columns:\n",
    "        prov_df_complete['Persentase%'] = prov_df_complete['Persentase'].astype(str) + '%'\n",
    "\n",
    "    prov_df_pivot = pd.pivot(prov_df_complete, index='Wilayah', columns='Kategori', values='Persentase')\n",
    "    prov_df_pivot = prov_df_pivot.reset_index()\n",
    "    prov_df_pivot.columns.name = None\n",
    "\n",
    "    # Agregasi Kabupaten\n",
    "    kab_area_sum = data.groupby('KABUPATEN')['Area_H'].sum()\n",
    "    kab_cat_area_sum = data.groupby(['Kategori','KABUPATEN'])['Area_H'].sum()\n",
    "    kab_df = round(kab_cat_area_sum / kab_area_sum, 4)\n",
    "    kab_df = kab_df.reset_index()\n",
    "    kab_df = kab_df[(kab_df['Kategori'] != \" \") & (kab_df['KABUPATEN'] != \" \")]\n",
    "    kab_df['Area_H'] = round(kab_df['Area_H']*100, 2)\n",
    "    all_combinations_kab = pd.MultiIndex.from_product([kab_df['KABUPATEN'].unique(), categories_sh], names=['KABUPATEN', 'Kategori']).to_frame(index=False)\n",
    "    kab_df_complete = all_combinations_kab.merge(kab_df, on=['KABUPATEN', 'Kategori'], how='left')\n",
    "    kab_df_complete['Area_H'] = kab_df_complete['Area_H'].fillna(0)\n",
    "    kab_df_complete_clean = pd.DataFrame()\n",
    "    for name, group in kab_df_complete.groupby('KABUPATEN'):\n",
    "        non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Area_H'].sum()\n",
    "\n",
    "        if total_non_zero > 0:\n",
    "            non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "\n",
    "        group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "        kab_df_complete_clean = pd.concat([kab_df_complete_clean, group])\n",
    "\n",
    "    kab_df_complete_clean = kab_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    top_5_areas = kab_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(5, 'Area_H')).reset_index(drop=True)\n",
    "    top_by_kategori = top_5_areas.groupby('Kategori')['KABUPATEN'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "    kab_df_complete_clean = pd.pivot(kab_df_complete_clean, index='KABUPATEN', columns='Kategori', values='Area_H')\n",
    "    kab_df_complete_clean = kab_df_complete_clean.reset_index()\n",
    "    kab_df_complete_clean.columns.name = None\n",
    "    kab_df_complete_clean.drop(kab_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "\n",
    "    # Agregasi Kecamatan\n",
    "    kec_adm = data[[ 'KABUPATEN', 'KECAMATAN']]\n",
    "    kec_adm = kec_adm.rename(columns={'KECAMATAN': 'Wilayah'})\n",
    "    kec_adm = kec_adm.drop_duplicates(subset='Wilayah', keep='last')\n",
    "\n",
    "\n",
    "    kec_area_sum = data.groupby('KECAMATAN')['Area_H'].sum()\n",
    "    kec_cat_area_sum = data.groupby(['Kategori','KECAMATAN'])['Area_H'].sum()\n",
    "    kec_df = round(kec_cat_area_sum / kec_area_sum, 4)\n",
    "    kec_df = kec_df.reset_index()\n",
    "    kec_df = kec_df[(kec_df['Kategori'] != \" \") & (kec_df['KECAMATAN'] != \" \")]\n",
    "    kec_df['Area_H'] = round(kec_df['Area_H']*100, 2)\n",
    "    all_combinations_kec = pd.MultiIndex.from_product([kec_df['KECAMATAN'].unique(), categories_sh], names=['KECAMATAN', 'Kategori']).to_frame(index=False)\n",
    "    kec_df_complete = all_combinations_kec.merge(kec_df, on=['KECAMATAN', 'Kategori'], how='left')\n",
    "    kec_df_complete['Area_H'] = kec_df_complete['Area_H'].fillna(0)\n",
    "    kec_df_complete_clean = pd.DataFrame()\n",
    "    for name, group in kec_df_complete.groupby('KECAMATAN'):\n",
    "        non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "        total_non_zero = non_zero_df['Area_H'].sum()\n",
    "\n",
    "        if total_non_zero > 0:\n",
    "            non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "\n",
    "        group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "        kec_df_complete_clean = pd.concat([kec_df_complete_clean, group])\n",
    "\n",
    "    kec_df_complete_clean = kec_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "    kec_df_complete_clean = pd.pivot(kec_df_complete_clean, index='KECAMATAN', columns='Kategori', values='Area_H')\n",
    "    kec_df_complete_clean = kec_df_complete_clean.reset_index()\n",
    "    kec_df_complete_clean.columns.name = None\n",
    "    kec_df_complete_clean.drop(kec_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "    # concat kecamatan, kabupaten, provinsi\n",
    "    kec_df_complete_clean = kec_df_complete_clean.rename(columns={'KECAMATAN': 'Wilayah'})\n",
    "    kab_df_complete_clean = kab_df_complete_clean.rename(columns={'KABUPATEN': 'Wilayah'})\n",
    "    # kec_df_complete_clean = pd.concat([kab_df_complete_clean, kec_df_complete_clean], ignore_index=True)\n",
    "    # kec_df_complete_clean = pd.concat([prov_df_pivot, kec_df_complete_clean], ignore_index=True)\n",
    "\n",
    "    # Merge kecamatan with kab name\n",
    "    kec_df_complete_clean = kec_df_complete_clean.merge(kec_adm, on='Wilayah', how='inner')\n",
    "\n",
    "\n",
    "\n",
    "    # # Concat Propinsi to kabupaten\n",
    "    #kab_df_complete_clean = kab_df_complete_clean.rename(columns={'KABUPATEN': 'Wilayah'})\n",
    "    kab_df_complete_clean_copy = kab_df_complete_clean.copy()\n",
    "    kab_df_complete_clean = pd.concat([prov_df_pivot, kab_df_complete_clean], ignore_index=True)\n",
    "\n",
    "    # Get kategori value for agregasi propinsi\n",
    "    atas_normal = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Atas Normal', 'Persentase'].values[0]\n",
    "    normal = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Normal', 'Persentase'].values[0]\n",
    "    bawah_normal = prov_df_complete.loc[prov_df_complete['Kategori'] == 'Bawah Normal', 'Persentase'].values[0]\n",
    "\n",
    "\n",
    "    kab_df_complete_clean = kab_df_complete_clean.rename(columns={'Bawah Normal': 'Bawah Normal (%)', 'Normal': 'Normal (%)','Atas Normal': 'Atas Normal (%)'})\n",
    "    new_order = ['Wilayah', 'Bawah Normal (%)', 'Normal (%)', 'Atas Normal (%)']\n",
    "    kab_df_complete_clean = kab_df_complete_clean[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_by_kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_complete, kab_df_complete_clean, prov_df_pivot, kab_df_complete_clean_copy, kec_df_complete_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kab_df_complete_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kab_area_sum = data.groupby('KABUPATEN')['Area_H'].sum()\n",
    "kab_cat_area_sum = data.groupby(['Kategori','KABUPATEN'])['Area_H'].sum()\n",
    "kab_df = round(kab_cat_area_sum / kab_area_sum, 4)\n",
    "kab_df = kab_df.reset_index()\n",
    "kab_df = kab_df[(kab_df['Kategori'] != \" \") & (kab_df['KABUPATEN'] != \" \")]\n",
    "kab_df['Area_H'] = round(kab_df['Area_H']*100, 2)\n",
    "all_combinations_kab = pd.MultiIndex.from_product([kab_df['KABUPATEN'].unique(), categories_sh], names=['KABUPATEN', 'Kategori']).to_frame(index=False)\n",
    "kab_df_complete = all_combinations_kab.merge(kab_df, on=['KABUPATEN', 'Kategori'], how='left')\n",
    "kab_df_complete['Area_H'] = kab_df_complete['Area_H'].fillna(0)\n",
    "kab_df_complete_clean = pd.DataFrame()\n",
    "for name, group in kab_df_complete.groupby('KABUPATEN'):\n",
    "    non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Area_H'].sum()\n",
    "\n",
    "    if total_non_zero > 0:\n",
    "        non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "\n",
    "    group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "    kab_df_complete_clean = pd.concat([kab_df_complete_clean, group])\n",
    "\n",
    "kab_df_complete_clean = kab_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "\n",
    "top_5_areas = kab_df_complete_clean.groupby('Kategori').apply(lambda x: x.nlargest(5, 'Area_H')).reset_index(drop=True)\n",
    "top_by_kategori = top_5_areas.groupby('Kategori')['KABUPATEN'].apply(lambda x: ', '.join(x)).to_dict()\n",
    "\n",
    "kab_df_complete_clean = pd.pivot(kab_df_complete_clean, index='KABUPATEN', columns='Kategori', values='Area_H')\n",
    "kab_df_complete_clean = kab_df_complete_clean.reset_index()\n",
    "kab_df_complete_clean.columns.name = None\n",
    "kab_df_complete_clean.drop(kab_df_complete_clean.index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kab_area_sum = data.groupby('KABUPATEN')['Area_H'].sum()\n",
    "kab_cat_area_sum = data.groupby(['Kategori','KABUPATEN'])['Area_H'].sum()\n",
    "kab_df = round(kab_cat_area_sum / kab_area_sum, 4)\n",
    "kab_df = kab_df.reset_index()\n",
    "kab_df = kab_df[(kab_df['Kategori'] != \" \") & (kab_df['KABUPATEN'] != \" \")]\n",
    "kab_df['Area_H'] = round(kab_df['Area_H']*100, 2)\n",
    "all_combinations_kab = pd.MultiIndex.from_product([kab_df['KABUPATEN'].unique(), categories_sh], names=['KABUPATEN', 'Kategori']).to_frame(index=False)\n",
    "kab_df_complete = all_combinations_kab.merge(kab_df, on=['KABUPATEN', 'Kategori'], how='left')\n",
    "\n",
    "kab_df_complete['Area_H'] = kab_df_complete['Area_H'].fillna(0)\n",
    "kab_df_complete_clean = pd.DataFrame()\n",
    "\n",
    "for name, group in kab_df_complete.groupby('KABUPATEN'):\n",
    "    non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Area_H'].sum()\n",
    "\n",
    "    if total_non_zero > 0:\n",
    "        non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "\n",
    "    group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "    kab_df_complete_clean = pd.concat([kab_df_complete_clean, group])\n",
    "    \n",
    "kab_df_complete_clean = kab_df_complete_clean.reset_index(drop=True)\n",
    "kab_df_complete_clean = pd.pivot(kab_df_complete_clean, index='KABUPATEN', columns='Kategori', values='Area_H')\n",
    "\n",
    "kab_df_complete_clean = kab_df_complete_clean.reset_index()\n",
    "kab_df_complete_clean.columns.name = None\n",
    "\n",
    "# kab_df_complete_clean.drop(kab_df_complete_clean.index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kab_df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kab_df_complete_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kab_df_complete_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kab_df_complete_clean_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_df_complete_clean.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_df[kec_df['KECAMATAN'] == 'WADO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_df['KECAMATAN'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_adm = data[[ 'KABUPATEN', 'KECAMATAN']]\n",
    "kec_adm = kec_adm.rename(columns={'KECAMATAN': 'Wilayah'})\n",
    "\n",
    "\n",
    "kec_area_sum = data.groupby('KECAMATAN')['Area_H'].sum()\n",
    "kec_cat_area_sum = data.groupby(['Kategori','KECAMATAN'])['Area_H'].sum()\n",
    "kec_df = round(kec_cat_area_sum / kec_area_sum, 4)\n",
    "kec_df = kec_df.reset_index()\n",
    "kec_df = kec_df[(kec_df['Kategori'] != \" \") & (kec_df['KECAMATAN'] != \" \")]\n",
    "kec_df['Area_H'] = round(kec_df['Area_H']*100, 2)\n",
    "all_combinations_kec = pd.MultiIndex.from_product([kec_df['KECAMATAN'].unique(), categories_sh], names=['KECAMATAN', 'Kategori']).to_frame(index=False)\n",
    "kec_df_complete = all_combinations_kec.merge(kec_df, on=['KECAMATAN', 'Kategori'], how='left')\n",
    "kec_df_complete['Area_H'] = kec_df_complete['Area_H'].fillna(0)\n",
    "kec_df_complete_clean = pd.DataFrame()\n",
    "for name, group in kec_df_complete.groupby('KECAMATAN'):\n",
    "    non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Area_H'].sum()\n",
    "\n",
    "    if total_non_zero > 0:\n",
    "        non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "\n",
    "    group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "    kec_df_complete_clean = pd.concat([kec_df_complete_clean, group])\n",
    "\n",
    "kec_df_complete_clean = kec_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "kec_df_complete_clean = pd.pivot(kec_df_complete_clean, index='KECAMATAN', columns='Kategori', values='Area_H')\n",
    "kec_df_complete_clean = kec_df_complete_clean.reset_index()\n",
    "kec_df_complete_clean.columns.name = None\n",
    "kec_df_complete_clean.drop(kec_df_complete_clean.index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_adm = data[[ 'KABUPATEN', 'KECAMATAN']]\n",
    "kec_adm = kec_adm.rename(columns={'KECAMATAN': 'Wilayah'})\n",
    "\n",
    "\n",
    "kec_area_sum = data.groupby('KECAMATAN')['Area_H'].sum()\n",
    "kec_cat_area_sum = data.groupby(['Kategori','KECAMATAN'])['Area_H'].sum()\n",
    "kec_df = round(kec_cat_area_sum / kec_area_sum, 4)\n",
    "kec_df = kec_df.reset_index()\n",
    "kec_df = kec_df[(kec_df['Kategori'] != \" \") & (kec_df['KECAMATAN'] != \" \")]\n",
    "kec_df['Area_H'] = round(kec_df['Area_H']*100, 2)\n",
    "\n",
    "all_combinations_kec = pd.MultiIndex.from_product([kec_df['KECAMATAN'].unique(), categories_sh], names=['KECAMATAN', 'Kategori']).to_frame(index=False)\n",
    "                                                  \n",
    "kec_df_complete = all_combinations_kec.merge(kec_df, on=['KECAMATAN', 'Kategori'], how='left')\n",
    "kec_df_complete['Area_H'] = kec_df_complete['Area_H'].fillna(0)\n",
    "kec_df_complete_clean = pd.DataFrame()\n",
    "\n",
    "for name, group in kec_df_complete.groupby('KECAMATAN'):\n",
    "    non_zero_df = group[group['Area_H'] > 0].copy()\n",
    "    total_non_zero = non_zero_df['Area_H'].sum()\n",
    "\n",
    "    if total_non_zero > 0:\n",
    "        non_zero_df['Area_H'] = (non_zero_df['Area_H'] * (100 / total_non_zero)).round(2)\n",
    "\n",
    "    group.loc[non_zero_df.index, 'Area_H'] = non_zero_df['Area_H']\n",
    "    kec_df_complete_clean = pd.concat([kec_df_complete_clean, group])\n",
    "\n",
    "kec_df_complete_clean = kec_df_complete_clean.reset_index(drop=True)\n",
    "\n",
    "kec_df_complete_clean = pd.pivot(kec_df_complete_clean, index='KECAMATAN', columns='Kategori', values='Area_H')\n",
    "kec_df_complete_clean = kec_df_complete_clean.reset_index()\n",
    "kec_df_complete_clean.columns.name = None\n",
    "\n",
    "kec_df_complete_clean.drop(kec_df_complete_clean.index[0], inplace=True)\n",
    "\n",
    "kec_df_complete_clean = kec_df_complete_clean.rename(columns={'KECAMATAN': 'Wilayah'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_df_complete_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_df_complete_clean[kec_df_complete_clean[\"KECAMATAN\"] == \"ANDIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_adm = data[[ 'KABUPATEN', 'KECAMATAN']]\n",
    "kec_adm = kec_adm.rename(columns={'KECAMATAN': 'Wilayah'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_adm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_adm2 = kec_adm.drop_duplicates(subset='Wilayah', keep='last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_adm2.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_adm2[kec_adm2['Wilayah'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = kec_adm2[kec_adm2['Wilayah'].isnull()]\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_values = kec_adm2[kec_adm2['Wilayah'].str.strip() == '']\n",
    "print(empty_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_by_kategori = {key: value.title() for key, value in top_by_kategori.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilayah_sgt_tinggi = top_by_kategori['Sangat Tinggi']\n",
    "wilayah_tinggi = top_by_kategori['Tinggi']\n",
    "wilayah_menengah = top_by_kategori['Menengah']\n",
    "wilayah_rendah = top_by_kategori['Rendah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilayah_sgt_tinggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kec_df_complete_clean.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " kab_df_complete_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_pivot =  kec_df_complete_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membuat data dalam bentuk dictionary dengan lebih banyak kabupaten dan kecamatan\n",
    "data = {\n",
    "    'kecamatan': [\n",
    "        # Kabupaten Cianjur\n",
    "        'Cianjur', 'Warungkondang', 'Cibeber', 'Sukaresmi', 'Pacet',\n",
    "        # Kabupaten Bogor\n",
    "        'Cibinong', 'Bojonggede', 'Citereup', 'Gunung Putri', 'Cileungsi',\n",
    "        # Kota Bekasi\n",
    "        'Bekasi Timur', 'Bekasi Barat', 'Bekasi Utara', 'Bekasi Selatan', 'Rawalumbu',\n",
    "        # Kota Bandung\n",
    "        'Coblong', 'Cidadap', 'Sukajadi', 'Cicendo', 'Andir'\n",
    "    ],\n",
    "    'kabupaten': [\n",
    "        # Kabupaten Cianjur\n",
    "        'Kabupaten Cianjur', 'Kabupaten Cianjur', 'Kabupaten Cianjur', 'Kabupaten Cianjur', 'Kabupaten Cianjur',\n",
    "        # Kabupaten Bogor\n",
    "        'Kabupaten Bogor', 'Kabupaten Bogor', 'Kabupaten Bogor', 'Kabupaten Bogor', 'Kabupaten Bogor',\n",
    "        # Kota Bekasi\n",
    "        'Kota Bekasi', 'Kota Bekasi', 'Kota Bekasi', 'Kota Bekasi', 'Kota Bekasi',\n",
    "        # Kota Bandung\n",
    "        'Kota Bandung', 'Kota Bandung', 'Kota Bandung', 'Kota Bandung', 'Kota Bandung'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Membuat DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Contoh beberapa operasi yang bisa dilakukan dengan DataFrame ini:\n",
    "\n",
    "# 1. Menampilkan seluruh data\n",
    "print(\"Seluruh Data:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Menghitung jumlah kecamatan per kabupaten\n",
    "print(\"Jumlah Kecamatan per Kabupaten:\")\n",
    "print(df.groupby('kabupaten')['kecamatan'].count())\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. Menampilkan kecamatan untuk kabupaten tertentu\n",
    "print(\"Kecamatan di Kota Bandung:\")\n",
    "print(df[df['kabupaten'] == 'Kota Bandung']['kecamatan'].tolist())\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Mengurutkan data berdasarkan kabupaten dan kecamatan\n",
    "print(\"Data Terurut:\")\n",
    "print(df.sort_values(['kabupaten', 'kecamatan']))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 5. Menyimpan ke CSV (opsional)\n",
    "# df.to_csv('data_kecamatan_jabar.csv', index=False)\n",
    "\n",
    "# 6. Menambah kolom baru (misalnya kode wilayah)\n",
    "df['kode_wilayah'] = range(1, len(df) + 1)\n",
    "\n",
    "# 7. Statistik dasar\n",
    "print(\"Statistik Data:\")\n",
    "print(df.groupby('kabupaten').agg({\n",
    "    'kecamatan': 'count'\n",
    "}).rename(columns={'kecamatan': 'jumlah_kecamatan'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create first DataFrame\n",
    "df1 = pd.DataFrame({\n",
    "    'kecamatan': ['Cianjur', 'Cibeber', 'Warungkondang', 'Pacet'],\n",
    "    'kabupaten': ['Cianjur', 'Cianjur', 'Cianjur', 'Cianjur'],\n",
    "    'populasi': [100000, 80000, 60000, 70000]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame 1:\")\n",
    "print(df1)\n",
    "\n",
    "# Create second DataFrame\n",
    "df2 = pd.DataFrame({\n",
    "    'kecamatan': ['Cianjur', 'Cibeber', 'Pacet', 'Sukaresmi'],\n",
    "    'luas_wilayah': [50, 40, 30, 45],\n",
    "    'jumlah_sekolah': [20, 15, 10, 12]\n",
    "})\n",
    "\n",
    "# Different ways to join/merge\n",
    "\n",
    "# 1. Inner join\n",
    "df1 = df1.merge(\n",
    "    df2,\n",
    "    on='kecamatan',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 2. Left join\n",
    "merged_left = df1.merge(\n",
    "    df2,\n",
    "    on='kecamatan',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3. Right join\n",
    "merged_right = df1.merge(\n",
    "    df2,\n",
    "    on='kecamatan',\n",
    "    how='right'\n",
    ")\n",
    "\n",
    "# 4. Outer join\n",
    "merged_outer = df1.merge(\n",
    "    df2,\n",
    "    on='kecamatan',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Print results\n",
    "\n",
    "print(\"\\nOriginal DataFrame 2:\")\n",
    "print(df2)\n",
    "print(\"\\nInner Join (only matching rows):\")\n",
    "print(df1)\n",
    "# print(\"\\nLeft Join (all rows from df1):\")\n",
    "# print(merged_left)\n",
    "# print(\"\\nRight Join (all rows from df2):\")\n",
    "# print(merged_right)\n",
    "# print(\"\\nOuter Join (all rows from both):\")\n",
    "# print(merged_outer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import datetime\n",
    "import locale\n",
    "from utils.proses1_download_data_from_server import *\n",
    "from utils.proses1_log_table import log_to_sde\n",
    "from utils.proses1_raster_mosaic import copy_raster, add_raster_and_update_fields, delete_old_rasters\n",
    "from utils.proses1_get_download_data import test_download_data_das\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_clear_fgdb_temp import empty_fgdb\n",
    "from utils.proses1_update_table_summary import update_table\n",
    "from utils.proses1_preprocess import Preprocessing\n",
    "from utils.proses1_peta_laporan import PembuatanPetaLaporan\n",
    "from utils.proses1_data_process import interpolasi_bln, interpolasi_das\n",
    "from dotenv import load_dotenv\n",
    "from utils.proses1_authenticate import map_network_drive\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get time\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.UTF-8')\n",
    "now = datetime.datetime.now()\n",
    "current_date = datetime.datetime.now()\n",
    "year = current_date.year\n",
    "month = now.strftime(\"%m\")\n",
    "month_name = now.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_txt = get_current_dasarian()\n",
    "current_das_pseudo, current_das_txt_pseudo = get_current_dasarian_pseudo()\n",
    "\n",
    "\n",
    "# # Special case for dasarian\n",
    "today = datetime.datetime.today()\n",
    "day = today.day\n",
    "\n",
    "if day < 9:\n",
    "    das_pseudo_today = current_date - datetime.timedelta(days=10)\n",
    "    year = das_pseudo_today.year\n",
    "    month = das_pseudo_today.strftime(\"%m\")\n",
    "    month_name = das_pseudo_today.strftime(\"%B\")\n",
    "\n",
    "    \n",
    "file_name_dasarian = f'BlendGSMAP_POS.{year}{month}dec0{current_das_pseudo}.xls'\n",
    "\n",
    "print(file_name_dasarian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    " \n",
    "gis = GIS(url=\"https://pinteriklim.bmkg.go.id/portal\", username=\"portaladmin\", password=\"1kl1mbmkg2024\")\n",
    " \n",
    "search = gis.content.search(query=\"\", item_type=\"Web Map\", max_items=100)\n",
    " \n",
    "csv_path = Path('./data')\n",
    " \n",
    "if not os.path.exists(csv_path):\n",
    "    os.makedirs(csv_path)\n",
    " \n",
    "csv_file = csv_path / 'webmap_details.csv'\n",
    " \n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Item ID', 'Item Title', 'Item Type', 'Service URL'])\n",
    " \n",
    "    for item in search:\n",
    "        writer.writerow([item.id, item.title[:250], item.type, item.url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_das_pseudo, current_das_txt_pseudo = get_current_dasarian_pseudo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_das_pseudo, current_das_txt_pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_date_of_dasarian():\n",
    "    today = datetime.datetime.now() # Get the current date\n",
    "    # Calculate the number of days since the start of the cycle\n",
    "    days_since_start = today.day % 10\n",
    "    # Calculate the first day of the current dasarian cycle\n",
    "    first_dasarian_date = today - timedelta(days=days_since_start)\n",
    "    first_dasarian_date_str = first_dasarian_date.strftime(\"%Y-%m-%d\")\n",
    "    return first_dasarian_date, first_dasarian_date_str\n",
    "\n",
    "first_dasarian_date, first_dasarian_date_str = first_date_of_dasarian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dasarian_date, first_dasarian_date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = first_dasarian_date.year\n",
    "month = first_dasarian_date.strftime(\"%m\")\n",
    "month_name = first_dasarian_date.strftime(\"%B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year, month, month_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.proses1_update_polygon import first_date_of_dasarian, first_date_of_previous_month\n",
    "date_input_bln, date_input_bln_str = first_date_of_previous_month()\n",
    "date_input_das, date_input_das_str = first_date_of_dasarian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "date_input_das = today - datetime.timedelta(days=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_input_bln, date_input_das"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_bln = date_input_bln.year\n",
    "month_bln = date_input_bln.strftime(\"%m\")\n",
    "month_name_bln = date_input_bln.strftime(\"%B\")\n",
    "\n",
    "year_das = date_input_das.year\n",
    "month_das = date_input_das.strftime(\"%m\")\n",
    "month_name_das = date_input_das.strftime(\"%B\")\n",
    "\n",
    "year_bln, month_bln, month_name_bln, year_das, month_das, month_name_das"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dasarian_number(date):\n",
    "    \"\"\"\n",
    "    Calculate the dasarian number for a given date.\n",
    "\n",
    "    Parameters:\n",
    "    date (datetime): The date for which to calculate the dasarian number.\n",
    "\n",
    "    Returns:\n",
    "    int: The dasarian number (1, 2, or 3).\n",
    "    \"\"\"\n",
    "    day = date.day\n",
    "\n",
    "    if 1 <= day <= 10:\n",
    "        return 1\n",
    "    elif 11 <= day <= 20:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "\n",
    "get_dasarian_number(date_input_das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from utils.dasarian import get_current_dasarian\n",
    "from utils.proses1_update_polygon import first_date_of_dasarian, first_date_of_previous_month\n",
    "\n",
    "# Get date for previous month and previous dasarian\n",
    "\n",
    "date_input_bln, date_input_bln_str = first_date_of_previous_month()\n",
    "date_input_das, date_input_das_str = first_date_of_dasarian()\n",
    "\n",
    "year_bln = date_input_bln.year\n",
    "month_bln = date_input_bln.strftime(\"%m\")\n",
    "month_name_bln = date_input_bln.strftime(\"%B\")\n",
    "\n",
    "year_das = date_input_das.year\n",
    "month_das = date_input_das.strftime(\"%m\")\n",
    "month_name_das = date_input_das.strftime(\"%B\")\n",
    "current_dasarian, current_dasarian_text = get_current_dasarian(date_input_das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 'III', 2024, '11', 'November')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dasarian, current_dasarian_text, year_das, month_das, month_name_das"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-11-01'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_bulanan = date_input_bln.strftime('%Y-%m-%d')\n",
    "\n",
    "date_bulanan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
